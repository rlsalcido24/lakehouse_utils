{"metadata": {"dbt_schema_version": "https://schemas.getdbt.com/dbt/manifest/v9.json", "dbt_version": "1.5.3", "generated_at": "2023-07-26T21:00:42.528704Z", "invocation_id": "7853c388-a81d-45ae-8707-f466041ea976", "env": {}, "project_id": "b31faa3b901c5f6d1868d8a6f2f58b16", "user_id": "5d9bb951-61db-46d8-b3c7-5b71beee3db5", "send_anonymous_usage_stats": true, "adapter_type": "databricks"}, "nodes": {"test.springbricks_integration_tests.asset_try_to_decimal": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "asset_try_to_decimal", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "asset_try_to_decimal.sql", "original_file_path": "tests/asset_try_to_decimal.sql", "unique_id": "test.springbricks_integration_tests.asset_try_to_decimal", "fqn": ["springbricks_integration_tests", "asset_try_to_decimal"], "alias": "asset_try_to_decimal", "checksum": {"name": "sha256", "checksum": "d881755960f581ac55c16137223f88935338eff42ce8f3248f96ecf587eee8f3"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.330786, "relation_name": null, "raw_code": "with test as (\n    \n    select\n    '345.123' as inputuno,\n    '345' as snowoutputuno,\n    {{try_to_decimal('inputuno')}} as dbxoutputuno,\n    '345.12' as snowoutputunoa,\n    'NULL' as snowoutputunob,\n    {{try_to_decimal('inputuno', 10, 2)}} as dbxoutputunoa ,\n    {{try_to_decimal('inputuno', 4, 2)}} as dbxoutputunob ,\n    '$345.12' as inputdos,\n    '345.12' as snowoutputdos,\n    'NULL' as snowoutputdosb,\n    {{try_to_decimal('inputdos', \"$999.00\")}} as dbxoutputdos,\n    {{try_to_decimal('inputdos', 5, 2)}} as dbxoutputdosb\n\n\n\n)\n\nselect *\nfrom test\nwhere (snowoutputuno <> dbxoutputuno or snowoutputunoa <> dbxoutputunoa\n\tor snowoutputdos <> dbxoutputdos)", "language": "sql", "refs": [], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.try_to_decimal"], "nodes": []}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/asset_try_to_decimal.sql", "compiled": true, "compiled_code": "with test as (\n    \n    select\n    '345.123' as inputuno,\n    '345' as snowoutputuno,\n    \n\n\n\n\ntry_cast(inputuno as decimal(38, 0))\n\n\t\n\n as dbxoutputuno,\n    '345.12' as snowoutputunoa,\n    'NULL' as snowoutputunob,\n    \n\n\n\n\ntry_cast(inputuno as decimal(10, 2))\n\n\n\t\n\n as dbxoutputunoa ,\n    \n\n\n\n\ntry_cast(inputuno as decimal(4, 2))\n\n\n\t\n\n as dbxoutputunob ,\n    '$345.12' as inputdos,\n    '345.12' as snowoutputdos,\n    'NULL' as snowoutputdosb,\n    \n\n\n\n\ntry_to_number(inputdos, \"$999.00\")\n\n\n\t\n\n as dbxoutputdos,\n    \n\n\n\n\ntry_cast(inputdos as decimal(5, 2))\n\n\n\t\n\n as dbxoutputdosb\n\n\n\n)\n\nselect *\nfrom test\nwhere (snowoutputuno <> dbxoutputuno or snowoutputunoa <> dbxoutputunoa\n\tor snowoutputdos <> dbxoutputdos)", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.assert_dayname": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "assert_dayname", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "assert_dayname.sql", "original_file_path": "tests/assert_dayname.sql", "unique_id": "test.springbricks_integration_tests.assert_dayname", "fqn": ["springbricks_integration_tests", "assert_dayname"], "alias": "assert_dayname", "checksum": {"name": "sha256", "checksum": "c57e98bad936b1737e336125cef98422618f605f52f62c0561485f1910fc4006"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.35686, "relation_name": null, "raw_code": "with testraw as (\n    \n    select\n    input,\n    expected_output,\n    to_date(input,'d/M/yyyy[ H:m]') as input_formatted\n   \nfrom {{ ref('springbrickstests')}}\nwhere function_name = 'dayname'\n),\n\ntest as (\nselect input,\nexpected_output,\n{{dayname('input_formatted')}} as actual_output\nfrom testraw\n\n)\n\nselect *\nfrom test\nwhere expected_output <> actual_output", "language": "sql", "refs": [{"name": "springbrickstests", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.dayname"], "nodes": ["seed.springbricks_integration_tests.springbrickstests"]}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/assert_dayname.sql", "compiled": true, "compiled_code": "with testraw as (\n    \n    select\n    input,\n    expected_output,\n    to_date(input,'d/M/yyyy[ H:m]') as input_formatted\n   \nfrom `hive_metastore`.`robertocircle`.`springbrickstests`\nwhere function_name = 'dayname'\n),\n\ntest as (\nselect input,\nexpected_output,\n\n    CASE \n         WHEN datediff(CAST(input_formatted AS DATE), DATE'1799-12-29') % 7 = 0 THEN 'Sun'\n         WHEN datediff(CAST(input_formatted AS DATE), DATE'1799-12-29') % 7 = 1 THEN 'Mon'\n         WHEN datediff(CAST(input_formatted AS DATE), DATE'1799-12-29') % 7 = 2 THEN 'Tue'\n         WHEN datediff(CAST(input_formatted AS DATE), DATE'1799-12-29') % 7 = 3 THEN 'Wed'\n         WHEN datediff(CAST(input_formatted AS DATE), DATE'1799-12-29') % 7 = 4 THEN 'Thu'\n         WHEN datediff(CAST(input_formatted AS DATE), DATE'1799-12-29') % 7 = 5 THEN 'Fri'\n         ELSE 'Sat' END\n as actual_output\nfrom testraw\n\n)\n\nselect *\nfrom test\nwhere expected_output <> actual_output", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.timestampadd": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "timestampadd", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "timestampadd.sql", "original_file_path": "tests/timestampadd.sql", "unique_id": "test.springbricks_integration_tests.timestampadd", "fqn": ["springbricks_integration_tests", "timestampadd"], "alias": "timestampadd", "checksum": {"name": "sha256", "checksum": "3bc912dbf2987d9faeb643ba2871e81a4c2e4fa7f1a35e308a8c54651d84bbf3"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.365341, "relation_name": null, "raw_code": "with testraw as (\n    \n    select\n    input,\n    expected_output,\n    input:col1 as unit,\n    input:col2 as measure,\n    input:col3 as base\n   \nfrom {{ ref('springbrickstests')}}\nwhere function_name = 'timestampadd'\n),\n\ntest as (\nselect input,\nexpected_output,\n{{timestampadd('unit', 'measure', 'base')}} as actual_output,\nconcat('\"',actual_output, '\"') as actual_output_quotes\nfrom testraw\n\n)\n\nselect *\nfrom test\nwhere expected_output <> actual_output_quotes", "language": "sql", "refs": [{"name": "springbrickstests", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.timestampadd"], "nodes": ["seed.springbricks_integration_tests.springbrickstests"]}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/timestampadd.sql", "compiled": true, "compiled_code": "with testraw as (\n    \n    select\n    input,\n    expected_output,\n    input:col1 as unit,\n    input:col2 as measure,\n    input:col3 as base\n   \nfrom `hive_metastore`.`robertocircle`.`springbrickstests`\nwhere function_name = 'timestampadd'\n),\n\ntest as (\nselect input,\nexpected_output,\n\nCASE \n  WHEN lower(unit) = 'year'   THEN base + make_interval(measure)\n  WHEN lower(unit) = 'month'  THEN base + make_interval(0, measure)\n  WHEN lower(unit) = 'day'    THEN base + make_interval(0, 0, 0, measure)\n  WHEN lower(unit) = 'hour'   THEN base + make_interval(0, 0, 0, 0, measure)\n  WHEN lower(unit) = 'minute' THEN base + make_interval(0, 0, 0, 0, 0, measure)\n  WHEN lower(unit) = 'second' THEN base + make_interval(0, 0, 0, 0, 0, 0, measure)\n  END\n as actual_output,\nconcat('\"',actual_output, '\"') as actual_output_quotes\nfrom testraw\n\n)\n\nselect *\nfrom test\nwhere expected_output <> actual_output_quotes", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.assert_to_boolean": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "assert_to_boolean", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "assert_to_boolean.sql", "original_file_path": "tests/assert_to_boolean.sql", "unique_id": "test.springbricks_integration_tests.assert_to_boolean", "fqn": ["springbricks_integration_tests", "assert_to_boolean"], "alias": "assert_to_boolean", "checksum": {"name": "sha256", "checksum": "69f464e40f71e473800bed24491c89809bf3bd25b3717c843ed3442e8db97df1"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.375015, "relation_name": null, "raw_code": "with test as (\n    \n    select\n    input,\n    expected_output,\n    {{to_boolean('input')}} as actual_output\nfrom {{ ref('springbrickstests')}}\nwhere function_name = 'to_boolean'\n)\n\nselect *\nfrom test\nwhere lower(expected_output) <> actual_output::string", "language": "sql", "refs": [{"name": "springbrickstests", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.to_boolean"], "nodes": ["seed.springbricks_integration_tests.springbrickstests"]}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/assert_to_boolean.sql", "compiled": true, "compiled_code": "with test as (\n    \n    select\n    input,\n    expected_output,\n    \n CASE \nWHEN lower(input) = 'false' THEN FALSE\nWHEN lower(input) = 'f' THEN FALSE\nWHEN lower(input) =  'no' THEN FALSE\nWHEN lower(input) = 'n' THEN FALSE\nWHEN lower(input) = 'off' THEN FALSE\nWHEN lower(input) = '0' THEN FALSE\nWHEN lower(input) = 'true' THEN TRUE\nWHEN lower(input) = 't' THEN TRUE\nWHEN lower(input) =  'yes' THEN TRUE\nWHEN lower(input) = 'y' THEN TRUE\nWHEN lower(input) = 'on' THEN TRUE\nWHEN lower(input) = '1' THEN TRUE\n\nELSE NULL\nEND\n as actual_output\nfrom `hive_metastore`.`robertocircle`.`springbrickstests`\nwhere function_name = 'to_boolean'\n)\n\nselect *\nfrom test\nwhere lower(expected_output) <> actual_output::string", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.assert_to_array": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "assert_to_array", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "assert_to_array.sql", "original_file_path": "tests/assert_to_array.sql", "unique_id": "test.springbricks_integration_tests.assert_to_array", "fqn": ["springbricks_integration_tests", "assert_to_array"], "alias": "assert_to_array", "checksum": {"name": "sha256", "checksum": "b8bdce2ea8cb0a6634459c8e05cea5ed00d30dc044772ab96fb0f33ac964e8df"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.3840451, "relation_name": null, "raw_code": "with test as (\n    \n    select\n    input,\n    expected_output,\n    {{to_array('input')}} as actual_output\nfrom {{ ref('springbrickstests')}}\nwhere function_name = 'to_array'\n)\n\nselect *\nfrom test\nwhere expected_output <> actual_output::string", "language": "sql", "refs": [{"name": "springbrickstests", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.to_array"], "nodes": ["seed.springbricks_integration_tests.springbrickstests"]}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/assert_to_array.sql", "compiled": true, "compiled_code": "with test as (\n    \n    select\n    input,\n    expected_output,\n    \n    array(input)\n as actual_output\nfrom `hive_metastore`.`robertocircle`.`springbrickstests`\nwhere function_name = 'to_array'\n)\n\nselect *\nfrom test\nwhere expected_output <> actual_output::string", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.assert_date_from_parts": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "assert_date_from_parts", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "assert_date_from_parts.sql", "original_file_path": "tests/assert_date_from_parts.sql", "unique_id": "test.springbricks_integration_tests.assert_date_from_parts", "fqn": ["springbricks_integration_tests", "assert_date_from_parts"], "alias": "assert_date_from_parts", "checksum": {"name": "sha256", "checksum": "868d9e0e18c812d8f0fe47b499b35447b6be421f5377507af3a7389a4c9323b2"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.39188, "relation_name": null, "raw_code": "with testraw as (\n    \n    select\n    input,\n    expected_output,\n    input:col1 as year,\n    input:col2 as month,\n    input:col3 as day,\n    to_date(expected_output,'d/M/yyyy[ H:m]') as expected_output_formatted\n   \nfrom {{ ref('springbrickstests')}}\nwhere function_name = 'date_from_parts'\n),\n\ntest as (\nselect input,\nexpected_output_formatted,\n{{date_from_parts('year','month','day')}} as actual_output\nfrom testraw\n\n)\n\nselect *\nfrom test\nwhere expected_output_formatted <> actual_output", "language": "sql", "refs": [{"name": "springbrickstests", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.date_from_parts"], "nodes": ["seed.springbricks_integration_tests.springbrickstests"]}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/assert_date_from_parts.sql", "compiled": true, "compiled_code": "with testraw as (\n    \n    select\n    input,\n    expected_output,\n    input:col1 as year,\n    input:col2 as month,\n    input:col3 as day,\n    to_date(expected_output,'d/M/yyyy[ H:m]') as expected_output_formatted\n   \nfrom `hive_metastore`.`robertocircle`.`springbrickstests`\nwhere function_name = 'date_from_parts'\n),\n\ntest as (\nselect input,\nexpected_output_formatted,\n\n    make_date(year, month, day)\n as actual_output\nfrom testraw\n\n)\n\nselect *\nfrom test\nwhere expected_output_formatted <> actual_output", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.asset_to_decimal": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "asset_to_decimal", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "asset_to_decimal.sql", "original_file_path": "tests/asset_to_decimal.sql", "unique_id": "test.springbricks_integration_tests.asset_to_decimal", "fqn": ["springbricks_integration_tests", "asset_to_decimal"], "alias": "asset_to_decimal", "checksum": {"name": "sha256", "checksum": "0e03a798a830bdf5910435c931e9f3f6ccd8bca33b8c767c8e92b2c852711d89"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.4012659, "relation_name": null, "raw_code": "with test as (\n    \n    select\n    '12.3456' as inputuno,\n    '12' as snowoutputuno,\n    {{to_decimal('inputuno')}} as dbxoutputuno,\n    '12.3' as snowoutputunoa,\n    '12.3456' as snowoutputunob,\n    {{to_decimal('inputuno', 10, 1)}} as dbxoutputunoa ,\n    {{to_decimal('inputuno', 10, 8)}} as dbxoutputunob ,\n    '98.76546' as inputdos,\n    '99' as snowoutputdos,\n    '98.8' as snowoutputdosa,\n    '98.76546' as snowoutputdosb,\n    {{to_decimal('inputdos')}} as dbxoutputdos,\n    {{to_decimal('inputdos', 10, 1)}} as dbxoutputdosa,\n    {{to_decimal('inputdos', 10, 8)}} as dbxoutputdosb,\n    '12.3' as inputtres,\n    '12.3' as snowoutputtres,\n    '12.3' as snowoutputtresa,\n    '12.3' as snowoutputtresb,\n    {{to_decimal('inputtres', '99.9')}} as dbxoutputtres,\n    {{to_decimal('inputtres', '99.9', 9, 5)}} as dbxoutputtresa,\n    {{to_decimal('inputtres', 'TM9', 9, 5)}} as dbxoutputtresb\n\n\n\n)\n\nselect *\nfrom test\nwhere (snowoutputuno <> dbxoutputuno or snowoutputunoa <> dbxoutputunoa or snowoutputunob <> dbxoutputunob\n\tor snowoutputdos <> dbxoutputdos or snowoutputdosa <> dbxoutputdosa or snowoutputdosb <> dbxoutputdosb\n\tor snowoutputtres <> dbxoutputtres or snowoutputtresa <> dbxoutputtresa or snowoutputtresb <> dbxoutputtresb)", "language": "sql", "refs": [], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.to_decimal"], "nodes": []}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/asset_to_decimal.sql", "compiled": true, "compiled_code": "with test as (\n    \n    select\n    '12.3456' as inputuno,\n    '12' as snowoutputuno,\n    \n\n\n\n\ncast(inputuno as decimal(38, 0))\n\n\t\n\n as dbxoutputuno,\n    '12.3' as snowoutputunoa,\n    '12.3456' as snowoutputunob,\n    \n\n\n\n\ncast(inputuno as decimal(10, 1))\n\n\n\t\n\n as dbxoutputunoa ,\n    \n\n\n\n\ncast(inputuno as decimal(10, 8))\n\n\n\t\n\n as dbxoutputunob ,\n    '98.76546' as inputdos,\n    '99' as snowoutputdos,\n    '98.8' as snowoutputdosa,\n    '98.76546' as snowoutputdosb,\n    \n\n\n\n\ncast(inputdos as decimal(38, 0))\n\n\t\n\n as dbxoutputdos,\n    \n\n\n\n\ncast(inputdos as decimal(10, 1))\n\n\n\t\n\n as dbxoutputdosa,\n    \n\n\n\n\ncast(inputdos as decimal(10, 8))\n\n\n\t\n\n as dbxoutputdosb,\n    '12.3' as inputtres,\n    '12.3' as snowoutputtres,\n    '12.3' as snowoutputtresa,\n    '12.3' as snowoutputtresb,\n    \n\n\n\n\nto_number(inputtres, \"99.9\")\n\n\n\t\n\n as dbxoutputtres,\n    \n\n\n\n\n\n\n\ncast(inputtres as decimal(9, 5))\n\n\n\t\n\n as dbxoutputtresa,\n    \n\n\n\n\n\n\n\ncast(inputtres as decimal(9, 5))\n\n\n\t\n\n as dbxoutputtresb\n\n\n\n)\n\nselect *\nfrom test\nwhere (snowoutputuno <> dbxoutputuno or snowoutputunoa <> dbxoutputunoa or snowoutputunob <> dbxoutputunob\n\tor snowoutputdos <> dbxoutputdos or snowoutputdosa <> dbxoutputdosa or snowoutputdosb <> dbxoutputdosb\n\tor snowoutputtres <> dbxoutputtres or snowoutputtresa <> dbxoutputtresa or snowoutputtresb <> dbxoutputtresb)", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.assert_zeroifnull": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "assert_zeroifnull", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "assert_zeroifnull.sql", "original_file_path": "tests/assert_zeroifnull.sql", "unique_id": "test.springbricks_integration_tests.assert_zeroifnull", "fqn": ["springbricks_integration_tests", "assert_zeroifnull"], "alias": "assert_zeroifnull", "checksum": {"name": "sha256", "checksum": "8d068aa949f842afa83833ce0b55e1587269f873a982409d42d5c853e9df4ce1"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.414311, "relation_name": null, "raw_code": "with test as (\n    \n    select\n    input,\n    input::decimal(9,5) as inputdec,\n    expected_output,\n    {{zeroifnull('inputdec')}} as actual_output\nfrom {{ ref('springbrickstests')}}\nwhere function_name = 'zeroifnull'\n)\n\nselect *\nfrom test\nwhere expected_output <> actual_output", "language": "sql", "refs": [{"name": "springbrickstests", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.zeroifnull"], "nodes": ["seed.springbricks_integration_tests.springbrickstests"]}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/assert_zeroifnull.sql", "compiled": true, "compiled_code": "with test as (\n    \n    select\n    input,\n    input::decimal(9,5) as inputdec,\n    expected_output,\n    \n    nvl(inputdec, 0)\n as actual_output\nfrom `hive_metastore`.`robertocircle`.`springbrickstests`\nwhere function_name = 'zeroifnull'\n)\n\nselect *\nfrom test\nwhere expected_output <> actual_output", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.assert_week": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "assert_week", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "assert_week.sql", "original_file_path": "tests/assert_week.sql", "unique_id": "test.springbricks_integration_tests.assert_week", "fqn": ["springbricks_integration_tests", "assert_week"], "alias": "assert_week", "checksum": {"name": "sha256", "checksum": "9010c0d0e694c9dfc65b942e24905f7c0aea4c473904566ac103553ccc40b77c"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.422116, "relation_name": null, "raw_code": "with test as (\n    \n    select\n    input,\n    expected_output,\n    {{week('input')}} as actual_output\nfrom {{ ref('springbrickstests')}}\nwhere function_name = 'week'\n)\n\nselect *\nfrom test\nwhere expected_output <> actual_output::string", "language": "sql", "refs": [{"name": "springbrickstests", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.week"], "nodes": ["seed.springbricks_integration_tests.springbrickstests"]}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/assert_week.sql", "compiled": true, "compiled_code": "with test as (\n    \n    select\n    input,\n    expected_output,\n    \n    EXTRACT(WEEK FROM input)\n as actual_output\nfrom `hive_metastore`.`robertocircle`.`springbrickstests`\nwhere function_name = 'week'\n)\n\nselect *\nfrom test\nwhere expected_output <> actual_output::string", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.assert_md5_binary": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "assert_md5_binary", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "assert_md5_binary.sql", "original_file_path": "tests/assert_md5_binary.sql", "unique_id": "test.springbricks_integration_tests.assert_md5_binary", "fqn": ["springbricks_integration_tests", "assert_md5_binary"], "alias": "assert_md5_binary", "checksum": {"name": "sha256", "checksum": "23fb287a6c3c1f8d51977217672a0ba5ec9f858c17a260eadd64021be4b994c0"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.42986, "relation_name": null, "raw_code": "with test as (\n    \n    select\n    input,\n    expected_output,\n    {{md5_binary('input')}} as actual_output\nfrom {{ ref('springbrickstests')}}\nwhere function_name = 'md5_binary'\n)\n\nselect *\nfrom test\nwhere expected_output <> upper(actual_output)", "language": "sql", "refs": [{"name": "springbrickstests", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.md5_binary"], "nodes": ["seed.springbricks_integration_tests.springbrickstests"]}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/assert_md5_binary.sql", "compiled": true, "compiled_code": "with test as (\n    \n    select\n    input,\n    expected_output,\n    \n    md5(input)\n as actual_output\nfrom `hive_metastore`.`robertocircle`.`springbrickstests`\nwhere function_name = 'md5_binary'\n)\n\nselect *\nfrom test\nwhere expected_output <> upper(actual_output)", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.asset_try_to_numeric": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "asset_try_to_numeric", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "asset_try_to_numeric.sql", "original_file_path": "tests/asset_try_to_numeric.sql", "unique_id": "test.springbricks_integration_tests.asset_try_to_numeric", "fqn": ["springbricks_integration_tests", "asset_try_to_numeric"], "alias": "asset_try_to_numeric", "checksum": {"name": "sha256", "checksum": "8b89a3ef9e15e75a0a4e3552c83927619fe911e988d8629958a543dc2c72488b"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.437126, "relation_name": null, "raw_code": "with test as (\n    \n    select\n    '345.123' as inputuno,\n    '345' as snowoutputuno,\n    {{try_to_numeric('inputuno')}} as dbxoutputuno,\n    '345.12' as snowoutputunoa,\n    'NULL' as snowoutputunob,\n    {{try_to_numeric('inputuno', 10, 2)}} as dbxoutputunoa ,\n    {{try_to_numeric('inputuno', 4, 2)}} as dbxoutputunob ,\n    '$345.12' as inputdos,\n    '345.12' as snowoutputdos,\n    'NULL' as snowoutputdosb,\n    {{try_to_numeric('inputdos', \"$999.00\")}} as dbxoutputdos,\n    {{try_to_numeric('inputdos', 5, 2)}} as dbxoutputdosb\n\n\n\n)\n\nselect *\nfrom test\nwhere (snowoutputuno <> dbxoutputuno or snowoutputunoa <> dbxoutputunoa\n\tor snowoutputdos <> dbxoutputdos)", "language": "sql", "refs": [], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.try_to_numeric"], "nodes": []}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/asset_try_to_numeric.sql", "compiled": true, "compiled_code": "with test as (\n    \n    select\n    '345.123' as inputuno,\n    '345' as snowoutputuno,\n    \n\n\n\n\ntry_cast(inputuno as decimal(38, 0))\n\n\t\n\n as dbxoutputuno,\n    '345.12' as snowoutputunoa,\n    'NULL' as snowoutputunob,\n    \n\n\n\n\ntry_cast(inputuno as decimal(10, 2))\n\n\n\t\n\n as dbxoutputunoa ,\n    \n\n\n\n\ntry_cast(inputuno as decimal(4, 2))\n\n\n\t\n\n as dbxoutputunob ,\n    '$345.12' as inputdos,\n    '345.12' as snowoutputdos,\n    'NULL' as snowoutputdosb,\n    \n\n\n\n\ntry_to_number(inputdos, \"$999.00\")\n\n\n\t\n\n as dbxoutputdos,\n    \n\n\n\n\ntry_cast(inputdos as decimal(5, 2))\n\n\n\t\n\n as dbxoutputdosb\n\n\n\n)\n\nselect *\nfrom test\nwhere (snowoutputuno <> dbxoutputuno or snowoutputunoa <> dbxoutputunoa\n\tor snowoutputdos <> dbxoutputdos)", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.assert_strtok_to_array": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "assert_strtok_to_array", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "assert_strtok_to_array.sql", "original_file_path": "tests/assert_strtok_to_array.sql", "unique_id": "test.springbricks_integration_tests.assert_strtok_to_array", "fqn": ["springbricks_integration_tests", "assert_strtok_to_array"], "alias": "assert_strtok_to_array", "checksum": {"name": "sha256", "checksum": "e951773ee20add01552babee7459fc4d2c7853bb2c3d639780660cab89d0589c"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.448253, "relation_name": null, "raw_code": "with testraw as (\n    \n    select\n    input,\n    expected_output,\n    input:col1 as expr,\n    input:col2 as delim\n   \nfrom {{ ref('springbrickstests')}}\nwhere function_name = 'strtok_to_array'\n),\n\ntest as (\nselect input,\nexpected_output,\n{{strtok_to_array('expr', 'delim')}} as actual_output\nfrom testraw\n\n)\n\nselect *\nfrom test\nwhere expected_output = actual_output::string", "language": "sql", "refs": [{"name": "springbrickstests", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.strtok_to_array"], "nodes": ["seed.springbricks_integration_tests.springbrickstests"]}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/assert_strtok_to_array.sql", "compiled": true, "compiled_code": "with testraw as (\n    \n    select\n    input,\n    expected_output,\n    input:col1 as expr,\n    input:col2 as delim\n   \nfrom `hive_metastore`.`robertocircle`.`springbrickstests`\nwhere function_name = 'strtok_to_array'\n),\n\ntest as (\nselect input,\nexpected_output,\n\n    split(expr, concat(\"[\", delim, \"]\"))\n as actual_output\nfrom testraw\n\n)\n\nselect *\nfrom test\nwhere expected_output = actual_output::string", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.timestampdiff": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "timestampdiff", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "timestampdiff.sql", "original_file_path": "tests/timestampdiff.sql", "unique_id": "test.springbricks_integration_tests.timestampdiff", "fqn": ["springbricks_integration_tests", "timestampdiff"], "alias": "timestampdiff", "checksum": {"name": "sha256", "checksum": "0f5ade3501f30e7a939460ece21e4839d568f77c85b1e2953aeefdf424aec975"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.4559958, "relation_name": null, "raw_code": "with testraw as (\n    \n    select\n    input,\n    expected_output,\n    input:col1 as unit,\n    input:col2 as timeuno,\n    input:col3 as timedos\n   \nfrom {{ ref('springbrickstests')}}\nwhere function_name = 'timestampdiff'\n),\n\ntest as (\nselect input,\nexpected_output,\n{{timestampdiff('unit', 'timeuno', 'timedos')}} as actual_output\nfrom testraw\n\n)\n\nselect *\nfrom test\nwhere expected_output <> actual_output", "language": "sql", "refs": [{"name": "springbrickstests", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.timestampdiff"], "nodes": ["seed.springbricks_integration_tests.springbrickstests"]}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/timestampdiff.sql", "compiled": true, "compiled_code": "with testraw as (\n    \n    select\n    input,\n    expected_output,\n    input:col1 as unit,\n    input:col2 as timeuno,\n    input:col3 as timedos\n   \nfrom `hive_metastore`.`robertocircle`.`springbrickstests`\nwhere function_name = 'timestampdiff'\n),\n\ntest as (\nselect input,\nexpected_output,\n\n  CASE \n  WHEN lower(unit) = 'year'   THEN EXTRACT(YEAR FROM timedos) - EXTRACT(YEAR FROM timeuno)\n  WHEN lower(unit) = 'month'  THEN (EXTRACT(YEAR FROM timedos) * 12 + EXTRACT(MONTH FROM timedos))\n                          - (EXTRACT(YEAR FROM timeuno) * 12 + EXTRACT(MONTH FROM timeuno))\n  WHEN lower(unit) = 'day'    THEN datediff(CAST(timedos AS DATE), CAST(timeuno AS DATE))\n  WHEN lower(unit) = 'hour'   THEN EXTRACT(HOUR FROM timedos) - EXTRACT(HOUR FROM timeuno)\n  WHEN lower(unit) = 'minute' THEN (EXTRACT(HOUR FROM timedos) * 60 + EXTRACT(MINUTE FROM timedos))\n                          - (EXTRACT(HOUR FROM timeuno) * 60 + EXTRACT(MINUTE FROM timeuno))\n  WHEN lower(unit) = 'second' THEN (EXTRACT(HOUR FROM timedos) * 3600 + EXTRACT(MINUTE FROM timedos) * 60 + EXTRACT(SECOND FROM timedos))\n                          - (EXTRACT(HOUR FROM timedos) * 3600 + EXTRACT(MINUTE FROM timedos) * 60 + EXTRACT(SECOND FROM timedos))\n  END\n as actual_output\nfrom testraw\n\n)\n\nselect *\nfrom test\nwhere expected_output <> actual_output", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.asset_to_numeric": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "asset_to_numeric", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "asset_to_numeric.sql", "original_file_path": "tests/asset_to_numeric.sql", "unique_id": "test.springbricks_integration_tests.asset_to_numeric", "fqn": ["springbricks_integration_tests", "asset_to_numeric"], "alias": "asset_to_numeric", "checksum": {"name": "sha256", "checksum": "3eba141b469e9e65c43a5b6b38c2aaf141475d147b064dd34d606bf94e6e7bb8"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.467658, "relation_name": null, "raw_code": "with test as (\n    \n    select\n    '12.3456' as inputuno,\n    '12' as snowoutputuno,\n    {{to_numeric('inputuno')}} as dbxoutputuno,\n    '12.3' as snowoutputunoa,\n    '12.3456' as snowoutputunob,\n    {{to_numeric('inputuno', 10, 1)}} as dbxoutputunoa ,\n    {{to_numeric('inputuno', 10, 8)}} as dbxoutputunob ,\n    '98.76546' as inputdos,\n    '99' as snowoutputdos,\n    '98.8' as snowoutputdosa,\n    '98.76546' as snowoutputdosb,\n    {{to_numeric('inputdos')}} as dbxoutputdos,\n    {{to_numeric('inputdos', 10, 1)}} as dbxoutputdosa,\n    {{to_numeric('inputdos', 10, 8)}} as dbxoutputdosb,\n    '12.3' as inputtres,\n    '12.3' as snowoutputtres,\n    '12.3' as snowoutputtresa,\n    '12.3' as snowoutputtresb,\n    {{to_numeric('inputtres', '99.9')}} as dbxoutputtres,\n    {{to_numeric('inputtres', '99.9', 9, 5)}} as dbxoutputtresa,\n    {{to_numeric('inputtres', 'TM9', 9, 5)}} as dbxoutputtresb\n\n\n\n)\n\nselect *\nfrom test\nwhere (snowoutputuno <> dbxoutputuno or snowoutputunoa <> dbxoutputunoa or snowoutputunob <> dbxoutputunob\n\tor snowoutputdos <> dbxoutputdos or snowoutputdosa <> dbxoutputdosa or snowoutputdosb <> dbxoutputdosb\n\tor snowoutputtres <> dbxoutputtres or snowoutputtresa <> dbxoutputtresa or snowoutputtresb <> dbxoutputtresb)", "language": "sql", "refs": [], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.to_numeric"], "nodes": []}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/asset_to_numeric.sql", "compiled": true, "compiled_code": "with test as (\n    \n    select\n    '12.3456' as inputuno,\n    '12' as snowoutputuno,\n    \n\n\n\n\ncast(inputuno as decimal(38, 0))\n\n\t\n\n as dbxoutputuno,\n    '12.3' as snowoutputunoa,\n    '12.3456' as snowoutputunob,\n    \n\n\n\n\ncast(inputuno as decimal(10, 1))\n\n\n\t\n\n as dbxoutputunoa ,\n    \n\n\n\n\ncast(inputuno as decimal(10, 8))\n\n\n\t\n\n as dbxoutputunob ,\n    '98.76546' as inputdos,\n    '99' as snowoutputdos,\n    '98.8' as snowoutputdosa,\n    '98.76546' as snowoutputdosb,\n    \n\n\n\n\ncast(inputdos as decimal(38, 0))\n\n\t\n\n as dbxoutputdos,\n    \n\n\n\n\ncast(inputdos as decimal(10, 1))\n\n\n\t\n\n as dbxoutputdosa,\n    \n\n\n\n\ncast(inputdos as decimal(10, 8))\n\n\n\t\n\n as dbxoutputdosb,\n    '12.3' as inputtres,\n    '12.3' as snowoutputtres,\n    '12.3' as snowoutputtresa,\n    '12.3' as snowoutputtresb,\n    \n\n\n\n\nto_number(inputtres, \"99.9\")\n\n\n\t\n\n as dbxoutputtres,\n    \n\n\n\n\n\n\n\ncast(inputtres as decimal(9, 5))\n\n\n\t\n\n as dbxoutputtresa,\n    \n\n\n\n\n\n\n\ncast(inputtres as decimal(9, 5))\n\n\n\t\n\n as dbxoutputtresb\n\n\n\n)\n\nselect *\nfrom test\nwhere (snowoutputuno <> dbxoutputuno or snowoutputunoa <> dbxoutputunoa or snowoutputunob <> dbxoutputunob\n\tor snowoutputdos <> dbxoutputdos or snowoutputdosa <> dbxoutputdosa or snowoutputdosb <> dbxoutputdosb\n\tor snowoutputtres <> dbxoutputtres or snowoutputtresa <> dbxoutputtresa or snowoutputtresb <> dbxoutputtresb)", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.assert_listagg": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "assert_listagg", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "assert_listagg.sql", "original_file_path": "tests/assert_listagg.sql", "unique_id": "test.springbricks_integration_tests.assert_listagg", "fqn": ["springbricks_integration_tests", "assert_listagg"], "alias": "assert_listagg", "checksum": {"name": "sha256", "checksum": "22586c5648e8033ed288a9bbc1cec62fcec06175a58d0efafa207244b2f44fc0"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.4805849, "relation_name": null, "raw_code": "with parse as (\nSELECT inputuno FROM VALUES (41445), (55937), (67781), (80550) AS (inputuno)\n),\n\n\ntest as (\n    \n    select\n\n\n    \"41445 55937 67781 80550\" as snowoutputuno,\n\n    {{listagg('inputuno',' ')}} as dbxoutputuno\n    from parse\ngroup by 1\n     \n)\n\nselect *\nfrom test\nwhere snowoutputuno <> dbxoutputuno", "language": "sql", "refs": [], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.listagg"], "nodes": []}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/assert_listagg.sql", "compiled": true, "compiled_code": "with parse as (\nSELECT inputuno FROM VALUES (41445), (55937), (67781), (80550) AS (inputuno)\n),\n\n\ntest as (\n    \n    select\n\n\n    \"41445 55937 67781 80550\" as snowoutputuno,\n\n    \n   array_join(sort_array(collect_list(inputuno)), \" \")\n  \n as dbxoutputuno\n    from parse\ngroup by 1\n     \n)\n\nselect *\nfrom test\nwhere snowoutputuno <> dbxoutputuno", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.assert_base64_encode": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "assert_base64_encode", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "assert_base64_encode.sql", "original_file_path": "tests/assert_base64_encode.sql", "unique_id": "test.springbricks_integration_tests.assert_base64_encode", "fqn": ["springbricks_integration_tests", "assert_base64_encode"], "alias": "assert_base64_encode", "checksum": {"name": "sha256", "checksum": "369df8b5aa3f40977315d2a6c37c9680b874ce7f0f1d62e0fae11c6eb869be62"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.487946, "relation_name": null, "raw_code": "with test as (\n    \n    select\n    'Snowflake' as inputuno,\n    'U25vd2ZsYWtl' as snowoutputuno,\n    {{base64_encode('inputuno')}} as dbxoutputuno\n\n\n\n\n)\n\nselect *\nfrom test\nwhere (snowoutputuno <> dbxoutputuno)", "language": "sql", "refs": [], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.base64_encode"], "nodes": []}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/assert_base64_encode.sql", "compiled": true, "compiled_code": "with test as (\n    \n    select\n    'Snowflake' as inputuno,\n    'U25vd2ZsYWtl' as snowoutputuno,\n    \n    base64(inputuno)\n as dbxoutputuno\n\n\n\n\n)\n\nselect *\nfrom test\nwhere (snowoutputuno <> dbxoutputuno)", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.assert_to_time": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "assert_to_time", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "assert_to_time.sql", "original_file_path": "tests/assert_to_time.sql", "unique_id": "test.springbricks_integration_tests.assert_to_time", "fqn": ["springbricks_integration_tests", "assert_to_time"], "alias": "assert_to_time", "checksum": {"name": "sha256", "checksum": "271e62fe88e47829ffa61a1b36a4b214ef0e49d21e55019b46ded32b4c9b6384"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.495039, "relation_name": null, "raw_code": "with testraw as (\n    \n    select\n    input,\n    expected_output,\n    input:col1 as expr\n   \nfrom {{ ref('springbrickstests')}}\nwhere function_name = 'to_time'\n),\n\ntest as (\nselect input,\nexpected_output,\n{{to_time('expr')}} as actual_output\nfrom testraw\n\n)\n\nselect *\nfrom test\nwhere expected_output <> actual_output", "language": "sql", "refs": [{"name": "springbrickstests", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.to_time"], "nodes": ["seed.springbricks_integration_tests.springbrickstests"]}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/assert_to_time.sql", "compiled": true, "compiled_code": "with testraw as (\n    \n    select\n    input,\n    expected_output,\n    input:col1 as expr\n   \nfrom `hive_metastore`.`robertocircle`.`springbrickstests`\nwhere function_name = 'to_time'\n),\n\ntest as (\nselect input,\nexpected_output,\n\n  to_timestamp(expr, 'HH:mm:ss')\n as actual_output\nfrom testraw\n\n)\n\nselect *\nfrom test\nwhere expected_output <> actual_output", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.assert_startswith": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "assert_startswith", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "assert_startswith.sql", "original_file_path": "tests/assert_startswith.sql", "unique_id": "test.springbricks_integration_tests.assert_startswith", "fqn": ["springbricks_integration_tests", "assert_startswith"], "alias": "assert_startswith", "checksum": {"name": "sha256", "checksum": "f7124b35d4f98d49d61494c9926beebf4c7b50284547e63cb584f8ea233b9d93"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.502342, "relation_name": null, "raw_code": "with test as (\n    \n    select\n    input,\n    expected_output,\n    {{startswith('input','\"te\"')}} as actual_output\nfrom {{ ref('springbrickstests')}}\nwhere function_name = 'startswith'\n     \n)\n\nselect *\nfrom test\nwhere expected_output::boolean <> actual_output", "language": "sql", "refs": [{"name": "springbrickstests", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.startswith"], "nodes": ["seed.springbricks_integration_tests.springbrickstests"]}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/assert_startswith.sql", "compiled": true, "compiled_code": "with test as (\n    \n    select\n    input,\n    expected_output,\n    \n    position(\"te\", input) = 1\n as actual_output\nfrom `hive_metastore`.`robertocircle`.`springbrickstests`\nwhere function_name = 'startswith'\n     \n)\n\nselect *\nfrom test\nwhere expected_output::boolean <> actual_output", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.asset_try_to_number": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "asset_try_to_number", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "asset_try_to_number.sql", "original_file_path": "tests/asset_try_to_number.sql", "unique_id": "test.springbricks_integration_tests.asset_try_to_number", "fqn": ["springbricks_integration_tests", "asset_try_to_number"], "alias": "asset_try_to_number", "checksum": {"name": "sha256", "checksum": "81cfe0a80c67e36bb263eab777dff5d69379f2426f826f666bc2452aaeb285e5"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.509879, "relation_name": null, "raw_code": "with test as (\n    \n    select\n    '345.123' as inputuno,\n    '345' as snowoutputuno,\n    {{try_to_number('inputuno')}} as dbxoutputuno,\n    '345.12' as snowoutputunoa,\n    'NULL' as snowoutputunob,\n    {{try_to_number('inputuno', 10, 2)}} as dbxoutputunoa ,\n    {{try_to_number('inputuno', 4, 2)}} as dbxoutputunob ,\n    '$345.12' as inputdos,\n    '345.12' as snowoutputdos,\n    'NULL' as snowoutputdosb,\n    {{try_to_number('inputdos', \"$999.00\")}} as dbxoutputdos,\n    {{try_to_number('inputdos', 5, 2)}} as dbxoutputdosb\n\n\n\n)\n\nselect *\nfrom test\nwhere (snowoutputuno <> dbxoutputuno or snowoutputunoa <> dbxoutputunoa\n\tor snowoutputdos <> dbxoutputdos)", "language": "sql", "refs": [], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.try_to_number"], "nodes": []}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/asset_try_to_number.sql", "compiled": true, "compiled_code": "with test as (\n    \n    select\n    '345.123' as inputuno,\n    '345' as snowoutputuno,\n    \n\n\n\n\ntry_cast(inputuno as decimal(38, 0))\n\n\t\n\n as dbxoutputuno,\n    '345.12' as snowoutputunoa,\n    'NULL' as snowoutputunob,\n    \n\n\n\n\ntry_cast(inputuno as decimal(10, 2))\n\n\n\t\n\n as dbxoutputunoa ,\n    \n\n\n\n\ntry_cast(inputuno as decimal(4, 2))\n\n\n\t\n\n as dbxoutputunob ,\n    '$345.12' as inputdos,\n    '345.12' as snowoutputdos,\n    'NULL' as snowoutputdosb,\n    \n\n\n\n\ntry_to_number(inputdos, \"$999.00\")\n\n\n\t\n\n as dbxoutputdos,\n    \n\n\n\n\ntry_cast(inputdos as decimal(5, 2))\n\n\n\t\n\n as dbxoutputdosb\n\n\n\n)\n\nselect *\nfrom test\nwhere (snowoutputuno <> dbxoutputuno or snowoutputunoa <> dbxoutputunoa\n\tor snowoutputdos <> dbxoutputdos)", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.assert_dayofweekiso": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "assert_dayofweekiso", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "assert_dayofweekiso.sql", "original_file_path": "tests/assert_dayofweekiso.sql", "unique_id": "test.springbricks_integration_tests.assert_dayofweekiso", "fqn": ["springbricks_integration_tests", "assert_dayofweekiso"], "alias": "assert_dayofweekiso", "checksum": {"name": "sha256", "checksum": "556d9004ef330cbe0efd512c796baa2f21a91ae609e0886a33aa43773d9d5aa3"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.522167, "relation_name": null, "raw_code": "with testraw as (\n    \n    select\n    input,\n    expected_output,\n    to_date(input,'d/M/yyyy[ H:m]') as input_formatted\n   \nfrom {{ ref('springbrickstests')}}\nwhere function_name = 'dayofweekiso'\n),\n\ntest as (\nselect input,\nexpected_output,\n{{dayofweekiso('input_formatted')}} as actual_output\nfrom testraw\n\n)\n\nselect *\nfrom test\nwhere expected_output <> actual_output", "language": "sql", "refs": [{"name": "springbrickstests", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.dayofweekiso"], "nodes": ["seed.springbricks_integration_tests.springbrickstests"]}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/assert_dayofweekiso.sql", "compiled": true, "compiled_code": "with testraw as (\n    \n    select\n    input,\n    expected_output,\n    to_date(input,'d/M/yyyy[ H:m]') as input_formatted\n   \nfrom `hive_metastore`.`robertocircle`.`springbrickstests`\nwhere function_name = 'dayofweekiso'\n),\n\ntest as (\nselect input,\nexpected_output,\n\n    EXTRACT(DAYOFWEEK_ISO FROM input_formatted)\n as actual_output\nfrom testraw\n\n)\n\nselect *\nfrom test\nwhere expected_output <> actual_output", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.assert_listaggdistinct": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "assert_listaggdistinct", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "assert_listaggdistinct.sql", "original_file_path": "tests/assert_listaggdistinct.sql", "unique_id": "test.springbricks_integration_tests.assert_listaggdistinct", "fqn": ["springbricks_integration_tests", "assert_listaggdistinct"], "alias": "assert_listaggdistinct", "checksum": {"name": "sha256", "checksum": "2e9644eb141a73bd2cfe5aa32eb709b6abe23c89e7f1a505d785a2c8ccb47fc4"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.52956, "relation_name": null, "raw_code": "with parse as (\n\nSELECT inputdos FROM VALUES ('F'), ('O'), ('F'), ('O') AS (inputdos)\n\n),\n\n\n test as (\n    \n    select\n\n\n    \"F|O\" as snowoutputdos,\n    \n    {{listagg('distinct inputdos','|')}} as dbxoutputdos\n    from parse\ngroup by 1\n     \n)\n\nselect *\nfrom test\nwhere snowoutputdos <> dbxoutputdos", "language": "sql", "refs": [], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.listagg"], "nodes": []}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/assert_listaggdistinct.sql", "compiled": true, "compiled_code": "with parse as (\n\nSELECT inputdos FROM VALUES ('F'), ('O'), ('F'), ('O') AS (inputdos)\n\n),\n\n\n test as (\n    \n    select\n\n\n    \"F|O\" as snowoutputdos,\n    \n    \n   array_join(sort_array(collect_list(distinct inputdos)), \"|\")\n  \n as dbxoutputdos\n    from parse\ngroup by 1\n     \n)\n\nselect *\nfrom test\nwhere snowoutputdos <> dbxoutputdos", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.timediff": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "timediff", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "timediff.sql", "original_file_path": "tests/timediff.sql", "unique_id": "test.springbricks_integration_tests.timediff", "fqn": ["springbricks_integration_tests", "timediff"], "alias": "timediff", "checksum": {"name": "sha256", "checksum": "160902504e41b480d2ff33578a6538d8df5f479aab511e98015fda09665d6220"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.535653, "relation_name": null, "raw_code": "with testraw as (\n    \n    select\n    input,\n    expected_output,\n    input:col1 as unit,\n    input:col2 as timeuno,\n    input:col3 as timedos\n   \nfrom {{ ref('springbrickstests')}}\nwhere function_name = 'timediff'\n),\n\ntest as (\nselect input,\nexpected_output,\n{{timediff('unit', 'timeuno', 'timedos')}} as actual_output\nfrom testraw\n\n)\n\nselect *\nfrom test\nwhere expected_output <> actual_output", "language": "sql", "refs": [{"name": "springbrickstests", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.timediff"], "nodes": ["seed.springbricks_integration_tests.springbrickstests"]}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/timediff.sql", "compiled": true, "compiled_code": "with testraw as (\n    \n    select\n    input,\n    expected_output,\n    input:col1 as unit,\n    input:col2 as timeuno,\n    input:col3 as timedos\n   \nfrom `hive_metastore`.`robertocircle`.`springbrickstests`\nwhere function_name = 'timediff'\n),\n\ntest as (\nselect input,\nexpected_output,\n\n  CASE \n  WHEN lower(unit) = 'year'   THEN EXTRACT(YEAR FROM timedos) - EXTRACT(YEAR FROM timeuno)\n  WHEN lower(unit) = 'month'  THEN (EXTRACT(YEAR FROM timedos) * 12 + EXTRACT(MONTH FROM timedos))\n                          - (EXTRACT(YEAR FROM timeuno) * 12 + EXTRACT(MONTH FROM timeuno))\n  WHEN lower(unit) = 'day'    THEN datediff(CAST(timedos AS DATE), CAST(timeuno AS DATE))\n  WHEN lower(unit) = 'hour'   THEN EXTRACT(HOUR FROM timedos) - EXTRACT(HOUR FROM timeuno)\n  WHEN lower(unit) = 'minute' THEN (EXTRACT(HOUR FROM timedos) * 60 + EXTRACT(MINUTE FROM timedos))\n                          - (EXTRACT(HOURs FROM timeuno) * 60 + EXTRACT(MINUTE FROM timeuno))\n  WHEN lower(unit) = 'second' THEN (EXTRACT(HOUR FROM timedos) * 3600 + EXTRACT(MINUTE FROM timedos) * 60 + EXTRACT(SECOND FROM timedos))\n                          - (EXTRACT(HOUR FROM timedos) * 3600 + EXTRACT(MINUTE FROM timedos) * 60 + EXTRACT(SECOND FROM timedos))\n  END\n as actual_output\nfrom testraw\n\n)\n\nselect *\nfrom test\nwhere expected_output <> actual_output", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.assert_contains": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "assert_contains", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "assert_contains.sql", "original_file_path": "tests/assert_contains.sql", "unique_id": "test.springbricks_integration_tests.assert_contains", "fqn": ["springbricks_integration_tests", "assert_contains"], "alias": "assert_contains", "checksum": {"name": "sha256", "checksum": "bf7b71635f26331b94068180ac05abc22697873521c09d94f35073f3c88217c8"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.545998, "relation_name": null, "raw_code": "with test as (\n    \n    select\n    input,\n    expected_output,\n    {{contains('input','\"te\"')}} as actual_output\nfrom {{ ref('springbrickstests')}}\nwhere function_name = 'contains'\n)\n\nselect *\nfrom test\nwhere expected_output::boolean <> actual_output", "language": "sql", "refs": [{"name": "springbrickstests", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.contains"], "nodes": ["seed.springbricks_integration_tests.springbrickstests"]}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/assert_contains.sql", "compiled": true, "compiled_code": "with test as (\n    \n    select\n    input,\n    expected_output,\n    \n\ncharindex(\"te\", input) > 0 \n\n as actual_output\nfrom `hive_metastore`.`robertocircle`.`springbrickstests`\nwhere function_name = 'contains'\n)\n\nselect *\nfrom test\nwhere expected_output::boolean <> actual_output", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.assert_json_extract_path_text": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "assert_json_extract_path_text", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "assert_json_extract_path_text.sql", "original_file_path": "tests/assert_json_extract_path_text.sql", "unique_id": "test.springbricks_integration_tests.assert_json_extract_path_text", "fqn": ["springbricks_integration_tests", "assert_json_extract_path_text"], "alias": "assert_json_extract_path_text", "checksum": {"name": "sha256", "checksum": "80531c23bbb307910d6c3b215138b61513061ad7a88c8d6821222b5153b43da8"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.553874, "relation_name": null, "raw_code": "with testraw as (\n    \n    select\n    input,\n    expected_output\n   \nfrom {{ ref('springbrickstests')}}\nwhere function_name = 'json_extract_path_text'\n),\n\ntest as (\nselect input,\nexpected_output,\n{{json_extract_path_text('input','col1')}} as actual_output\nfrom testraw\n\n)\n\nselect *\nfrom test\nwhere expected_output <> actual_output", "language": "sql", "refs": [{"name": "springbrickstests", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.json_extract_path_text"], "nodes": ["seed.springbricks_integration_tests.springbrickstests"]}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/assert_json_extract_path_text.sql", "compiled": true, "compiled_code": "with testraw as (\n    \n    select\n    input,\n    expected_output\n   \nfrom `hive_metastore`.`robertocircle`.`springbrickstests`\nwhere function_name = 'json_extract_path_text'\n),\n\ntest as (\nselect input,\nexpected_output,\n\n    get_json_object(input, '$.col1') \n as actual_output\nfrom testraw\n\n)\n\nselect *\nfrom test\nwhere expected_output <> actual_output", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.asset_to_number": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "asset_to_number", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "asset_to_number.sql", "original_file_path": "tests/asset_to_number.sql", "unique_id": "test.springbricks_integration_tests.asset_to_number", "fqn": ["springbricks_integration_tests", "asset_to_number"], "alias": "asset_to_number", "checksum": {"name": "sha256", "checksum": "4d69713dd2b0083f9c7e38f27e8c146f22fcd8e884bdeb87e1478cddf7f125e0"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.561867, "relation_name": null, "raw_code": "with test as (\n    \n    select\n    '12.3456' as inputuno,\n    '12' as snowoutputuno,\n    {{to_number('inputuno')}} as dbxoutputuno,\n    '12.3' as snowoutputunoa,\n    '12.3456' as snowoutputunob,\n    {{to_number('inputuno', 10, 1)}} as dbxoutputunoa ,\n    {{to_number('inputuno', 10, 8)}} as dbxoutputunob ,\n    '98.76546' as inputdos,\n    '99' as snowoutputdos,\n    '98.8' as snowoutputdosa,\n    '98.76546' as snowoutputdosb,\n    {{to_number('inputdos')}} as dbxoutputdos,\n    {{to_number('inputdos', 10, 1)}} as dbxoutputdosa,\n    {{to_number('inputdos', 10, 8)}} as dbxoutputdosb,\n    '12.3' as inputtres,\n    '12.3' as snowoutputtres,\n    '12.3' as snowoutputtresa,\n    '12.3' as snowoutputtresb,\n    {{to_number('inputtres', '99.9')}} as dbxoutputtres,\n    {{to_number('inputtres', '99.9', 9, 5)}} as dbxoutputtresa,\n    {{to_number('inputtres', 'TM9', 9, 5)}} as dbxoutputtresb\n\n\n\n)\n\nselect *\nfrom test\nwhere (snowoutputuno <> dbxoutputuno or snowoutputunoa <> dbxoutputunoa or snowoutputunob <> dbxoutputunob\n\tor snowoutputdos <> dbxoutputdos or snowoutputdosa <> dbxoutputdosa or snowoutputdosb <> dbxoutputdosb\n\tor snowoutputtres <> dbxoutputtres or snowoutputtresa <> dbxoutputtresa or snowoutputtresb <> dbxoutputtresb)", "language": "sql", "refs": [], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.to_number"], "nodes": []}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/asset_to_number.sql", "compiled": true, "compiled_code": "with test as (\n    \n    select\n    '12.3456' as inputuno,\n    '12' as snowoutputuno,\n    \n\n\n\n\ncast(inputuno as decimal(38, 0))\n\n\t\n\n as dbxoutputuno,\n    '12.3' as snowoutputunoa,\n    '12.3456' as snowoutputunob,\n    \n\n\n\n\ncast(inputuno as decimal(10, 1))\n\n\n\t\n\n as dbxoutputunoa ,\n    \n\n\n\n\ncast(inputuno as decimal(10, 8))\n\n\n\t\n\n as dbxoutputunob ,\n    '98.76546' as inputdos,\n    '99' as snowoutputdos,\n    '98.8' as snowoutputdosa,\n    '98.76546' as snowoutputdosb,\n    \n\n\n\n\ncast(inputdos as decimal(38, 0))\n\n\t\n\n as dbxoutputdos,\n    \n\n\n\n\ncast(inputdos as decimal(10, 1))\n\n\n\t\n\n as dbxoutputdosa,\n    \n\n\n\n\ncast(inputdos as decimal(10, 8))\n\n\n\t\n\n as dbxoutputdosb,\n    '12.3' as inputtres,\n    '12.3' as snowoutputtres,\n    '12.3' as snowoutputtresa,\n    '12.3' as snowoutputtresb,\n    \n\n\n\n\nto_number(inputtres, \"99.9\")\n\n\n\t\n\n as dbxoutputtres,\n    \n\n\n\n\n\n\n\ncast(inputtres as decimal(9, 5))\n\n\n\t\n\n as dbxoutputtresa,\n    \n\n\n\n\n\n\n\ncast(inputtres as decimal(9, 5))\n\n\n\t\n\n as dbxoutputtresb\n\n\n\n)\n\nselect *\nfrom test\nwhere (snowoutputuno <> dbxoutputuno or snowoutputunoa <> dbxoutputunoa or snowoutputunob <> dbxoutputunob\n\tor snowoutputdos <> dbxoutputdos or snowoutputdosa <> dbxoutputdosa or snowoutputdosb <> dbxoutputdosb\n\tor snowoutputtres <> dbxoutputtres or snowoutputtresa <> dbxoutputtresa or snowoutputtresb <> dbxoutputtresb)", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "test.springbricks_integration_tests.assert_monthname": {"database": "hive_metastore", "schema": "robertocircle_dbt_test__audit", "name": "assert_monthname", "resource_type": "test", "package_name": "springbricks_integration_tests", "path": "assert_monthname.sql", "original_file_path": "tests/assert_monthname.sql", "unique_id": "test.springbricks_integration_tests.assert_monthname", "fqn": ["springbricks_integration_tests", "assert_monthname"], "alias": "assert_monthname", "checksum": {"name": "sha256", "checksum": "8b62413102421a12decd948dd39c69fea8caa27f098e28026041786343d100c8"}, "config": {"enabled": true, "alias": null, "schema": "dbt_test__audit", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "test", "severity": "ERROR", "store_failures": null, "where": null, "limit": null, "fail_calc": "count(*)", "warn_if": "!= 0", "error_if": "!= 0"}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.576343, "relation_name": null, "raw_code": "with testraw as (\n    \n    select\n    input,\n    expected_output,\n    to_date(input,'d/M/yyyy[ H:m]') as input_formatted\n\nfrom {{ ref('springbrickstests')}}\nwhere function_name = 'monthname'\n),\n\ntest as (\nselect input,\nexpected_output,\n{{monthname('input_formatted')}} as actual_output\nfrom testraw\n\n)\n\nselect *\nfrom test\nwhere expected_output <> actual_output", "language": "sql", "refs": [{"name": "springbrickstests", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.springbricks_integration_tests.monthname"], "nodes": ["seed.springbricks_integration_tests.springbrickstests"]}, "compiled_path": "target/compiled/springbricks_integration_tests/tests/assert_monthname.sql", "compiled": true, "compiled_code": "with testraw as (\n    \n    select\n    input,\n    expected_output,\n    to_date(input,'d/M/yyyy[ H:m]') as input_formatted\n\nfrom `hive_metastore`.`robertocircle`.`springbrickstests`\nwhere function_name = 'monthname'\n),\n\ntest as (\nselect input,\nexpected_output,\n\n     CASE \n         WHEN EXTRACT(MONTH FROM input_formatted) = 1 THEN 'Jan'\n         WHEN EXTRACT(MONTH FROM input_formatted) = 2 THEN 'Feb'\n         WHEN EXTRACT(MONTH FROM input_formatted) = 3 THEN 'Mar'\n         WHEN EXTRACT(MONTH FROM input_formatted) = 4 THEN 'Apr'\n         WHEN EXTRACT(MONTH FROM input_formatted) = 5 THEN 'May'\n         WHEN EXTRACT(MONTH FROM input_formatted) = 6 THEN 'Jun'\n         WHEN EXTRACT(MONTH FROM input_formatted) = 7 THEN 'Jul'\n         WHEN EXTRACT(MONTH FROM input_formatted) = 8 THEN 'Aug'\n         WHEN EXTRACT(MONTH FROM input_formatted) = 9 THEN 'Sep'\n         WHEN EXTRACT(MONTH FROM input_formatted) = 10 THEN 'Oct'\n         WHEN EXTRACT(MONTH FROM input_formatted) = 11 THEN 'Nov'\n         ELSE 'Dec' END\n as actual_output\nfrom testraw\n\n)\n\nselect *\nfrom test\nwhere expected_output <> actual_output", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "checksum": null}}, "seed.springbricks_integration_tests.springbrickstests": {"database": "hive_metastore", "schema": "robertocircle", "name": "springbrickstests", "resource_type": "seed", "package_name": "springbricks_integration_tests", "path": "springbrickstests.csv", "original_file_path": "seeds/springbrickstests.csv", "unique_id": "seed.springbricks_integration_tests.springbrickstests", "fqn": ["springbricks_integration_tests", "springbrickstests"], "alias": "springbrickstests", "checksum": {"name": "sha256", "checksum": "fa5d993ebbcf4f6f297465ad629418698401ec9b980d478afa88f062480a1e84"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "seed", "incremental_strategy": null, "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false}, "quote_columns": null, "post-hook": [], "pre-hook": []}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "deferred": false, "unrendered_config": {}, "created_at": 1690405244.6067772, "relation_name": "`hive_metastore`.`robertocircle`.`springbrickstests`", "raw_code": "", "root_path": "/Users/roberto.salcido/Desktop/springbricks-gendocs/integration_tests", "depends_on": {"macros": []}}}, "sources": {}, "macros": {"macro.springbricks_integration_tests.array_size": {"name": "array_size", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/array_size.sql", "original_file_path": "macros/array_size.sql", "unique_id": "macro.springbricks_integration_tests.array_size", "macro_sql": "{% macro array_size(column_name) %}\n    size({{column_name}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.653315, "supported_languages": null}, "macro.springbricks_integration_tests.div0": {"name": "div0", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/div0.sql", "original_file_path": "macros/div0.sql", "unique_id": "macro.springbricks_integration_tests.div0", "macro_sql": "{% macro div0(arg1, arg2) %}\n   CASE WHEN {{arg2}} = 0 THEN 0 ELSE {{arg1}} / {{arg2}} END;\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.6540082, "supported_languages": null}, "macro.springbricks_integration_tests.seq4": {"name": "seq4", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/seq4.sql", "original_file_path": "macros/seq4.sql", "unique_id": "macro.springbricks_integration_tests.seq4", "macro_sql": "{% macro seq4() %}\n    monotonically_increasing_id()\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.6543748, "supported_languages": null}, "macro.springbricks_integration_tests.to_number": {"name": "to_number", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/to_number.sql", "original_file_path": "macros/to_number.sql", "unique_id": "macro.springbricks_integration_tests.to_number", "macro_sql": "{% macro to_number(expr, format, precision, scale) %}\n\n\n{% if scale %}\n\n\n\n\ncast({{expr}} as decimal({{precision}}, {{scale}}))\n\n\n{% elif precision %}\n\ncast({{expr}} as decimal({{format}}, {{precision}}))\n\n\n{% elif format %}\n\nto_number({{expr}}, \"{{format}}\")\n\n\n{% else %}\n\ncast({{expr}} as decimal(38, 0))\n\n{% endif %}\t\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.6561558, "supported_languages": null}, "macro.springbricks_integration_tests.yearofweekiso": {"name": "yearofweekiso", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/yearofweekiso.sql", "original_file_path": "macros/yearofweekiso.sql", "unique_id": "macro.springbricks_integration_tests.yearofweekiso", "macro_sql": "{% macro yearofweekiso(arg) %}\n    extract(year from {{arg}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.656638, "supported_languages": null}, "macro.springbricks_integration_tests.try_to_decimal": {"name": "try_to_decimal", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/try_to_decimal.sql", "original_file_path": "macros/try_to_decimal.sql", "unique_id": "macro.springbricks_integration_tests.try_to_decimal", "macro_sql": "{% macro try_to_decimal(expr, format, precision, scale) %}\n\n\n{% if scale %}\n\n\n\n\ntry_cast({{expr}} as decimal({{precision}}, {{scale}}))\n\n\n{% elif precision %}\n\ntry_cast({{expr}} as decimal({{format}}, {{precision}}))\n\n\n{% elif format %}\n\ntry_to_number({{expr}}, \"{{format}}\")\n\n\n{% else %}\n\ntry_cast({{expr}} as decimal(38, 0))\n\n{% endif %}\t\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.6584802, "supported_languages": null}, "macro.springbricks_integration_tests.timestampadd": {"name": "timestampadd", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/timestampadd.sql", "original_file_path": "macros/timestampadd.sql", "unique_id": "macro.springbricks_integration_tests.timestampadd", "macro_sql": "{% macro timestampadd(unit, measure, base) %}\nCASE \n  WHEN lower({{unit}}) = 'year'   THEN {{base}} + make_interval({{measure}})\n  WHEN lower({{unit}}) = 'month'  THEN {{base}} + make_interval(0, {{measure}})\n  WHEN lower({{unit}}) = 'day'    THEN {{base}} + make_interval(0, 0, 0, {{measure}})\n  WHEN lower({{unit}}) = 'hour'   THEN {{base}} + make_interval(0, 0, 0, 0, {{measure}})\n  WHEN lower({{unit}}) = 'minute' THEN {{base}} + make_interval(0, 0, 0, 0, 0, {{measure}})\n  WHEN lower({{unit}}) = 'second' THEN {{base}} + make_interval(0, 0, 0, 0, 0, 0, {{measure}})\n  END\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.660712, "supported_languages": null}, "macro.springbricks_integration_tests.date_from_parts": {"name": "date_from_parts", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/date_from_parts.sql", "original_file_path": "macros/date_from_parts.sql", "unique_id": "macro.springbricks_integration_tests.date_from_parts", "macro_sql": "{% macro date_from_parts(year, month, day) %}\n    make_date({{year}}, {{month}}, {{day}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.66138, "supported_languages": null}, "macro.springbricks_integration_tests.to_numeric": {"name": "to_numeric", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/to_numeric.sql", "original_file_path": "macros/to_numeric.sql", "unique_id": "macro.springbricks_integration_tests.to_numeric", "macro_sql": "{% macro to_numeric(expr, format, precision, scale) %}\n\n\n{% if scale %}\n\n\n\n\ncast({{expr}} as decimal({{precision}}, {{scale}}))\n\n\n{% elif precision %}\n\ncast({{expr}} as decimal({{format}}, {{precision}}))\n\n\n{% elif format %}\n\nto_number({{expr}}, \"{{format}}\")\n\n\n{% else %}\n\ncast({{expr}} as decimal(38, 0))\n\n{% endif %}\t\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.6630971, "supported_languages": null}, "macro.springbricks_integration_tests.sysdate": {"name": "sysdate", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/sysdate.sql", "original_file_path": "macros/sysdate.sql", "unique_id": "macro.springbricks_integration_tests.sysdate", "macro_sql": "{% macro sysdate() %}\n   to_utc_timestamp(current_timestamp(), current_timezone());\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.6634738, "supported_languages": null}, "macro.springbricks_integration_tests.seq2": {"name": "seq2", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/seq2.sql", "original_file_path": "macros/seq2.sql", "unique_id": "macro.springbricks_integration_tests.seq2", "macro_sql": "{% macro seq2(arg) %}\n    monotonically_increasing_id()\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.663852, "supported_languages": null}, "macro.springbricks_integration_tests.timestamp_from_parts": {"name": "timestamp_from_parts", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/timestamp_from_parts.sql", "original_file_path": "macros/timestamp_from_parts.sql", "unique_id": "macro.springbricks_integration_tests.timestamp_from_parts", "macro_sql": "{% macro timestamp_from_parts(year, month, day, hour, minute, second) %}\n   make_timestamp({{year}}, {{month}}, {{day}}, {{hour}}, {{minute}}, {{second}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.664831, "supported_languages": null}, "macro.springbricks_integration_tests.array_intersection": {"name": "array_intersection", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/array_intersection.sql", "original_file_path": "macros/array_intersection.sql", "unique_id": "macro.springbricks_integration_tests.array_intersection", "macro_sql": "{% macro array_intersection(arg1, arg2) %}\n    array_intersect({{arg1}}, {{arg2}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.6654022, "supported_languages": null}, "macro.springbricks_integration_tests.yearofweek": {"name": "yearofweek", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/yearofweek.sql", "original_file_path": "macros/yearofweek.sql", "unique_id": "macro.springbricks_integration_tests.yearofweek", "macro_sql": "{% macro yearofweek(arg) %}\n    extract(year from {{arg}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.665903, "supported_languages": null}, "macro.springbricks_integration_tests.startswith": {"name": "startswith", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/startswith.sql", "original_file_path": "macros/startswith.sql", "unique_id": "macro.springbricks_integration_tests.startswith", "macro_sql": "{% macro startswith(arg1, arg2) %}\n    position({{arg2}}, {{arg1}}) = 1\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.66648, "supported_languages": null}, "macro.springbricks_integration_tests.seq1": {"name": "seq1", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/seq1.sql", "original_file_path": "macros/seq1.sql", "unique_id": "macro.springbricks_integration_tests.seq1", "macro_sql": "{% macro seq1() %}\n    monotonically_increasing_id()\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.666841, "supported_languages": null}, "macro.springbricks_integration_tests.sha1hex": {"name": "sha1hex", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/sha1hex.sql", "original_file_path": "macros/sha1hex.sql", "unique_id": "macro.springbricks_integration_tests.sha1hex", "macro_sql": "{% macro sha1hex(arg, len) %}\n    sha1({{arg}}, {{len}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.66741, "supported_languages": null}, "macro.springbricks_integration_tests.previous_day": {"name": "previous_day", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/previous_day.sql", "original_file_path": "macros/previous_day.sql", "unique_id": "macro.springbricks_integration_tests.previous_day", "macro_sql": "{% macro previous_day(arg, day) %}\n    CASE WHEN substr(dayname({{arg}}), 1, 2) = substr({{day}}, 1, 2) THEN {{arg}} - INTERVAL 7 DAY\n              ELSE next_day({{arg}}, {{day}}) - INTERVAL 7 DAY END;\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.6682692, "supported_languages": null}, "macro.springbricks_integration_tests.try_to_numeric": {"name": "try_to_numeric", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/try_to_numeric.sql", "original_file_path": "macros/try_to_numeric.sql", "unique_id": "macro.springbricks_integration_tests.try_to_numeric", "macro_sql": "{% macro try_to_numeric(expr, format, precision, scale) %}\n\n\n{% if scale %}\n\n\n\n\ntry_cast({{expr}} as decimal({{precision}}, {{scale}}))\n\n\n{% elif precision %}\n\ntry_cast({{expr}} as decimal({{format}}, {{precision}}))\n\n\n{% elif format %}\n\ntry_to_number({{expr}}, \"{{format}}\")\n\n\n{% else %}\n\ntry_cast({{expr}} as decimal(38, 0))\n\n{% endif %}\t\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.670023, "supported_languages": null}, "macro.springbricks_integration_tests.endswith": {"name": "endswith", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/endswith.sql", "original_file_path": "macros/endswith.sql", "unique_id": "macro.springbricks_integration_tests.endswith", "macro_sql": "{% macro endswith(arg1, arg2) %}\n    substr({{arg1}}, -length({{arg2}}), length({{arg2}})) = {{arg2}};\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.67084, "supported_languages": null}, "macro.springbricks_integration_tests.equal_null": {"name": "equal_null", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/equal_null.sql", "original_file_path": "macros/equal_null.sql", "unique_id": "macro.springbricks_integration_tests.equal_null", "macro_sql": "{% macro equal_null(arg1, arg2) %}\n    {{arg1}} <=> {{arg2}}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.671435, "supported_languages": null}, "macro.springbricks_integration_tests.try_cast": {"name": "try_cast", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/try_cast.sql", "original_file_path": "macros/try_cast.sql", "unique_id": "macro.springbricks_integration_tests.try_cast", "macro_sql": "{% macro try_cast(column_name, precision=2) %}\n    cast({{column_name}} as string)\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.671992, "supported_languages": null}, "macro.springbricks_integration_tests.array_to_string": {"name": "array_to_string", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/array_to_string.sql", "original_file_path": "macros/array_to_string.sql", "unique_id": "macro.springbricks_integration_tests.array_to_string", "macro_sql": "{% macro array_to_string(arg, delim) %}\n    array_join({{arg}}, {{delim}}, null)\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.672601, "supported_languages": null}, "macro.springbricks_integration_tests.exclude": {"name": "exclude", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/exclude.sql", "original_file_path": "macros/exclude.sql", "unique_id": "macro.springbricks_integration_tests.exclude", "macro_sql": "{%- macro exclude() -%}\n\n  {%- set all_args = [] -%}\n    {% for col in kwargs.items() -%}\n      {%- do all_args.append(col) -%}\n    {%- endfor -%}\n  \n  \n  except({{ all_args|join(', ') }})\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.6754181, "supported_languages": null}, "macro.springbricks_integration_tests.timestampdiff": {"name": "timestampdiff", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/timestampdiff.sql", "original_file_path": "macros/timestampdiff.sql", "unique_id": "macro.springbricks_integration_tests.timestampdiff", "macro_sql": "{% macro timestampdiff(unit, arg1,arg2) %}\n  CASE \n  WHEN lower({{unit}}) = 'year'   THEN EXTRACT(YEAR FROM {{arg2}}) - EXTRACT(YEAR FROM {{arg1}})\n  WHEN lower({{unit}}) = 'month'  THEN (EXTRACT(YEAR FROM {{arg2}}) * 12 + EXTRACT(MONTH FROM {{arg2}}))\n                          - (EXTRACT(YEAR FROM {{arg1}}) * 12 + EXTRACT(MONTH FROM {{arg1}}))\n  WHEN lower({{unit}}) = 'day'    THEN datediff(CAST({{arg2}} AS DATE), CAST({{arg1}} AS DATE))\n  WHEN lower({{unit}}) = 'hour'   THEN EXTRACT(HOUR FROM {{arg2}}) - EXTRACT(HOUR FROM {{arg1}})\n  WHEN lower({{unit}}) = 'minute' THEN (EXTRACT(HOUR FROM {{arg2}}) * 60 + EXTRACT(MINUTE FROM {{arg2}}))\n                          - (EXTRACT(HOUR FROM {{arg1}}) * 60 + EXTRACT(MINUTE FROM {{arg1}}))\n  WHEN lower({{unit}}) = 'second' THEN (EXTRACT(HOUR FROM {{arg2}}) * 3600 + EXTRACT(MINUTE FROM {{arg2}}) * 60 + EXTRACT(SECOND FROM {{arg2}}))\n                          - (EXTRACT(HOUR FROM {{arg2}}) * 3600 + EXTRACT(MINUTE FROM {{arg2}}) * 60 + EXTRACT(SECOND FROM {{arg2}}))\n  END\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.679779, "supported_languages": null}, "macro.springbricks_integration_tests.contains": {"name": "contains", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/contains.sql", "original_file_path": "macros/contains.sql", "unique_id": "macro.springbricks_integration_tests.contains", "macro_sql": "{% macro contains(column_name, position) %}\n\ncharindex({{position}}, {{column_name}}) > 0 \n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.6803782, "supported_languages": null}, "macro.springbricks_integration_tests.bitand": {"name": "bitand", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/bitand.sql", "original_file_path": "macros/bitand.sql", "unique_id": "macro.springbricks_integration_tests.bitand", "macro_sql": "{% macro bitand(arg1, arg2) %}\n   {{arg1}} & {{arg2}}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.680934, "supported_languages": null}, "macro.springbricks_integration_tests.square": {"name": "square", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/square.sql", "original_file_path": "macros/square.sql", "unique_id": "macro.springbricks_integration_tests.square", "macro_sql": "{% macro square(arg) %}\n    {{arg}} * {{arg}}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.681451, "supported_languages": null}, "macro.springbricks_integration_tests.uniform": {"name": "uniform", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/uniform.sql", "original_file_path": "macros/uniform.sql", "unique_id": "macro.springbricks_integration_tests.uniform", "macro_sql": "{% macro uniform(min, max, double) %}\n    {{min}} + ({{max}} - {{min}}) * {{rand}}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.6821692, "supported_languages": null}, "macro.springbricks_integration_tests.to_time": {"name": "to_time", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/to_time.sql", "original_file_path": "macros/to_time.sql", "unique_id": "macro.springbricks_integration_tests.to_time", "macro_sql": "{% macro to_time(expr) %}\n  to_timestamp(expr, 'HH:mm:ss')\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.6825511, "supported_languages": null}, "macro.springbricks_integration_tests.getdate": {"name": "getdate", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/getdate.sql", "original_file_path": "macros/getdate.sql", "unique_id": "macro.springbricks_integration_tests.getdate", "macro_sql": "{% macro getdate() %}\n    current_timestamp()\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.682901, "supported_languages": null}, "macro.springbricks_integration_tests.parse_json": {"name": "parse_json", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/parse_json.sql", "original_file_path": "macros/parse_json.sql", "unique_id": "macro.springbricks_integration_tests.parse_json", "macro_sql": "{% macro parse_json(string) %}\n from_json({{string}}, schema_of_json({{string}}))\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.683425, "supported_languages": null}, "macro.springbricks_integration_tests.strtok_to_array": {"name": "strtok_to_array", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/strtok_to_array.sql", "original_file_path": "macros/strtok_to_array.sql", "unique_id": "macro.springbricks_integration_tests.strtok_to_array", "macro_sql": "{% macro strtok_to_array(arg, delim) %}\n    split({{arg}}, concat(\"[\", {{delim}}, \"]\"))\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.683986, "supported_languages": null}, "macro.springbricks_integration_tests.to_decimal": {"name": "to_decimal", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/to_decimal.sql", "original_file_path": "macros/to_decimal.sql", "unique_id": "macro.springbricks_integration_tests.to_decimal", "macro_sql": "{% macro to_decimal(expr, format, precision, scale) %}\n\n\n{% if scale %}\n\n\n\n\ncast({{expr}} as decimal({{precision}}, {{scale}}))\n\n\n{% elif precision %}\n\ncast({{expr}} as decimal({{format}}, {{precision}}))\n\n\n{% elif format %}\n\nto_number({{expr}}, \"{{format}}\")\n\n\n{% else %}\n\ncast({{expr}} as decimal(38, 0))\n\n{% endif %}\t\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.685693, "supported_languages": null}, "macro.springbricks_integration_tests.hex_decode_string": {"name": "hex_decode_string", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/hex_decode_string.sql", "original_file_path": "macros/hex_decode_string.sql", "unique_id": "macro.springbricks_integration_tests.hex_decode_string", "macro_sql": "{% macro hex_decode_string(arg1) %}\n    decode(unhex({{arg1}}), 'UTF-8')\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.6862211, "supported_languages": null}, "macro.springbricks_integration_tests.weekiso": {"name": "weekiso", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/weekiso.sql", "original_file_path": "macros/weekiso.sql", "unique_id": "macro.springbricks_integration_tests.weekiso", "macro_sql": "{% macro weekiso(arg) %}\n    extract (week from {{arg}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.686686, "supported_languages": null}, "macro.springbricks_integration_tests.to_boolean": {"name": "to_boolean", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/to_boolean.sql", "original_file_path": "macros/to_boolean.sql", "unique_id": "macro.springbricks_integration_tests.to_boolean", "macro_sql": "{% macro to_boolean(arg) %}\n CASE \nWHEN lower({{arg}}) = 'false' THEN FALSE\nWHEN lower({{arg}}) = 'f' THEN FALSE\nWHEN lower({{arg}}) =  'no' THEN FALSE\nWHEN lower({{arg}}) = 'n' THEN FALSE\nWHEN lower({{arg}}) = 'off' THEN FALSE\nWHEN lower({{arg}}) = '0' THEN FALSE\nWHEN lower({{arg}}) = 'true' THEN TRUE\nWHEN lower({{arg}}) = 't' THEN TRUE\nWHEN lower({{arg}}) =  'yes' THEN TRUE\nWHEN lower({{arg}}) = 'y' THEN TRUE\nWHEN lower({{arg}}) = 'on' THEN TRUE\nWHEN lower({{arg}}) = '1' THEN TRUE\n\nELSE NULL\nEND\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.688258, "supported_languages": null}, "macro.springbricks_integration_tests.listagg": {"name": "listagg", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/listagg.sql", "original_file_path": "macros/listagg.sql", "unique_id": "macro.springbricks_integration_tests.listagg", "macro_sql": "{% macro listagg(arg, delim) %}\n   array_join(sort_array(collect_list({{arg}})), \"{{delim}}\")\n  \n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.688842, "supported_languages": null}, "macro.springbricks_integration_tests.insert": {"name": "insert", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/insert.sql", "original_file_path": "macros/insert.sql", "unique_id": "macro.springbricks_integration_tests.insert", "macro_sql": "{% macro insert(base, pos, len, ins) %}\n   overlay({{base}}, {{ins}}, {{pos}}, {{len}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.6896052, "supported_languages": null}, "macro.springbricks_integration_tests.dbt_housekeeping": {"name": "dbt_housekeeping", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/dbt_housekeeping.sql", "original_file_path": "macros/dbt_housekeeping.sql", "unique_id": "macro.springbricks_integration_tests.dbt_housekeeping", "macro_sql": "{% macro dbt_housekeeping() -%}\n    '{{ invocation_id }}'::string as dbt_batch_id,\n    '{{ run_started_at }}'::timestamp as dbt_batch_ts\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.6901572, "supported_languages": null}, "macro.springbricks_integration_tests.systimestamp": {"name": "systimestamp", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/systimestamp.sql", "original_file_path": "macros/systimestamp.sql", "unique_id": "macro.springbricks_integration_tests.systimestamp", "macro_sql": "{% macro systimestamp() %}\n    current_timestamp()\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.690521, "supported_languages": null}, "macro.springbricks_integration_tests.base64_encode": {"name": "base64_encode", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/base64_encode.sql", "original_file_path": "macros/base64_encode.sql", "unique_id": "macro.springbricks_integration_tests.base64_encode", "macro_sql": "{% macro base64_encode(arg) %}\n    base64({{arg}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.690978, "supported_languages": null}, "macro.springbricks_integration_tests.to_char": {"name": "to_char", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/to_char.sql", "original_file_path": "macros/to_char.sql", "unique_id": "macro.springbricks_integration_tests.to_char", "macro_sql": "{% macro to_char(arg) %}\n    cast({{arg}} as string)\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.691457, "supported_languages": null}, "macro.springbricks_integration_tests.to_binary": {"name": "to_binary", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/to_binary.sql", "original_file_path": "macros/to_binary.sql", "unique_id": "macro.springbricks_integration_tests.to_binary", "macro_sql": "{% macro to_binary(arg) %}\n    unhex({{arg}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.6919942, "supported_languages": null}, "macro.springbricks_integration_tests.from_utc_timestamp": {"name": "from_utc_timestamp", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/from_utc_timestamp.sql", "original_file_path": "macros/from_utc_timestamp.sql", "unique_id": "macro.springbricks_integration_tests.from_utc_timestamp", "macro_sql": "{% macro from_utc_timestamp(source, target, stamp) %}\n    from_utc_timestamp(to_utc_timestamp({{stamp}}, {{source}}), {{target}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.6927092, "supported_languages": null}, "macro.springbricks_integration_tests.week": {"name": "week", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/week.sql", "original_file_path": "macros/week.sql", "unique_id": "macro.springbricks_integration_tests.week", "macro_sql": "{% macro week(stamp) %}\n    EXTRACT(WEEK FROM {{stamp}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.693172, "supported_languages": null}, "macro.springbricks_integration_tests.array_compact": {"name": "array_compact", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/array_compact.sql", "original_file_path": "macros/array_compact.sql", "unique_id": "macro.springbricks_integration_tests.array_compact", "macro_sql": "{% macro array_compact(arg) %}\n  filter({{arg}} , x -> x IS NOT NULL)\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.6936488, "supported_languages": null}, "macro.springbricks_integration_tests.monthname": {"name": "monthname", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/monthname.sql", "original_file_path": "macros/monthname.sql", "unique_id": "macro.springbricks_integration_tests.monthname", "macro_sql": "{% macro monthname(arg) %}\n     CASE \n         WHEN EXTRACT(MONTH FROM {{arg}}) = 1 THEN 'Jan'\n         WHEN EXTRACT(MONTH FROM {{arg}}) = 2 THEN 'Feb'\n         WHEN EXTRACT(MONTH FROM {{arg}}) = 3 THEN 'Mar'\n         WHEN EXTRACT(MONTH FROM {{arg}}) = 4 THEN 'Apr'\n         WHEN EXTRACT(MONTH FROM {{arg}}) = 5 THEN 'May'\n         WHEN EXTRACT(MONTH FROM {{arg}}) = 6 THEN 'Jun'\n         WHEN EXTRACT(MONTH FROM {{arg}}) = 7 THEN 'Jul'\n         WHEN EXTRACT(MONTH FROM {{arg}}) = 8 THEN 'Aug'\n         WHEN EXTRACT(MONTH FROM {{arg}}) = 9 THEN 'Sep'\n         WHEN EXTRACT(MONTH FROM {{arg}}) = 10 THEN 'Oct'\n         WHEN EXTRACT(MONTH FROM {{arg}}) = 11 THEN 'Nov'\n         ELSE 'Dec' END\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.6955462, "supported_languages": null}, "macro.springbricks_integration_tests.to_array": {"name": "to_array", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/to_array.sql", "original_file_path": "macros/to_array.sql", "unique_id": "macro.springbricks_integration_tests.to_array", "macro_sql": "{% macro to_array(expr) %}\n    array({{expr}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.6960168, "supported_languages": null}, "macro.springbricks_integration_tests.array_cat": {"name": "array_cat", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/array_cat.sql", "original_file_path": "macros/array_cat.sql", "unique_id": "macro.springbricks_integration_tests.array_cat", "macro_sql": "{% macro array_cat(arg1, arg2) %}\n    concat({{arg1}}. {{arg2}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.6965692, "supported_languages": null}, "macro.springbricks_integration_tests.current_schema": {"name": "current_schema", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/current_schema.sql", "original_file_path": "macros/current_schema.sql", "unique_id": "macro.springbricks_integration_tests.current_schema", "macro_sql": "{% macro current_schema() %}\n    current_database()\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.6969202, "supported_languages": null}, "macro.springbricks_integration_tests.to_timestamp_ntz": {"name": "to_timestamp_ntz", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/to_timestamp_ntz.sql", "original_file_path": "macros/to_timestamp_ntz.sql", "unique_id": "macro.springbricks_integration_tests.to_timestamp_ntz", "macro_sql": "{% macro to_timestamp_ntz(arg) %}\n   to_timestamp(arg)\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.697292, "supported_languages": null}, "macro.springbricks_integration_tests.sha2_hex": {"name": "sha2_hex", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/sha2_hex.sql", "original_file_path": "macros/sha2_hex.sql", "unique_id": "macro.springbricks_integration_tests.sha2_hex", "macro_sql": "{% macro sha2_hex(arg, len) %}\n sha2({{arg}}, {{len}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.6978528, "supported_languages": null}, "macro.springbricks_integration_tests.json_extract_path_text": {"name": "json_extract_path_text", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/json_extract_path_text.sql", "original_file_path": "macros/json_extract_path_text.sql", "unique_id": "macro.springbricks_integration_tests.json_extract_path_text", "macro_sql": "{% macro json_extract_path_text(expr, key) %}\n    get_json_object({{expr}}, '$.{{key}}') \n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.698509, "supported_languages": null}, "macro.springbricks_integration_tests.dayofweekiso": {"name": "dayofweekiso", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/dayofweekiso.sql", "original_file_path": "macros/dayofweekiso.sql", "unique_id": "macro.springbricks_integration_tests.dayofweekiso", "macro_sql": "{% macro dayofweekiso(arg) %}\n    EXTRACT(DAYOFWEEK_ISO FROM {{arg}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.69899, "supported_languages": null}, "macro.springbricks_integration_tests.uuid_string": {"name": "uuid_string", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/uuid_string.sql", "original_file_path": "macros/uuid_string.sql", "unique_id": "macro.springbricks_integration_tests.uuid_string", "macro_sql": "{% macro uuid_string() %}\n    uuid()\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.699347, "supported_languages": null}, "macro.springbricks_integration_tests.base64_decode_string": {"name": "base64_decode_string", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/base64_decode_string.sql", "original_file_path": "macros/base64_decode_string.sql", "unique_id": "macro.springbricks_integration_tests.base64_decode_string", "macro_sql": "{% macro base64_decode_string(arg) %}\n    unbase({{arg}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.699806, "supported_languages": null}, "macro.springbricks_integration_tests.base64_decode_binary": {"name": "base64_decode_binary", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/base64_decode_binary.sql", "original_file_path": "macros/base64_decode_binary.sql", "unique_id": "macro.springbricks_integration_tests.base64_decode_binary", "macro_sql": "{% macro base64_decode_binary(arg) %}\n    unbase64({{arg}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.700261, "supported_languages": null}, "macro.springbricks_integration_tests.nullifzero": {"name": "nullifzero", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/nullifzero.sql", "original_file_path": "macros/nullifzero.sql", "unique_id": "macro.springbricks_integration_tests.nullifzero", "macro_sql": "{% macro nullifzero(arg) %}\n    nullif({{arg}}, 0)\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.7007139, "supported_languages": null}, "macro.springbricks_integration_tests.money": {"name": "money", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/dt_convert_money.sql", "original_file_path": "macros/dt_convert_money.sql", "unique_id": "macro.springbricks_integration_tests.money", "macro_sql": "{% macro money(col) -%}\n::decimal(16,4)\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.70109, "supported_languages": null}, "macro.springbricks_integration_tests.array_agg": {"name": "array_agg", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/array_agg.sql", "original_file_path": "macros/array_agg.sql", "unique_id": "macro.springbricks_integration_tests.array_agg", "macro_sql": "{% macro array_agg(arg, delim) %}\n CASE WHEN locate('distinct', lower({{arg}})) = 0\n  THEN sort_array(collect_list({{arg}}), {{delim}})\n  ELSE sort_array(collect_list(DISTINCT {{arg}}), {{delim}})\n  END\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.701922, "supported_languages": null}, "macro.springbricks_integration_tests.timediff": {"name": "timediff", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/timediff.sql", "original_file_path": "macros/timediff.sql", "unique_id": "macro.springbricks_integration_tests.timediff", "macro_sql": "{% macro timediff(unit, arg1,arg2) %}\n  CASE \n  WHEN lower({{unit}}) = 'year'   THEN EXTRACT(YEAR FROM {{arg2}}) - EXTRACT(YEAR FROM {{arg1}})\n  WHEN lower({{unit}}) = 'month'  THEN (EXTRACT(YEAR FROM {{arg2}}) * 12 + EXTRACT(MONTH FROM {{arg2}}))\n                          - (EXTRACT(YEAR FROM {{arg1}}) * 12 + EXTRACT(MONTH FROM {{arg1}}))\n  WHEN lower({{unit}}) = 'day'    THEN datediff(CAST({{arg2}} AS DATE), CAST({{arg1}} AS DATE))\n  WHEN lower({{unit}}) = 'hour'   THEN EXTRACT(HOUR FROM {{arg2}}) - EXTRACT(HOUR FROM {{arg1}})\n  WHEN lower({{unit}}) = 'minute' THEN (EXTRACT(HOUR FROM {{arg2}}) * 60 + EXTRACT(MINUTE FROM {{arg2}}))\n                          - (EXTRACT(HOURs FROM {{arg1}}) * 60 + EXTRACT(MINUTE FROM {{arg1}}))\n  WHEN lower({{unit}}) = 'second' THEN (EXTRACT(HOUR FROM {{arg2}}) * 3600 + EXTRACT(MINUTE FROM {{arg2}}) * 60 + EXTRACT(SECOND FROM {{arg2}}))\n                          - (EXTRACT(HOUR FROM {{arg2}}) * 3600 + EXTRACT(MINUTE FROM {{arg2}}) * 60 + EXTRACT(SECOND FROM {{arg2}}))\n  END\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.705966, "supported_languages": null}, "macro.springbricks_integration_tests.try_to_number": {"name": "try_to_number", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/try_to_number.sql", "original_file_path": "macros/try_to_number.sql", "unique_id": "macro.springbricks_integration_tests.try_to_number", "macro_sql": "{% macro try_to_number(expr, format, precision, scale) %}\n\n\n{% if scale %}\n\n\n\n\ntry_cast({{expr}} as decimal({{precision}}, {{scale}}))\n\n\n{% elif precision %}\n\ntry_cast({{expr}} as decimal({{format}}, {{precision}}))\n\n\n{% elif format %}\n\ntry_to_number({{expr}}, \"{{format}}\")\n\n\n{% else %}\n\ntry_cast({{expr}} as decimal(38, 0))\n\n{% endif %}\t\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.707686, "supported_languages": null}, "macro.springbricks_integration_tests.strtok": {"name": "strtok", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/strtok.sql", "original_file_path": "macros/strtok.sql", "unique_id": "macro.springbricks_integration_tests.strtok", "macro_sql": "{% macro strtok(arg, delim, part) %}\n    element_at(split({{arg}}, {{delim}}), {{part}} )\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.708364, "supported_languages": null}, "macro.springbricks_integration_tests.split_part": {"name": "split_part", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/split_part.sql", "original_file_path": "macros/split_part.sql", "unique_id": "macro.springbricks_integration_tests.split_part", "macro_sql": "{% macro split_part(arg, delim, part) %}\n    element_at(split({{arg}}, {{delim}}), {{part}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.7090318, "supported_languages": null}, "macro.springbricks_integration_tests.is_null_value": {"name": "is_null_value", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/is_null_value.sql", "original_file_path": "macros/is_null_value.sql", "unique_id": "macro.springbricks_integration_tests.is_null_value", "macro_sql": "{% macro is_null_value(string) %}\n    isnull({{string}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.709496, "supported_languages": null}, "macro.springbricks_integration_tests.databricks__dateadd": {"name": "databricks__dateadd", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/dateaddog.sql", "original_file_path": "macros/dateaddog.sql", "unique_id": "macro.springbricks_integration_tests.databricks__dateadd", "macro_sql": "{% macro databricks__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    {%- set clock_component -%}\n        {# make sure the dates + timestamps are real, otherwise raise an error asap #}\n        to_unix_timestamp({{ spark_utils.assert_not_null('to_timestamp', from_date_or_timestamp) }})\n        - to_unix_timestamp({{ spark_utils.assert_not_null('date', from_date_or_timestamp) }})\n    {%- endset -%}\n\n    {%- if datepart in ['day', 'week'] -%}\n        \n        {%- set multiplier = 7 if datepart == 'week' else 1 -%}\n\n        to_timestamp(\n            to_unix_timestamp(\n                date_add(\n                    {{ spark_utils.assert_not_null('date', from_date_or_timestamp) }},\n                    cast({{interval}} * {{multiplier}} as int)\n                )\n            ) + {{clock_component}}\n        )\n\n    {%- elif datepart in ['month', 'quarter', 'year'] -%}\n    \n        {%- set multiplier -%} \n            {%- if datepart == 'month' -%} 1\n            {%- elif datepart == 'quarter' -%} 3\n            {%- elif datepart == 'year' -%} 12\n            {%- endif -%}\n        {%- endset -%}\n\n        to_timestamp(\n            to_unix_timestamp(\n                add_months(\n                    {{ spark_utils.assert_not_null('date', from_date_or_timestamp) }},\n                    cast({{interval}} * {{multiplier}} as int)\n                )\n            ) + {{clock_component}}\n        )\n\n    {%- elif datepart in ('hour', 'minute', 'second', 'millisecond', 'microsecond') -%}\n    \n        {%- set multiplier -%} \n            {%- if datepart == 'hour' -%} 3600\n            {%- elif datepart == 'minute' -%} 60\n            {%- elif datepart == 'second' -%} 1\n            {%- elif datepart == 'millisecond' -%} (1/1000000)\n            {%- elif datepart == 'microsecond' -%} (1/1000000)\n            {%- endif -%}\n        {%- endset -%}\n\n        to_timestamp(\n            {{ spark_utils.assert_not_null('to_unix_timestamp', from_date_or_timestamp) }}\n            + cast({{interval}} * {{multiplier}} as int)\n        )\n\n    {%- else -%}\n\n        {{ exceptions.raise_compiler_error(\"macro dateadd not implemented for datepart ~ '\" ~ datepart ~ \"' ~ on Spark\") }}\n\n    {%- endif -%}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.assert_not_null"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.717977, "supported_languages": null}, "macro.springbricks_integration_tests.array_construct": {"name": "array_construct", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/array_construct.sql", "original_file_path": "macros/array_construct.sql", "unique_id": "macro.springbricks_integration_tests.array_construct", "macro_sql": "{% macro array_construct(expr) %}\n    array({{expr}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.7185411, "supported_languages": null}, "macro.springbricks_integration_tests.dayname": {"name": "dayname", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/dayname.sql", "original_file_path": "macros/dayname.sql", "unique_id": "macro.springbricks_integration_tests.dayname", "macro_sql": "{% macro dayname(arg) %}\n    CASE \n         WHEN datediff(CAST({{arg}} AS DATE), DATE'1799-12-29') % 7 = 0 THEN 'Sun'\n         WHEN datediff(CAST({{arg}} AS DATE), DATE'1799-12-29') % 7 = 1 THEN 'Mon'\n         WHEN datediff(CAST({{arg}} AS DATE), DATE'1799-12-29') % 7 = 2 THEN 'Tue'\n         WHEN datediff(CAST({{arg}} AS DATE), DATE'1799-12-29') % 7 = 3 THEN 'Wed'\n         WHEN datediff(CAST({{arg}} AS DATE), DATE'1799-12-29') % 7 = 4 THEN 'Thu'\n         WHEN datediff(CAST({{arg}} AS DATE), DATE'1799-12-29') % 7 = 5 THEN 'Fri'\n         ELSE 'Sat' END\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.7196732, "supported_languages": null}, "macro.springbricks_integration_tests.to_varchar": {"name": "to_varchar", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/to_varchar.sql", "original_file_path": "macros/to_varchar.sql", "unique_id": "macro.springbricks_integration_tests.to_varchar", "macro_sql": "{% macro to_varchar(expr, format) %}\n\n{% if format %}\n\ncase when typeof({{expr}}) = 'date'\nthen to_date({{expr}}, {{format}})::string\nwhen typeof({{expr}}) = 'timestamp'\nthen to_timestamp({{expr}}, {{format}})::string\nwhen typeof({{expr}}) = 'binary'\nthen to_binary({{expr}}, {{format}})::string\nelse to_char({{expr}}, {{format}})::string\nend\n\n{% else %}\n\ncast({{expr}} as string)\n\n\n\n{% endif %}\t\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.721382, "supported_languages": null}, "macro.springbricks_integration_tests.seq8": {"name": "seq8", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/seq8.sql", "original_file_path": "macros/seq8.sql", "unique_id": "macro.springbricks_integration_tests.seq8", "macro_sql": "{% macro seq8() %}\n    monotonically_increasing_id()\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.721747, "supported_languages": null}, "macro.springbricks_integration_tests.md5_binary": {"name": "md5_binary", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/md5_binary.sql", "original_file_path": "macros/md5_binary.sql", "unique_id": "macro.springbricks_integration_tests.md5_binary", "macro_sql": "{% macro md5_binary(arg) %}\n    md5({{arg}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.7221918, "supported_languages": null}, "macro.springbricks_integration_tests.charindex": {"name": "charindex", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/charindex.sql", "original_file_path": "macros/charindex.sql", "unique_id": "macro.springbricks_integration_tests.charindex", "macro_sql": "{% macro charindex(arg1, arg2, start) %}\n    position({{arg1}}, {{arg2}}, {{start}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.7228422, "supported_languages": null}, "macro.springbricks_integration_tests.zeroifnull": {"name": "zeroifnull", "resource_type": "macro", "package_name": "springbricks_integration_tests", "path": "macros/zeroifnull.sql", "original_file_path": "macros/zeroifnull.sql", "unique_id": "macro.springbricks_integration_tests.zeroifnull", "macro_sql": "{% macro zeroifnull(column_name) %}\n    nvl({{column_name}}, 0)\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.723291, "supported_languages": null}, "macro.dbt_databricks.statement_with_staging_table": {"name": "statement_with_staging_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/statement.sql", "original_file_path": "macros/statement.sql", "unique_id": "macro.dbt_databricks.statement_with_staging_table", "macro_sql": "{% macro statement_with_staging_table(name=None, staging_table=None, fetch_result=False, auto_begin=True) -%}\n  {%- if execute: -%}\n    {%- set sql = caller() -%}\n\n    {%- if name == 'main' -%}\n      {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n      {{ write(sql) }}\n    {%- endif -%}\n\n    {%- set res, table = adapter.execute(sql, auto_begin=auto_begin, fetch=fetch_result, staging_table=staging_table) -%}\n    {%- if name is not none -%}\n      {{ store_result(name, response=res, agate_table=table) }}\n    {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.726088, "supported_languages": null}, "macro.dbt_databricks.databricks_copy_into": {"name": "databricks_copy_into", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/copy_into.sql", "original_file_path": "macros/copy_into.sql", "unique_id": "macro.dbt_databricks.databricks_copy_into", "macro_sql": "{% macro databricks_copy_into(\n  target_table,\n  source,\n  file_format,\n  expression_list=none,\n  source_credential=none,\n  source_encryption=none,\n  validate=none,\n  files=none,\n  pattern=none,\n  format_options=none,\n  copy_options=none) -%}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n        database=target.database,\n        schema=target.schema,\n        identifier=target_table,\n        type='table') -%}\n\n  {%- set source_clause -%}\n    {%- if expression_list -%}\n      ( select {{ expression_list }} from '{{ source }}' )\n    {%- else -%}\n      '{{ source }}'\n    {%- endif -%}\n    {%- if source_credential or source_encryption %}\n      WITH (\n      {%- if source_credential %}\n        credential (\n          {%- for name in source_credential -%}\n            '{{ name }}' = '{{ source_credential[name] }}' {%- if not loop.last %}, {% endif -%}\n          {%- endfor -%}\n        )\n      {%- endif %}\n      {%- if source_encryption %}\n        encryption (\n          {%- for name in source_encryption -%}\n            '{{ name }}' = '{{ source_encryption[name] }}' {%- if not loop.last %}, {% endif -%}\n          {%- endfor -%}\n        )\n      {%- endif %}\n      )\n    {%- endif -%}\n  {%- endset -%}\n\n  {% set query %}\n    copy into {{ target_relation }}\n    from {{ source_clause }}\n    fileformat = {{ file_format }}\n    {% if validate -%} validate {{ validate }} {%- endif %}\n    {% if files and pattern %}\n        {{ exceptions.raise_compiler_error(\"You can only specify one of 'files' or 'pattern'\") }}\n    {% endif %}\n    {% if files -%}\n      files = (\n        {%- for file in files -%}\n          '{{ file }}' {%- if not loop.last %}, {% endif -%}\n        {%- endfor -%}\n      )\n    {%- endif %}\n    {% if pattern -%}\n        pattern = '{{ pattern }}'\n    {%- endif %}\n    {% if format_options -%}\n      format_options (\n        {%- for key in format_options -%}\n          '{{ key }}' = '{{ format_options[key] }}' {%- if not loop.last %}, {% endif -%}\n        {%- endfor -%}\n      )\n    {%- endif %}\n    {% if copy_options -%}\n      copy_options (\n        {%- for key in copy_options -%}\n          '{{ key }}' = '{{ copy_options[key] }}' {%- if not loop.last %}, {% endif -%}\n        {%- endfor -%}\n      )\n    {%- endif %}\n  {% endset %}\n\n  {% do log(\"Running COPY INTO\" ~ adapter.redact_credentials(query), info=True) %}\n  {% do run_query(query) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_or_create_relation", "macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.738156, "supported_languages": null}, "macro.dbt_databricks.current_catalog": {"name": "current_catalog", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/catalog.sql", "original_file_path": "macros/catalog.sql", "unique_id": "macro.dbt_databricks.current_catalog", "macro_sql": "{% macro current_catalog() -%}\n  {{ return(adapter.dispatch('current_catalog', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__current_catalog"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.739348, "supported_languages": null}, "macro.dbt_databricks.databricks__current_catalog": {"name": "databricks__current_catalog", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/catalog.sql", "original_file_path": "macros/catalog.sql", "unique_id": "macro.dbt_databricks.databricks__current_catalog", "macro_sql": "{% macro databricks__current_catalog() -%}\n  {% call statement('current_catalog', fetch_result=True) %}\n      select current_catalog()\n  {% endcall %}\n  {% do return(load_result('current_catalog').table) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.740161, "supported_languages": null}, "macro.dbt_databricks.use_catalog": {"name": "use_catalog", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/catalog.sql", "original_file_path": "macros/catalog.sql", "unique_id": "macro.dbt_databricks.use_catalog", "macro_sql": "{% macro use_catalog(catalog) -%}\n  {{ return(adapter.dispatch('use_catalog', 'dbt')(catalog)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__use_catalog"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.740779, "supported_languages": null}, "macro.dbt_databricks.databricks__use_catalog": {"name": "databricks__use_catalog", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/catalog.sql", "original_file_path": "macros/catalog.sql", "unique_id": "macro.dbt_databricks.databricks__use_catalog", "macro_sql": "{% macro databricks__use_catalog(catalog) -%}\n  {% call statement() %}\n    use catalog {{ adapter.quote(catalog) }}\n  {% endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.7413938, "supported_languages": null}, "macro.dbt_databricks.databricks__file_format_clause": {"name": "databricks__file_format_clause", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.databricks__file_format_clause", "macro_sql": "{% macro databricks__file_format_clause() %}\n  {%- set file_format = config.get('file_format', default='delta') -%}\n  {%- if file_format is not none %}\n    using {{ file_format }}\n  {%- endif %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.7846222, "supported_languages": null}, "macro.dbt_databricks.databricks__options_clause": {"name": "databricks__options_clause", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.databricks__options_clause", "macro_sql": "{% macro databricks__options_clause() -%}\n  {%- set options = config.get('options') -%}\n  {%- if config.get('file_format', default='delta') == 'hudi' -%}\n    {%- set unique_key = config.get('unique_key') -%}\n    {%- if unique_key is not none and options is none -%}\n      {%- set options = {'primaryKey': config.get('unique_key')} -%}\n    {%- elif unique_key is not none and options is not none and 'primaryKey' not in options -%}\n      {%- set _ = options.update({'primaryKey': config.get('unique_key')}) -%}\n    {%- elif options is not none and 'primaryKey' in options and options['primaryKey'] != unique_key -%}\n      {{ exceptions.raise_compiler_error(\"unique_key and options('primaryKey') should be the same column(s).\") }}\n    {%- endif %}\n  {%- endif %}\n\n  {%- if options is not none %}\n    options (\n      {%- for option in options -%}\n      {{ option }} \"{{ options[option] }}\" {% if not loop.last %}, {% endif %}\n      {%- endfor %}\n    )\n  {%- endif %}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.7881541, "supported_languages": null}, "macro.dbt_databricks.tblproperties_clause": {"name": "tblproperties_clause", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.tblproperties_clause", "macro_sql": "{% macro tblproperties_clause() -%}\n  {{ return(adapter.dispatch('tblproperties_clause', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_databricks.databricks__tblproperties_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.788749, "supported_languages": null}, "macro.dbt_databricks.databricks__tblproperties_clause": {"name": "databricks__tblproperties_clause", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.databricks__tblproperties_clause", "macro_sql": "{% macro databricks__tblproperties_clause() -%}\n  {%- set tblproperties = config.get('tblproperties') -%}\n  {%- if tblproperties is not none %}\n    tblproperties (\n      {%- for prop in tblproperties -%}\n      '{{ prop }}' = '{{ tblproperties[prop] }}' {% if not loop.last %}, {% endif %}\n      {%- endfor %}\n    )\n  {%- endif %}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.789974, "supported_languages": null}, "macro.dbt_databricks.databricks__create_table_as": {"name": "databricks__create_table_as", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.databricks__create_table_as", "macro_sql": "{% macro databricks__create_table_as(temporary, relation, compiled_code, language='sql') -%}\n  {%- if language == 'sql' -%}\n    {%- if temporary -%}\n      {{ create_temporary_view(relation, compiled_code) }}\n    {%- else -%}\n      {% if config.get('file_format', default='delta') == 'delta' %}\n        create or replace table {{ relation }}\n      {% else %}\n        create table {{ relation }}\n      {% endif %}\n      {%- set contract_config = config.get('contract') -%}\n      {% if contract_config and contract_config.enforced %}\n        {{ get_assert_columns_equivalent(compiled_code) }}\n        {%- set compiled_code = get_select_subquery(compiled_code) %}\n      {% endif %}\n      {{ file_format_clause() }}\n      {{ options_clause() }}\n      {{ partition_cols(label=\"partitioned by\") }}\n      {{ clustered_cols(label=\"clustered by\") }}\n      {{ location_clause() }}\n      {{ comment_clause() }}\n      {{ tblproperties_clause() }}\n      as\n      {{ compiled_code }}\n    {%- endif -%}\n  {%- elif language == 'python' -%}\n    {#--\n    N.B. Python models _can_ write to temp views HOWEVER they use a different session\n    and have already expired by the time they need to be used (I.E. in merges for incremental models)\n\n    TODO: Deep dive into spark sessions to see if we can reuse a single session for an entire\n    dbt invocation.\n     --#}\n    {{ py_write_table(compiled_code=compiled_code, target_relation=relation) }}\n  {%- endif -%}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_spark.create_temporary_view", "macro.dbt.get_assert_columns_equivalent", "macro.dbt.get_select_subquery", "macro.dbt_spark.file_format_clause", "macro.dbt_spark.options_clause", "macro.dbt_spark.partition_cols", "macro.dbt_spark.clustered_cols", "macro.dbt_spark.location_clause", "macro.dbt_spark.comment_clause", "macro.dbt_databricks.tblproperties_clause", "macro.dbt_spark.py_write_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.7933261, "supported_languages": null}, "macro.dbt_databricks.databricks__create_view_as": {"name": "databricks__create_view_as", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.databricks__create_view_as", "macro_sql": "{% macro databricks__create_view_as(relation, sql) -%}\n  create or replace view {{ relation }}\n  {{ comment_clause() }}\n  {%- set contract_config = config.get('contract') -%}\n  {% if contract_config and contract_config.enforced %}\n    {{ get_assert_columns_equivalent(sql) }}\n  {%- endif %}\n  {{ tblproperties_clause() }}\n  as\n    {{ sql }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.comment_clause", "macro.dbt.get_assert_columns_equivalent", "macro.dbt_databricks.tblproperties_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.7945411, "supported_languages": null}, "macro.dbt_databricks.databricks__alter_column_comment": {"name": "databricks__alter_column_comment", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.databricks__alter_column_comment", "macro_sql": "{% macro databricks__alter_column_comment(relation, column_dict) %}\n  {% if config.get('file_format', default='delta') in ['delta', 'hudi'] %}\n    {% for column_name in column_dict %}\n      {% set comment = column_dict[column_name]['description'] %}\n      {% set escaped_comment = comment | replace('\\'', '\\\\\\'') %}\n      {% set comment_query %}\n        alter table {{ relation }} change column\n            {{ adapter.quote(column_name) if column_dict[column_name]['quote'] else column_name }}\n            comment '{{ escaped_comment }}';\n      {% endset %}\n      {% do run_query(comment_query) %}\n    {% endfor %}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.796854, "supported_languages": null}, "macro.dbt_databricks.persist_constraints": {"name": "persist_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.persist_constraints", "macro_sql": "{% macro persist_constraints(relation, model) %}\n  {{ return(adapter.dispatch('persist_constraints', 'dbt')(relation, model)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__persist_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.797573, "supported_languages": null}, "macro.dbt_databricks.databricks__persist_constraints": {"name": "databricks__persist_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.databricks__persist_constraints", "macro_sql": "{% macro databricks__persist_constraints(relation, model) %}\n  {%- set contract_config = config.get('contract') -%}\n  {% set has_model_contract = contract_config and contract_config.enforced %}\n  {% set has_databricks_constraints = config.get('persist_constraints', False) %}\n\n  {% if (has_model_contract or has_databricks_constraints) %}\n    {% if config.get('file_format', 'delta') != 'delta' %}\n      {# Constraints are only supported for delta tables #}\n      {{ exceptions.warn(\"Constraints not supported for file format: \" ~ config.get('file_format')) }}\n    {% elif relation.is_view %}\n      {# Constraints are not supported for views. This point in the code should not have been reached. #}\n      {{ exceptions.raise_compiler_error(\"Constraints not supported for views.\") }}\n    {% elif is_incremental() %}\n      {# Constraints are not applied for incremental updates. This point in the code should not have been reached #}\n      {{ exceptions.raise_compiler_error(\"Constraints are not applied for incremental updates. Full refresh is required to update constraints.\") }}\n    {% else %}\n      {% do alter_table_add_constraints(relation, model) %}\n      {% do alter_column_set_constraints(relation, model) %}\n    {% endif %}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.is_incremental", "macro.dbt_databricks.alter_table_add_constraints", "macro.dbt_databricks.alter_column_set_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.800488, "supported_languages": null}, "macro.dbt_databricks.alter_table_add_constraints": {"name": "alter_table_add_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.alter_table_add_constraints", "macro_sql": "{% macro alter_table_add_constraints(relation, constraints) %}\n  {{ return(adapter.dispatch('alter_table_add_constraints', 'dbt')(relation, constraints)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__alter_table_add_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.801375, "supported_languages": null}, "macro.dbt_databricks.databricks__alter_table_add_constraints": {"name": "databricks__alter_table_add_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.databricks__alter_table_add_constraints", "macro_sql": "{% macro databricks__alter_table_add_constraints(relation, model) %}\n    {% set constraints = get_model_constraints(model) %}\n    {% set statements = get_constraints_sql(relation, constraints, model) %}\n    {% for stmt in statements %}\n      {% call statement() %}\n        {{ stmt }}\n      {% endcall %}\n    {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_model_constraints", "macro.dbt_databricks.get_constraints_sql", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.8026218, "supported_languages": null}, "macro.dbt_databricks.get_model_constraints": {"name": "get_model_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.get_model_constraints", "macro_sql": "{% macro get_model_constraints(model) %}\n  {% set constraints = model.get('constraints', []) %}\n  {% if config.get('persist_constraints', False) and model.get('meta', {}).get('constraints') is sequence %}\n    {# Databricks constraints implementation.  Constraints are in the meta property. #}\n    {% set db_constraints = model.get('meta', {}).get('constraints', []) %}\n    {% set constraints = databricks_constraints_to_dbt(db_constraints) %}\n  {% endif %}\n  {{ return(constraints) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks_constraints_to_dbt"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.804652, "supported_languages": null}, "macro.dbt_databricks.get_column_constraints": {"name": "get_column_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.get_column_constraints", "macro_sql": "{% macro get_column_constraints(column) %}\n  {% set constraints = column.get('constraints', []) %}\n  {% if config.get('persist_constraints', False) and column.get('meta', {}).get('constraint') %}\n    {# Databricks constraints implementation.  Constraint is in the meta property. #}\n    {% set db_constraints = [column.get('meta', {}).get('constraint')] %}\n    {% set constraints = databricks_constraints_to_dbt(db_constraints, column) %}\n  {% endif %}\n  {{ return(constraints) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks_constraints_to_dbt"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.806558, "supported_languages": null}, "macro.dbt_databricks.alter_column_set_constraints": {"name": "alter_column_set_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.alter_column_set_constraints", "macro_sql": "{% macro alter_column_set_constraints(relation, column_dict) %}\n  {{ return(adapter.dispatch('alter_column_set_constraints', 'dbt')(relation, column_dict)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__alter_column_set_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.8072588, "supported_languages": null}, "macro.dbt_databricks.databricks__alter_column_set_constraints": {"name": "databricks__alter_column_set_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.databricks__alter_column_set_constraints", "macro_sql": "{% macro databricks__alter_column_set_constraints(relation, model) %}\n  {% set column_dict = model.columns %}\n  {% for column_name in column_dict %}\n    {% set column = column_dict[column_name] %}\n    {% set constraints = get_column_constraints(column)  %}\n    {% set statements = get_constraints_sql(relation, constraints, model, column) %}\n    {% for stmt in statements %}\n      {% call statement() %}\n        {{ stmt }}\n      {% endcall %}\n    {% endfor %}\n  {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_column_constraints", "macro.dbt_databricks.get_constraints_sql", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.809076, "supported_languages": null}, "macro.dbt_databricks.get_constraints_sql": {"name": "get_constraints_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.get_constraints_sql", "macro_sql": "{% macro get_constraints_sql(relation, constraints, model, column) %}\n  {% set statements = [] %}\n  {% for constraint in constraints %}\n    {% if constraint %}\n      {% set constraint_statements = get_constraint_sql(relation, constraint, model, column) %}\n      {% for statement in constraint_statements %}\n        {% if statement %}\n          {% do statements.append(statement) %}\n        {% endif %}\n      {% endfor %}  \n    {% endif %}\n  {% endfor %}\n\n  {{ return(statements) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_constraint_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.8109288, "supported_languages": null}, "macro.dbt_databricks.get_constraint_sql": {"name": "get_constraint_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.get_constraint_sql", "macro_sql": "{% macro get_constraint_sql(relation, constraint, model, column={}) %}\n  {% set statements = [] %}\n  {% set type = constraint.get(\"type\", \"\") %}\n\n  {% if type == 'check' %}\n    {% set expression = constraint.get(\"expression\", \"\") %}\n    {% if not expression %}\n      {{ exceptions.raise_compiler_error('Invalid check constraint expression') }}\n    {% endif %}\n\n    {% set name = constraint.get(\"name\") %}\n    {% if not name and local_md5 %}\n      {{ exceptions.warn(\"Constraint of type \" ~ type ~ \" with no `name` provided. Generating hash instead.\") }}\n      {%- set name = local_md5 (column.get(\"name\", \"\") ~ \";\" ~ expression ~ \";\") -%}\n    {% endif %}\n    {% set stmt = \"alter table \" ~ relation ~ \" add constraint \" ~ name ~ \" check (\" ~ expression ~ \");\" %}\n    {% do statements.append(stmt) %}\n  {% elif type == 'not_null' %}\n    {% set column_names = constraint.get(\"columns\", []) %}\n    {% if column and not column_names %}\n      {% set column_names = [column['name']] %}\n    {% endif %}\n    {% for column_name in column_names %}\n      {% set column = model.get('columns', {}).get(column_name) %}\n      {% if column %}\n        {% set quoted_name = adapter.quote(column['name']) if column['quote'] else column['name'] %}\n        {% set stmt = \"alter table \" ~ relation ~ \" change column \" ~ quoted_name ~ \" set not null \" ~ (constraint.expression or \"\") ~ \";\" %}\n        {% do statements.append(stmt) %}\n      {% else %}\n        {{ exceptions.warn('not_null constraint on invalid column: ' ~ column_name) }}\n      {% endif %}\n    {% endfor %}\n  {% elif type == 'primary_key' %}\n    {% if constraint.get('warn_unenforced') %}\n      {{ exceptions.warn(\"unenforced constraint type: \" ~ type)}}\n    {% endif %}\n    {% set column_names = constraint.get(\"columns\", []) %}\n    {% if column and not column_names %}\n      {% set column_names = [column['name']] %}\n    {% endif %}\n    {% set quoted_names = [] %}\n    {% for column_name in column_names %}\n      {% set column = model.get('columns', {}).get(column_name) %}\n      {% if not column %}\n        {{ exceptions.warn('Invalid primary key column: ' ~ column_name) }}\n      {% else %}\n        {% set quoted_name = adapter.quote(column['name']) if column['quote'] else column['name'] %}\n        {% do quoted_names.append(quoted_name) %}\n      {% endif %}\n    {% endfor %}\n\n    {% set joined_names = quoted_names|join(\", \") %}\n\n    {% set name = constraint.get(\"name\") %}\n    {% if not name and local_md5 %}\n      {{ exceptions.warn(\"Constraint of type \" ~ type ~ \" with no `name` provided. Generating hash instead.\") }}\n      {%- set name = local_md5(\"primary_key;\" ~ column_names ~ \";\") -%}\n    {% endif %}\n    {% set stmt = \"alter table \" ~ relation ~ \" add constraint \" ~ name ~ \" primary key(\" ~ joined_names ~ \");\" %}\n    {% do statements.append(stmt) %}\n  {% elif type == 'foreign_key' %}\n\n    {% if constraint.get('warn_unenforced') %}\n      {{ exceptions.warn(\"unenforced constraint type: \" ~ constraint.type)}}\n    {% endif %}\n\n    {% set column_names = constraint.get(\"columns\", []) %}\n    {% if column and not column_names %}\n      {% set column_names = [column['name']] %}\n    {% endif %}\n    {% set quoted_names = [] %}\n    {% for column_name in column_names %}\n      {% set column = model.get('columns', {}).get(column_name) %}\n      {% if not column %}\n        {{ exceptions.warn('Invalid foreign key column: ' ~ column_name) }}\n      {% else %}\n        {% set quoted_name = adapter.quote(column['name']) if column['quote'] else column['name'] %}\n        {% do quoted_names.append(quoted_name) %}\n      {% endif %}\n    {% endfor %}\n\n    {% set joined_names = quoted_names|join(\", \") %}\n\n    {% set name = constraint.get(\"name\") %}\n    {% if not name and local_md5 %}\n      {{ exceptions.warn(\"Constraint of type \" ~ type ~ \" with no `name` provided. Generating hash instead.\") }}\n      {%- set name = local_md5(\"primary_key;\" ~ column_names ~ \";\") -%}\n    {% endif %}\n\n    {% set parent = constraint.get(\"parent\") %}\n    {% if not parent %} \n      {{ exceptions.raise_compiler_error('No parent table defined for foreign key: ' ~ expression) }}\n    {% endif %}\n    {% if not \".\" in parent %}\n      {% set parent = relation.schema ~ \".\" ~ parent%}\n    {% endif %}\n    {% set stmt = \"alter table \" ~ relation ~ \" add constraint \" ~ name ~ \" foreign key(\" ~ joined_names ~ \") references \" ~ parent %}\n    {% set parent_columns = constraint.get(\"parent_columns\") %}\n    {% if parent_columns %}\n      {% set stmt = stmt ~ \"(\" ~ parent_columns|join(\", \") ~ \")\"%}\n    {% endif %}\n    {% set stmt = stmt ~ \";\" %}\n    {% do statements.append(stmt) %}\n  {% elif constraint.get('warn_unsupported') %}\n    {{ exceptions.warn(\"unsupported constraint type: \" ~ constraint.type)}}\n  {% endif %}\n\n  {{ return(statements) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.829629, "supported_languages": null}, "macro.dbt_databricks.databricks_constraints_to_dbt": {"name": "databricks_constraints_to_dbt", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.databricks_constraints_to_dbt", "macro_sql": "{% macro databricks_constraints_to_dbt(constraints, column) %}\n  {# convert constraints defined using the original databricks format #}\n  {% set dbt_constraints = [] %}\n  {% for constraint in constraints %}\n    {% if constraint.get and constraint.get(\"type\") %}\n      {# already in model contract format #}\n      {% do dbt_constraints.append(constraint) %}\n    {% else %}\n      {% if column %}\n        {% if constraint == \"not_null\" %}\n          {% do dbt_constraints.append({\"type\": \"not_null\", \"columns\": [column.get(\"name\")]}) %}\n        {% else %}\n          {{ exceptions.raise_compiler_error('Invalid constraint for column ' ~ column.get(\"name\", \"\") ~ '. Only `not_null` is supported.') }}\n        {% endif %}\n      {% else %}\n        {% set name = constraint['name'] %}\n        {% if not name %}\n          {{ exceptions.raise_compiler_error('Invalid check constraint name') }}\n        {% endif %}\n        {% set condition = constraint['condition'] %}\n        {% if not condition %}\n          {{ exceptions.raise_compiler_error('Invalid check constraint condition') }}\n        {% endif %}\n        {% do dbt_constraints.append({\"name\": name, \"type\": \"check\", \"expression\": condition}) %}\n      {% endif %}\n    {% endif %}\n  {% endfor %}\n\n  {{ return(dbt_constraints) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.8339462, "supported_languages": null}, "macro.dbt_databricks.optimize": {"name": "optimize", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.optimize", "macro_sql": "{% macro optimize(relation) %}\n  {{ return(adapter.dispatch('optimize', 'dbt')(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__optimize"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.8345978, "supported_languages": null}, "macro.dbt_databricks.databricks__optimize": {"name": "databricks__optimize", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.databricks__optimize", "macro_sql": "{% macro databricks__optimize(relation) %}\n  {% if config.get('zorder', False) and config.get('file_format', 'delta') == 'delta' %}\n    {% if var('DATABRICKS_SKIP_OPTIMIZE', 'false')|lower != 'true' and var('databricks_skip_optimize', 'false')|lower != 'true' %}\n      {% call statement('run_optimize_stmt') %}\n        {{ get_optimize_sql(relation) }}\n      {% endcall %}\n    {% endif %}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.get_optimize_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.836266, "supported_languages": null}, "macro.dbt_databricks.get_optimize_sql": {"name": "get_optimize_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.get_optimize_sql", "macro_sql": "{% macro get_optimize_sql(relation) %}\n  {% if config.get('zorder', False) and config.get('file_format', 'delta') == 'delta' %}\n     {%- set zorder = config.get('zorder', none) -%}\n    optimize {{ relation }}\n    {# TODO: predicates here? WHERE ...  #}\n    {% if zorder is sequence and zorder is not string %}\n      zorder by (\n        {%- for col in zorder -%}\n        {{ col }}{% if not loop.last %}, {% endif %}\n        {%- endfor -%}\n      )\n    {% else %}\n      zorder by ({{zorder}})\n    {% endif %}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.838217, "supported_languages": null}, "macro.dbt_databricks.databricks__list_relations_without_caching": {"name": "databricks__list_relations_without_caching", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.databricks__list_relations_without_caching", "macro_sql": "{% macro databricks__list_relations_without_caching(schema_relation) %}\n  {{ return(adapter.get_relations_without_caching(schema_relation)) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.8387341, "supported_languages": null}, "macro.dbt_databricks.show_table_extended": {"name": "show_table_extended", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.show_table_extended", "macro_sql": "{% macro show_table_extended(schema_relation) %}\n  {{ return(adapter.dispatch('show_table_extended', 'dbt')(schema_relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__show_table_extended"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.839345, "supported_languages": null}, "macro.dbt_databricks.databricks__show_table_extended": {"name": "databricks__show_table_extended", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.databricks__show_table_extended", "macro_sql": "{% macro databricks__show_table_extended(schema_relation) %}\n  {% call statement('show_table_extended', fetch_result=True) -%}\n    show table extended in {{ schema_relation.without_identifier() }} like '{{ schema_relation.identifier }}'\n  {% endcall %}\n\n  {% do return(load_result('show_table_extended').table) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.840371, "supported_languages": null}, "macro.dbt_databricks.show_tables": {"name": "show_tables", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.show_tables", "macro_sql": "{% macro show_tables(relation) %}\n  {{ return(adapter.dispatch('show_tables', 'dbt')(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__show_tables"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.841023, "supported_languages": null}, "macro.dbt_databricks.databricks__show_tables": {"name": "databricks__show_tables", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.databricks__show_tables", "macro_sql": "{% macro databricks__show_tables(relation) %}\n  {% call statement('show_tables', fetch_result=True) -%}\n    show tables in {{ relation }}\n  {% endcall %}\n\n  {% do return(load_result('show_tables').table) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.841985, "supported_languages": null}, "macro.dbt_databricks.show_views": {"name": "show_views", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.show_views", "macro_sql": "{% macro show_views(relation) %}\n  {{ return(adapter.dispatch('show_views', 'dbt')(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__show_views"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.842614, "supported_languages": null}, "macro.dbt_databricks.databricks__show_views": {"name": "databricks__show_views", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.databricks__show_views", "macro_sql": "{% macro databricks__show_views(relation) %}\n  {% call statement('show_views', fetch_result=True) -%}\n    show views in {{ relation }}\n  {% endcall %}\n\n  {% do return(load_result('show_views').table) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.843549, "supported_languages": null}, "macro.dbt_databricks.databricks__generate_database_name": {"name": "databricks__generate_database_name", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.databricks__generate_database_name", "macro_sql": "{% macro databricks__generate_database_name(custom_database_name=none, node=none) -%}\n    {%- set default_database = target.database -%}\n    {%- if custom_database_name is none -%}\n        {{ return(default_database) }}\n    {%- else -%}\n        {{ return(custom_database_name) }}\n    {%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.8445718, "supported_languages": null}, "macro.dbt_databricks.databricks__make_temp_relation": {"name": "databricks__make_temp_relation", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.databricks__make_temp_relation", "macro_sql": "{% macro databricks__make_temp_relation(base_relation, suffix='__dbt_tmp', as_table=False) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {%- if as_table -%}\n        {% set tmp_relation = api.Relation.create(\n            identifier=tmp_identifier,\n            schema=base_relation.schema,\n            database=base_relation.database,\n            type='table') %}\n    {%- else -%}\n        {% set tmp_relation = api.Relation.create(identifier=tmp_identifier, type='view') %}\n    {%- endif -%}\n    {% do return(tmp_relation) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.8463, "supported_languages": null}, "macro.dbt_databricks.databricks__get_or_create_relation": {"name": "databricks__get_or_create_relation", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_databricks.databricks__get_or_create_relation", "macro_sql": "{% macro databricks__get_or_create_relation(database, schema, identifier, type, needs_information=False) %}\n  {%- set target_relation = adapter.get_relation(\n            database=database,\n            schema=schema,\n            identifier=identifier,\n            needs_information=needs_information) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.848206, "supported_languages": null}, "macro.dbt_databricks.databricks__get_binding_char": {"name": "databricks__get_binding_char", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "unique_id": "macro.dbt_databricks.databricks__get_binding_char", "macro_sql": "{% macro databricks__get_binding_char() %}\n  {{ return('%s') }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.852105, "supported_languages": null}, "macro.dbt_databricks.databricks__load_csv_rows": {"name": "databricks__load_csv_rows", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "unique_id": "macro.dbt_databricks.databricks__load_csv_rows", "macro_sql": "{% macro databricks__load_csv_rows(model, agate_table) %}\n\n  {% set batch_size = get_batch_size() %}\n  {% set column_override = model['config'].get('column_types', {}) %}\n\n  {% set statements = [] %}\n\n  {% for chunk in agate_table.rows | batch(batch_size) %}\n      {% set bindings = [] %}\n\n      {% for row in chunk %}\n          {% do bindings.extend(row) %}\n      {% endfor %}\n\n      {% set sql %}\n          insert {% if loop.index0 == 0 -%} overwrite {% else -%} into {% endif -%} {{ this.render() }} values\n          {% for row in chunk -%}\n              ({%- for col_name in agate_table.column_names -%}\n                  {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n                  {%- set type = column_override.get(col_name, inferred_type) -%}\n                    cast({{ get_binding_char() }} as {{type}})\n                  {%- if not loop.last%},{%- endif %}\n              {%- endfor -%})\n              {%- if not loop.last%},{%- endif %}\n          {%- endfor %}\n      {% endset %}\n\n      {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True, close_cursor=True) %}\n\n      {% if loop.index0 == 0 %}\n          {% do statements.append(sql) %}\n      {% endif %}\n  {% endfor %}\n\n  {# Return SQL so we can render it out into the compiled files #}\n  {{ return(statements[0]) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_batch_size", "macro.dbt.get_binding_char"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.856801, "supported_languages": null}, "macro.dbt_databricks.databricks__create_csv_table": {"name": "databricks__create_csv_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "unique_id": "macro.dbt_databricks.databricks__create_csv_table", "macro_sql": "{% macro databricks__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n    {{ file_format_clause() }}\n    {{ partition_cols(label=\"partitioned by\") }}\n    {{ clustered_cols(label=\"clustered by\") }}\n    {{ location_clause() }}\n    {{ comment_clause() }}\n    {{ tblproperties_clause() }}\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.file_format_clause", "macro.dbt_spark.partition_cols", "macro.dbt_spark.clustered_cols", "macro.dbt_spark.location_clause", "macro.dbt_spark.comment_clause", "macro.dbt_databricks.tblproperties_clause", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.860628, "supported_languages": null}, "macro.dbt_databricks.materialization_view_databricks": {"name": "materialization_view_databricks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/view.sql", "original_file_path": "macros/materializations/view.sql", "unique_id": "macro.dbt_databricks.materialization_view_databricks", "macro_sql": "{% materialization view, adapter='databricks' -%}\n    {{ return(create_or_replace_view()) }}\n{%- endmaterialization %}", "depends_on": {"macros": ["macro.dbt.create_or_replace_view"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.861295, "supported_languages": ["sql"]}, "macro.dbt_databricks.materialization_table_databricks": {"name": "materialization_table_databricks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/table.sql", "original_file_path": "macros/materializations/table.sql", "unique_id": "macro.dbt_databricks.materialization_table_databricks", "macro_sql": "{% materialization table, adapter = 'databricks', supported_languages=['sql', 'python'] %}\n  {%- set language = model['language'] -%}\n  {%- set identifier = model['alias'] -%}\n  {%- set grant_config = config.get('grants') -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier, needs_information=True) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier,\n                                                schema=schema,\n                                                database=database,\n                                                type='table') -%}\n\n  {{ run_hooks(pre_hooks) }}\n\n  -- setup: if the target relation already exists, drop it\n  -- in case if the existing and future table is delta, we want to do a\n  -- create or replace table instead of dropping, so we don't have the table unavailable\n  {% if old_relation and not (old_relation.is_delta and config.get('file_format', default='delta') == 'delta') -%}\n    {{ adapter.drop_relation(old_relation) }}\n  {%- endif %}\n\n  -- build model\n\n  {%- call statement('main', language=language) -%}\n    {{ create_table_as(False, target_relation, compiled_code, language) }}\n  {%- endcall -%}\n\n  {% set should_revoke = should_revoke(old_relation, full_refresh_mode=True) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {% do persist_constraints(target_relation, model) %}\n\n  {% do optimize(target_relation) %}\n\n  {{ run_hooks(post_hooks) }}\n\n  {{ return({'relations': [target_relation]})}}\n\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt.run_hooks", "macro.dbt.statement", "macro.dbt.create_table_as", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs", "macro.dbt_databricks.persist_constraints", "macro.dbt_databricks.optimize"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.8672268, "supported_languages": ["sql", "python"]}, "macro.dbt_databricks.databricks_build_snapshot_staging_table": {"name": "databricks_build_snapshot_staging_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_databricks.databricks_build_snapshot_staging_table", "macro_sql": "{% macro databricks_build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_identifier = target_relation.identifier ~ '__dbt_tmp' %}\n\n    {%- set tmp_relation = api.Relation.create(identifier=tmp_identifier,\n                                               schema=target_relation.schema,\n                                               database=target_relation.database,\n                                               type='view') -%}\n\n    {% set select = snapshot_staging_table(strategy, sql, target_relation) %}\n\n    {# needs to be a non-temp view so that its columns can be ascertained via `describe` #}\n    {% call statement('build_snapshot_staging_relation') %}\n        {{ create_view_as(tmp_relation, select) }}\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.snapshot_staging_table", "macro.dbt.statement", "macro.dbt.create_view_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.884301, "supported_languages": null}, "macro.dbt_databricks.materialization_snapshot_databricks": {"name": "materialization_snapshot_databricks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_databricks.materialization_snapshot_databricks", "macro_sql": "{% materialization snapshot, adapter='databricks' %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n  {%- set file_format = config.get('file_format', 'delta') -%}\n  {%- set grant_config = config.get('grants') -%}\n\n  {% set target_relation_exists, target_relation = databricks__get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table',\n          needs_information=True) -%}\n\n  {%- if file_format not in ['delta', 'hudi'] -%}\n    {% set invalid_format_msg -%}\n      Invalid file format: {{ file_format }}\n      Snapshot functionality requires file_format be set to 'delta' or 'hudi'\n    {%- endset %}\n    {% do exceptions.raise_compiler_error(invalid_format_msg) %}\n  {% endif %}\n\n  {%- if target_relation_exists -%}\n    {%- if not target_relation.is_delta and not target_relation.is_hudi -%}\n      {% set invalid_format_msg -%}\n        The existing table {{ model.schema }}.{{ target_table }} is in another format than 'delta' or 'hudi'\n      {%- endset %}\n      {% do exceptions.raise_compiler_error(invalid_format_msg) %}\n    {% endif %}\n  {% endif %}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['compiled_code']) %}\n      {% set final_sql = create_table_as(False, target_relation, build_sql) %}\n\n      {% call statement('main') %}\n          {{ final_sql }}\n      {% endcall %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% if target_relation.database is none %}\n          {% set staging_table = spark_build_snapshot_staging_table(strategy, sql, target_relation) %}\n      {% else %}\n          {% set staging_table = databricks_build_snapshot_staging_table(strategy, sql, target_relation) %}\n      {% endif %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% set final_sql = snapshot_merge_sql(\n            target = target_relation,\n            source = staging_table,\n            insert_cols = quoted_source_columns\n         )\n      %}\n\n      {% call statement_with_staging_table('main', staging_table) %}\n          {{ final_sql }}\n      {% endcall %}\n\n  {% endif %}\n\n  {% set should_revoke = should_revoke(target_relation_exists, full_refresh_mode) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {% do persist_constraints(target_relation, model) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_or_create_relation", "macro.dbt.run_hooks", "macro.dbt.strategy_dispatch", "macro.dbt.build_snapshot_table", "macro.dbt.create_table_as", "macro.dbt.statement", "macro.dbt_spark.spark_build_snapshot_staging_table", "macro.dbt_databricks.databricks_build_snapshot_staging_table", "macro.dbt.create_columns", "macro.dbt.snapshot_merge_sql", "macro.dbt_databricks.statement_with_staging_table", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs", "macro.dbt_databricks.persist_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.896739, "supported_languages": ["sql"]}, "macro.dbt_databricks.dbt_databricks_validate_get_file_format": {"name": "dbt_databricks_validate_get_file_format", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/validate.sql", "original_file_path": "macros/materializations/incremental/validate.sql", "unique_id": "macro.dbt_databricks.dbt_databricks_validate_get_file_format", "macro_sql": "{% macro dbt_databricks_validate_get_file_format(raw_file_format) %}\n  {#-- Validate the file format #}\n\n  {% set accepted_formats = ['text', 'csv', 'json', 'jdbc', 'parquet', 'orc', 'hive', 'delta', 'libsvm', 'hudi'] %}\n\n  {% set invalid_file_format_msg -%}\n    Invalid file format provided: {{ raw_file_format }}\n    Expected one of: {{ accepted_formats | join(', ') }}\n  {%- endset %}\n\n  {% if raw_file_format not in accepted_formats %}\n    {% do exceptions.raise_compiler_error(invalid_file_format_msg) %}\n  {% endif %}\n\n  {% do return(raw_file_format) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.900279, "supported_languages": null}, "macro.dbt_databricks.dbt_databricks_validate_get_incremental_strategy": {"name": "dbt_databricks_validate_get_incremental_strategy", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/validate.sql", "original_file_path": "macros/materializations/incremental/validate.sql", "unique_id": "macro.dbt_databricks.dbt_databricks_validate_get_incremental_strategy", "macro_sql": "{% macro dbt_databricks_validate_get_incremental_strategy(raw_strategy, file_format) %}\n  {#-- Validate the incremental strategy #}\n\n  {% set invalid_strategy_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    Expected one of: 'merge', 'replace_where', 'append', 'insert_overwrite'\n  {%- endset %}\n\n  {% set invalid_delta_only_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    You can only choose this strategy when file_format is set to 'delta'\n  {%- endset %}\n\n  {% set invalid_insert_overwrite_endpoint_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    You cannot use this strategy when connecting via warehouse\n    Use the 'merge' or 'replace_where' strategy instead\n  {%- endset %}\n\n  {% if raw_strategy not in ['append', 'merge', 'insert_overwrite', 'replace_where'] %}\n    {% do exceptions.raise_compiler_error(invalid_strategy_msg) %}\n  {%-else %}\n    {% if raw_strategy == 'merge' and file_format not in ['delta', 'hudi'] %}\n      {% do exceptions.raise_compiler_error(invalid_delta_only_msg) %}\n    {% endif %}\n    {% if raw_strategy == 'replace_where' and file_format not in ['delta'] %}\n      {% do exceptions.raise_compiler_error(invalid_delta_only_msg) %}\n    {% endif %}\n    {% if raw_strategy == 'insert_overwrite' and target.endpoint %}\n      {% do exceptions.raise_compiler_error(invalid_insert_overwrite_endpoint_msg) %}\n    {% endif %}\n  {% endif %}\n\n  {% do return(raw_strategy) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.903588, "supported_languages": null}, "macro.dbt_databricks.databricks__get_incremental_default_sql": {"name": "databricks__get_incremental_default_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.databricks__get_incremental_default_sql", "macro_sql": "{% macro databricks__get_incremental_default_sql(arg_dict) %}\n  {{ return(get_incremental_merge_sql(arg_dict)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_incremental_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.909523, "supported_languages": null}, "macro.dbt_databricks.databricks__get_incremental_append_sql": {"name": "databricks__get_incremental_append_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.databricks__get_incremental_append_sql", "macro_sql": "{% macro databricks__get_incremental_append_sql(arg_dict) %}\n  {% do return(get_insert_into_sql(arg_dict[\"temp_relation\"], arg_dict[\"target_relation\"])) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_insert_into_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.910201, "supported_languages": null}, "macro.dbt_databricks.databricks__get_incremental_replace_where_sql": {"name": "databricks__get_incremental_replace_where_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.databricks__get_incremental_replace_where_sql", "macro_sql": "{% macro databricks__get_incremental_replace_where_sql(arg_dict) %}\n  {% do return(get_replace_where_sql(arg_dict)) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_replace_where_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.9107132, "supported_languages": null}, "macro.dbt_databricks.get_incremental_replace_where_sql": {"name": "get_incremental_replace_where_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.get_incremental_replace_where_sql", "macro_sql": "{% macro get_incremental_replace_where_sql(arg_dict) %}\n\n  {{ return(adapter.dispatch('get_incremental_replace_where_sql', 'dbt')(arg_dict)) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_incremental_replace_where_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.911335, "supported_languages": null}, "macro.dbt_databricks.databricks__get_insert_overwrite_merge_sql": {"name": "databricks__get_insert_overwrite_merge_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.databricks__get_insert_overwrite_merge_sql", "macro_sql": "{% macro databricks__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates, include_sql_header) %}\n    {{ return(get_insert_overwrite_sql(source, target)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_insert_overwrite_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.9119859, "supported_languages": null}, "macro.dbt_databricks.get_insert_overwrite_sql": {"name": "get_insert_overwrite_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.get_insert_overwrite_sql", "macro_sql": "{% macro get_insert_overwrite_sql(source_relation, target_relation) %}\n\n    {%- set dest_columns = adapter.get_columns_in_relation(target_relation) -%}\n    {%- set dest_cols_csv = dest_columns | map(attribute='quoted') | join(', ') -%}\n    insert overwrite table {{ target_relation }}\n    {{ partition_cols(label=\"partition\") }}\n    select {{dest_cols_csv}} from {{ source_relation }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.partition_cols"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.91319, "supported_languages": null}, "macro.dbt_databricks.get_replace_where_sql": {"name": "get_replace_where_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.get_replace_where_sql", "macro_sql": "{% macro get_replace_where_sql(args_dict) -%}\n    {%- set predicates = args_dict['incremental_predicates'] -%}\n    {%- set target_relation = args_dict['target_relation'] -%}\n    {%- set temp_relation = args_dict['temp_relation'] -%}\n\n    insert into {{ target_relation }}\n    {% if predicates %}\n      {% if predicates is sequence and predicates is not string %}\n    replace where {{ predicates | join(' and ') }}\n      {% else %}\n    replace where {{ predicates }}\n      {% endif %}\n    {% endif %}\n    table {{ temp_relation }}\n        \n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.914867, "supported_languages": null}, "macro.dbt_databricks.get_insert_into_sql": {"name": "get_insert_into_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.get_insert_into_sql", "macro_sql": "{% macro get_insert_into_sql(source_relation, target_relation) %}\n\n    {%- set dest_columns = adapter.get_columns_in_relation(target_relation) -%}\n    {%- set dest_cols_csv = dest_columns | map(attribute='quoted') | join(', ') -%}\n    insert into table {{ target_relation }}\n    select {{dest_cols_csv}} from {{ source_relation }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.915921, "supported_languages": null}, "macro.dbt_databricks.databricks__get_merge_sql": {"name": "databricks__get_merge_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.databricks__get_merge_sql", "macro_sql": "{% macro databricks__get_merge_sql(target, source, unique_key, dest_columns, incremental_predicates) %}\n  {# need dest_columns for merge_exclude_columns, default to use \"*\" #}\n  {%- set predicates = [] if incremental_predicates is none else [] + incremental_predicates -%}\n  {%- set dest_columns = adapter.get_columns_in_relation(target) -%}\n  {%- set merge_update_columns = config.get('merge_update_columns') -%}\n  {%- set merge_exclude_columns = config.get('merge_exclude_columns') -%}\n  {%- set update_columns = get_merge_update_columns(merge_update_columns, merge_exclude_columns, dest_columns) -%}\n\n  {% if unique_key %}\n      {% if unique_key is sequence and unique_key is not mapping and unique_key is not string %}\n          {% for key in unique_key %}\n              {% set this_key_match %}\n                  DBT_INTERNAL_SOURCE.{{ key }} = DBT_INTERNAL_DEST.{{ key }}\n              {% endset %}\n              {% do predicates.append(this_key_match) %}\n          {% endfor %}\n      {% else %}\n          {% set unique_key_match %}\n              DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n          {% endset %}\n          {% do predicates.append(unique_key_match) %}\n      {% endif %}\n  {% else %}\n      {% do predicates.append('FALSE') %}\n  {% endif %}\n\n  {{ sql_header if sql_header is not none }}\n\n  merge into {{ target }} as DBT_INTERNAL_DEST\n      using {{ source }} as DBT_INTERNAL_SOURCE\n      on {{ predicates | join(' and ') }}\n\n      when matched then update set\n        {% if update_columns -%}{%- for column_name in update_columns %}\n            {{ column_name }} = DBT_INTERNAL_SOURCE.{{ column_name }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n        {%- else %} * {% endif %}\n\n      when not matched then insert *\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_merge_update_columns"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.9205408, "supported_languages": null}, "macro.dbt_databricks.materialization_incremental_databricks": {"name": "materialization_incremental_databricks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/incremental.sql", "original_file_path": "macros/materializations/incremental/incremental.sql", "unique_id": "macro.dbt_databricks.materialization_incremental_databricks", "macro_sql": "{% materialization incremental, adapter='databricks', supported_languages=['sql', 'python'] -%}\n  {#-- Validate early so we don't run SQL if the file_format + strategy combo is invalid --#}\n  {%- set raw_file_format = config.get('file_format', default='delta') -%}\n  {%- set raw_strategy = config.get('incremental_strategy') or 'merge' -%}\n  {%- set grant_config = config.get('grants') -%}\n\n  {%- set file_format = dbt_databricks_validate_get_file_format(raw_file_format) -%}\n  {%- set incremental_strategy = dbt_databricks_validate_get_incremental_strategy(raw_strategy, file_format) -%}\n\n  {#-- Set vars --#}\n\n  {%- set incremental_predicates = config.get('predicates', default=none) or config.get('incremental_predicates', default=none) -%}\n  {%- set unique_key = config.get('unique_key', none) -%}\n  {%- set partition_by = config.get('partition_by', none) -%}\n  {%- set language = model['language'] -%}\n  {%- set on_schema_change = incremental_validate_on_schema_change(config.get('on_schema_change'), default='ignore') -%}\n  {%- set target_relation = this -%}\n  {%- set existing_relation = adapter.get_relation(database=this.database, schema=this.schema, identifier=this.identifier, needs_information=True) -%}\n\n  {#-- Set Overwrite Mode - does not work for warehouses --#}\n  {%- if incremental_strategy == 'insert_overwrite' and partition_by -%}\n    {%- call statement() -%}\n      set spark.sql.sources.partitionOverwriteMode = DYNAMIC\n    {%- endcall -%}\n  {%- endif -%}\n\n  {#-- Run pre-hooks --#}\n  {{ run_hooks(pre_hooks) }}\n\n  {#-- Incremental run logic --#}\n  {%- if existing_relation is none -%}\n    {#-- Relation must be created --#}\n    {%- call statement('main', language=language) -%}\n      {{ create_table_as(False, target_relation, compiled_code, language) }}\n    {%- endcall -%}\n    {% do persist_constraints(target_relation, model) %}\n  {%- elif existing_relation.is_view or should_full_refresh() -%}\n    {#-- Relation must be dropped & recreated --#}\n    {% set is_delta = (file_format == 'delta' and existing_relation.is_delta) %}\n    {% if not is_delta %} {#-- If Delta, we will `create or replace` below, so no need to drop --#}\n      {% do adapter.drop_relation(existing_relation) %}\n    {% endif %}\n    {%- call statement('main', language=language) -%}\n      {{ create_table_as(False, target_relation, compiled_code, language) }}\n    {%- endcall -%}\n\n    {% if not existing_relation.is_view %}\n      {% do persist_constraints(target_relation, model) %}\n    {% endif %}\n  {%- else -%}\n    {#-- Relation must be merged --#}\n    {%- set temp_relation = databricks__make_temp_relation(target_relation, as_table=language != 'sql') -%}\n    {%- call statement('create_temp_relation', language=language) -%}\n      {{ create_table_as(True, temp_relation, compiled_code, language) }}\n    {%- endcall -%}\n    {%- do process_schema_changes(on_schema_change, temp_relation, existing_relation) -%}\n    {%- set strategy_sql_macro_func = adapter.get_incremental_strategy_macro(context, incremental_strategy) -%}\n    {%- set strategy_arg_dict = ({\n            'target_relation': target_relation,\n            'temp_relation': temp_relation,\n            'unique_key': unique_key,\n            'dest_columns': none,\n            'incremental_predicates': incremental_predicates}) -%}\n    {%- set build_sql = strategy_sql_macro_func(strategy_arg_dict) -%}\n    {%- if language == 'sql' -%}\n      {%- call statement('main') -%}\n        {{ build_sql }}\n      {%- endcall -%}\n    {%- elif language == 'python' -%}\n      {%- call statement_with_staging_table('main', temp_relation) -%}\n        {{ build_sql }}\n      {%- endcall -%}\n      {#--\n      This is yucky.\n      See note in dbt-spark/dbt/include/spark/macros/adapters.sql\n      re: python models and temporary views.\n\n      Also, why does not either drop_relation or adapter.drop_relation work here?!\n      --#}\n    {%- endif -%}\n  {%- endif -%}\n\n  {% set should_revoke = should_revoke(existing_relation, full_refresh_mode) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n\n  {% do optimize(target_relation) %}\n\n  {{ run_hooks(post_hooks) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "depends_on": {"macros": ["macro.dbt_databricks.dbt_databricks_validate_get_file_format", "macro.dbt_databricks.dbt_databricks_validate_get_incremental_strategy", "macro.dbt.incremental_validate_on_schema_change", "macro.dbt.statement", "macro.dbt.run_hooks", "macro.dbt.create_table_as", "macro.dbt_databricks.persist_constraints", "macro.dbt.should_full_refresh", "macro.dbt_databricks.databricks__make_temp_relation", "macro.dbt.process_schema_changes", "macro.dbt_databricks.statement_with_staging_table", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs", "macro.dbt_databricks.optimize"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.933613, "supported_languages": ["sql", "python"]}, "macro.dbt_databricks.databricks__dateadd": {"name": "databricks__dateadd", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/utils/dateadd.sql", "original_file_path": "macros/utils/dateadd.sql", "unique_id": "macro.dbt_databricks.databricks__dateadd", "macro_sql": "{% macro databricks__dateadd(datepart, interval, from_date_or_timestamp) %}\n  {%- if adapter.compare_dbr_version(10, 4) >= 0 -%}\n    timestampadd({{datepart}}, {{interval}}, {{from_date_or_timestamp}})\n  {%- else -%}\n    {{ spark__dateadd(datepart, interval, from_date_or_timestamp) }}\n  {%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__dateadd"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.9350731, "supported_languages": null}, "macro.dbt_databricks.databricks__datediff": {"name": "databricks__datediff", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/utils/datediff.sql", "original_file_path": "macros/utils/datediff.sql", "unique_id": "macro.dbt_databricks.databricks__datediff", "macro_sql": "{% macro databricks__datediff(first_date, second_date, datepart) %}\n  {%- if adapter.compare_dbr_version(10, 4) >= 0 -%}\n    timestampdiff({{datepart}}, {{date_trunc(datepart, first_date)}}, {{date_trunc(datepart, second_date)}})\n  {%- else -%}\n    {{ spark__datediff(first_date, second_date, datepart) }}\n  {%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.date_trunc", "macro.dbt_spark.spark__datediff"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.9366028, "supported_languages": null}, "macro.dbt_spark.dbt_spark_tblproperties_clause": {"name": "dbt_spark_tblproperties_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.dbt_spark_tblproperties_clause", "macro_sql": "{% macro dbt_spark_tblproperties_clause() -%}\n  {%- set tblproperties = config.get('tblproperties') -%}\n  {%- if tblproperties is not none %}\n    tblproperties (\n      {%- for prop in tblproperties -%}\n      '{{ prop }}' = '{{ tblproperties[prop] }}' {% if not loop.last %}, {% endif %}\n      {%- endfor %}\n    )\n  {%- endif %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.974954, "supported_languages": null}, "macro.dbt_spark.file_format_clause": {"name": "file_format_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.file_format_clause", "macro_sql": "{% macro file_format_clause() %}\n  {{ return(adapter.dispatch('file_format_clause', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_databricks.databricks__file_format_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.975538, "supported_languages": null}, "macro.dbt_spark.spark__file_format_clause": {"name": "spark__file_format_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__file_format_clause", "macro_sql": "{% macro spark__file_format_clause() %}\n  {%- set file_format = config.get('file_format', validator=validation.any[basestring]) -%}\n  {%- if file_format is not none %}\n    using {{ file_format }}\n  {%- endif %}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.9764018, "supported_languages": null}, "macro.dbt_spark.location_clause": {"name": "location_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.location_clause", "macro_sql": "{% macro location_clause() %}\n  {{ return(adapter.dispatch('location_clause', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_spark.spark__location_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.976963, "supported_languages": null}, "macro.dbt_spark.spark__location_clause": {"name": "spark__location_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__location_clause", "macro_sql": "{% macro spark__location_clause() %}\n  {%- set location_root = config.get('location_root', validator=validation.any[basestring]) -%}\n  {%- set identifier = model['alias'] -%}\n  {%- if location_root is not none %}\n    location '{{ location_root }}/{{ identifier }}'\n  {%- endif %}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.978069, "supported_languages": null}, "macro.dbt_spark.options_clause": {"name": "options_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.options_clause", "macro_sql": "{% macro options_clause() -%}\n  {{ return(adapter.dispatch('options_clause', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_databricks.databricks__options_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.978624, "supported_languages": null}, "macro.dbt_spark.spark__options_clause": {"name": "spark__options_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__options_clause", "macro_sql": "{% macro spark__options_clause() -%}\n  {%- set options = config.get('options') -%}\n  {%- if config.get('file_format') == 'hudi' -%}\n    {%- set unique_key = config.get('unique_key') -%}\n    {%- if unique_key is not none and options is none -%}\n      {%- set options = {'primaryKey': config.get('unique_key')} -%}\n    {%- elif unique_key is not none and options is not none and 'primaryKey' not in options -%}\n      {%- set _ = options.update({'primaryKey': config.get('unique_key')}) -%}\n    {%- elif options is not none and 'primaryKey' in options and options['primaryKey'] != unique_key -%}\n      {{ exceptions.raise_compiler_error(\"unique_key and options('primaryKey') should be the same column(s).\") }}\n    {%- endif %}\n  {%- endif %}\n\n  {%- if options is not none %}\n    options (\n      {%- for option in options -%}\n      {{ option }} \"{{ options[option] }}\" {% if not loop.last %}, {% endif %}\n      {%- endfor %}\n    )\n  {%- endif %}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.9820092, "supported_languages": null}, "macro.dbt_spark.comment_clause": {"name": "comment_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.comment_clause", "macro_sql": "{% macro comment_clause() %}\n  {{ return(adapter.dispatch('comment_clause', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_spark.spark__comment_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.982589, "supported_languages": null}, "macro.dbt_spark.spark__comment_clause": {"name": "spark__comment_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__comment_clause", "macro_sql": "{% macro spark__comment_clause() %}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n\n  {%- if raw_persist_docs is mapping -%}\n    {%- set raw_relation = raw_persist_docs.get('relation', false) -%}\n      {%- if raw_relation -%}\n      comment '{{ model.description | replace(\"'\", \"\\\\'\") }}'\n      {% endif %}\n  {%- elif raw_persist_docs -%}\n    {{ exceptions.raise_compiler_error(\"Invalid value provided for 'persist_docs'. Expected dict but got value: \" ~ raw_persist_docs) }}\n  {% endif %}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.984131, "supported_languages": null}, "macro.dbt_spark.partition_cols": {"name": "partition_cols", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.partition_cols", "macro_sql": "{% macro partition_cols(label, required=false) %}\n  {{ return(adapter.dispatch('partition_cols', 'dbt')(label, required)) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_spark.spark__partition_cols"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.984854, "supported_languages": null}, "macro.dbt_spark.spark__partition_cols": {"name": "spark__partition_cols", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__partition_cols", "macro_sql": "{% macro spark__partition_cols(label, required=false) %}\n  {%- set cols = config.get('partition_by', validator=validation.any[list, basestring]) -%}\n  {%- if cols is not none %}\n    {%- if cols is string -%}\n      {%- set cols = [cols] -%}\n    {%- endif -%}\n    {{ label }} (\n    {%- for item in cols -%}\n      {{ item }}\n      {%- if not loop.last -%},{%- endif -%}\n    {%- endfor -%}\n    )\n  {%- endif %}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.986561, "supported_languages": null}, "macro.dbt_spark.clustered_cols": {"name": "clustered_cols", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.clustered_cols", "macro_sql": "{% macro clustered_cols(label, required=false) %}\n  {{ return(adapter.dispatch('clustered_cols', 'dbt')(label, required)) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_spark.spark__clustered_cols"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.987296, "supported_languages": null}, "macro.dbt_spark.spark__clustered_cols": {"name": "spark__clustered_cols", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__clustered_cols", "macro_sql": "{% macro spark__clustered_cols(label, required=false) %}\n  {%- set cols = config.get('clustered_by', validator=validation.any[list, basestring]) -%}\n  {%- set buckets = config.get('buckets', validator=validation.any[int]) -%}\n  {%- if (cols is not none) and (buckets is not none) %}\n    {%- if cols is string -%}\n      {%- set cols = [cols] -%}\n    {%- endif -%}\n    {{ label }} (\n    {%- for item in cols -%}\n      {{ item }}\n      {%- if not loop.last -%},{%- endif -%}\n    {%- endfor -%}\n    ) into {{ buckets }} buckets\n  {%- endif %}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.989547, "supported_languages": null}, "macro.dbt_spark.fetch_tbl_properties": {"name": "fetch_tbl_properties", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.fetch_tbl_properties", "macro_sql": "{% macro fetch_tbl_properties(relation) -%}\n  {% call statement('list_properties', fetch_result=True) -%}\n    SHOW TBLPROPERTIES {{ relation }}\n  {% endcall %}\n  {% do return(load_result('list_properties').table) %}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.990709, "supported_languages": null}, "macro.dbt_spark.create_temporary_view": {"name": "create_temporary_view", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.create_temporary_view", "macro_sql": "{% macro create_temporary_view(relation, compiled_code) -%}\n  {{ return(adapter.dispatch('create_temporary_view', 'dbt')(relation, compiled_code)) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_spark.spark__create_temporary_view"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.991406, "supported_languages": null}, "macro.dbt_spark.spark__create_temporary_view": {"name": "spark__create_temporary_view", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__create_temporary_view", "macro_sql": "{% macro spark__create_temporary_view(relation, compiled_code) -%}\n    create temporary view {{ relation }} as\n      {{ compiled_code }}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.9918668, "supported_languages": null}, "macro.dbt_spark.spark__create_table_as": {"name": "spark__create_table_as", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__create_table_as", "macro_sql": "{%- macro spark__create_table_as(temporary, relation, compiled_code, language='sql') -%}\n  {%- if language == 'sql' -%}\n    {%- if temporary -%}\n      {{ create_temporary_view(relation, compiled_code) }}\n    {%- else -%}\n      {% if config.get('file_format', validator=validation.any[basestring]) in ['delta', 'iceberg'] %}\n        create or replace table {{ relation }}\n      {% else %}\n        create table {{ relation }}\n      {% endif %}\n      {%- set contract_config = config.get('contract') -%}\n      {%- if contract_config.enforced -%}\n        {{ get_assert_columns_equivalent(compiled_code) }}\n        {%- set compiled_code = get_select_subquery(compiled_code) %}\n      {% endif %}\n      {{ file_format_clause() }}\n      {{ options_clause() }}\n      {{ partition_cols(label=\"partitioned by\") }}\n      {{ clustered_cols(label=\"clustered by\") }}\n      {{ location_clause() }}\n      {{ comment_clause() }}\n      as\n      {{ compiled_code }}\n    {%- endif -%}\n  {%- elif language == 'python' -%}\n    {#--\n    N.B. Python models _can_ write to temp views HOWEVER they use a different session\n    and have already expired by the time they need to be used (I.E. in merges for incremental models)\n\n    TODO: Deep dive into spark sessions to see if we can reuse a single session for an entire\n    dbt invocation.\n     --#}\n    {{ py_write_table(compiled_code=compiled_code, target_relation=relation) }}\n  {%- endif -%}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": ["macro.dbt_spark.create_temporary_view", "macro.dbt.get_assert_columns_equivalent", "macro.dbt.get_select_subquery", "macro.dbt_spark.file_format_clause", "macro.dbt_spark.options_clause", "macro.dbt_spark.partition_cols", "macro.dbt_spark.clustered_cols", "macro.dbt_spark.location_clause", "macro.dbt_spark.comment_clause", "macro.dbt_spark.py_write_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.995266, "supported_languages": null}, "macro.dbt_spark.persist_constraints": {"name": "persist_constraints", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.persist_constraints", "macro_sql": "{% macro persist_constraints(relation, model) %}\n  {{ return(adapter.dispatch('persist_constraints', 'dbt')(relation, model)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__persist_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.99598, "supported_languages": null}, "macro.dbt_spark.spark__persist_constraints": {"name": "spark__persist_constraints", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__persist_constraints", "macro_sql": "{% macro spark__persist_constraints(relation, model) %}\n  {%- set contract_config = config.get('contract') -%}\n  {% if contract_config.enforced and config.get('file_format', 'delta') == 'delta' %}\n    {% do alter_table_add_constraints(relation, model.columns) %}\n    {% do alter_column_set_constraints(relation, model.columns) %}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.alter_table_add_constraints", "macro.dbt_spark.alter_column_set_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.997355, "supported_languages": null}, "macro.dbt_spark.alter_table_add_constraints": {"name": "alter_table_add_constraints", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.alter_table_add_constraints", "macro_sql": "{% macro alter_table_add_constraints(relation, constraints) %}\n  {{ return(adapter.dispatch('alter_table_add_constraints', 'dbt')(relation, constraints)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__alter_table_add_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405242.998056, "supported_languages": null}, "macro.dbt_spark.spark__alter_table_add_constraints": {"name": "spark__alter_table_add_constraints", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__alter_table_add_constraints", "macro_sql": "{% macro spark__alter_table_add_constraints(relation, column_dict) %}\n\n  {% for column_name in column_dict %}\n    {% set constraints = column_dict[column_name]['constraints'] %}\n    {% for constraint in constraints %}\n      {% if constraint.type == 'check' and not is_incremental() %}\n        {%- set constraint_hash = local_md5(column_name ~ \";\" ~ constraint.expression ~ \";\" ~ loop.index) -%}\n        {% call statement() %}\n          alter table {{ relation }} add constraint {{ constraint_hash }} check {{ constraint.expression }};\n        {% endcall %}\n      {% endif %}\n    {% endfor %}\n  {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.is_incremental", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.0001018, "supported_languages": null}, "macro.dbt_spark.alter_column_set_constraints": {"name": "alter_column_set_constraints", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.alter_column_set_constraints", "macro_sql": "{% macro alter_column_set_constraints(relation, column_dict) %}\n  {{ return(adapter.dispatch('alter_column_set_constraints', 'dbt')(relation, column_dict)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__alter_column_set_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.000818, "supported_languages": null}, "macro.dbt_spark.spark__alter_column_set_constraints": {"name": "spark__alter_column_set_constraints", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__alter_column_set_constraints", "macro_sql": "{% macro spark__alter_column_set_constraints(relation, column_dict) %}\n  {% for column_name in column_dict %}\n    {% set constraints = column_dict[column_name]['constraints'] %}\n    {% for constraint in constraints %}\n      {% if constraint.type != 'not_null' %}\n        {{ exceptions.warn('Invalid constraint for column ' ~ column_name ~ '. Only `not_null` is supported.') }}\n      {% else %}\n        {% set quoted_name = adapter.quote(column_name) if column_dict[column_name]['quote'] else column_name %}\n        {% call statement() %}\n          alter table {{ relation }} change column {{ quoted_name }} set not null {{ constraint.expression or \"\" }};\n        {% endcall %}\n      {% endif %}\n    {% endfor %}\n  {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.003148, "supported_languages": null}, "macro.dbt_spark.spark__create_view_as": {"name": "spark__create_view_as", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__create_view_as", "macro_sql": "{% macro spark__create_view_as(relation, sql) -%}\n  create or replace view {{ relation }}\n  {{ comment_clause() }}\n  {%- set contract_config = config.get('contract') -%}\n  {%- if contract_config.enforced -%}\n    {{ get_assert_columns_equivalent(sql) }}\n  {%- endif %}\n  as\n    {{ sql }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.comment_clause", "macro.dbt.get_assert_columns_equivalent"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.0042229, "supported_languages": null}, "macro.dbt_spark.spark__create_schema": {"name": "spark__create_schema", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__create_schema", "macro_sql": "{% macro spark__create_schema(relation) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{relation}}\n  {% endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.00481, "supported_languages": null}, "macro.dbt_spark.spark__drop_schema": {"name": "spark__drop_schema", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__drop_schema", "macro_sql": "{% macro spark__drop_schema(relation) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{ relation }} cascade\n  {%- endcall -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.005366, "supported_languages": null}, "macro.dbt_spark.get_columns_in_relation_raw": {"name": "get_columns_in_relation_raw", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.get_columns_in_relation_raw", "macro_sql": "{% macro get_columns_in_relation_raw(relation) -%}\n  {{ return(adapter.dispatch('get_columns_in_relation_raw', 'dbt')(relation)) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_spark.spark__get_columns_in_relation_raw"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.0059662, "supported_languages": null}, "macro.dbt_spark.spark__get_columns_in_relation_raw": {"name": "spark__get_columns_in_relation_raw", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__get_columns_in_relation_raw", "macro_sql": "{% macro spark__get_columns_in_relation_raw(relation) -%}\n  {% call statement('get_columns_in_relation_raw', fetch_result=True) %}\n      describe extended {{ relation }}\n  {% endcall %}\n  {% do return(load_result('get_columns_in_relation_raw').table) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.006856, "supported_languages": null}, "macro.dbt_spark.spark__get_columns_in_relation": {"name": "spark__get_columns_in_relation", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__get_columns_in_relation", "macro_sql": "{% macro spark__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      describe extended {{ relation.include(schema=(schema is not none)) }}\n  {% endcall %}\n  {% do return(load_result('get_columns_in_relation').table) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.007978, "supported_languages": null}, "macro.dbt_spark.spark__list_relations_without_caching": {"name": "spark__list_relations_without_caching", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__list_relations_without_caching", "macro_sql": "{% macro spark__list_relations_without_caching(relation) %}\n  {% call statement('list_relations_without_caching', fetch_result=True) -%}\n    show table extended in {{ relation }} like '*'\n  {% endcall %}\n\n  {% do return(load_result('list_relations_without_caching').table) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.0089412, "supported_languages": null}, "macro.dbt_spark.list_relations_show_tables_without_caching": {"name": "list_relations_show_tables_without_caching", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.list_relations_show_tables_without_caching", "macro_sql": "{% macro list_relations_show_tables_without_caching(schema_relation) %}\n  {#-- Spark with iceberg tables don't work with show table extended for #}\n  {#-- V2 iceberg tables #}\n  {#-- https://issues.apache.org/jira/browse/SPARK-33393 #}\n  {% call statement('list_relations_without_caching_show_tables', fetch_result=True) -%}\n    show tables in {{ schema_relation }} like '*'\n  {% endcall %}\n\n  {% do return(load_result('list_relations_without_caching_show_tables').table) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.009922, "supported_languages": null}, "macro.dbt_spark.describe_table_extended_without_caching": {"name": "describe_table_extended_without_caching", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.describe_table_extended_without_caching", "macro_sql": "{% macro describe_table_extended_without_caching(table_name) %}\n  {#-- Spark with iceberg tables don't work with show table extended for #}\n  {#-- V2 iceberg tables #}\n  {#-- https://issues.apache.org/jira/browse/SPARK-33393 #}\n  {% call statement('describe_table_extended_without_caching', fetch_result=True) -%}\n    describe extended {{ table_name }}\n  {% endcall %}\n  {% do return(load_result('describe_table_extended_without_caching').table) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.010893, "supported_languages": null}, "macro.dbt_spark.spark__list_schemas": {"name": "spark__list_schemas", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__list_schemas", "macro_sql": "{% macro spark__list_schemas(database) -%}\n  {% call statement('list_schemas', fetch_result=True, auto_begin=False) %}\n    show databases\n  {% endcall %}\n  {{ return(load_result('list_schemas').table) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.011759, "supported_languages": null}, "macro.dbt_spark.spark__rename_relation": {"name": "spark__rename_relation", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__rename_relation", "macro_sql": "{% macro spark__rename_relation(from_relation, to_relation) -%}\n  {% call statement('rename_relation') -%}\n    {% if not from_relation.type %}\n      {% do exceptions.raise_database_error(\"Cannot rename a relation with a blank type: \" ~ from_relation.identifier) %}\n    {% elif from_relation.type in ('table') %}\n        alter table {{ from_relation }} rename to {{ to_relation }}\n    {% elif from_relation.type == 'view' %}\n        alter view {{ from_relation }} rename to {{ to_relation }}\n    {% else %}\n      {% do exceptions.raise_database_error(\"Unknown type '\" ~ from_relation.type ~ \"' for relation: \" ~ from_relation.identifier) %}\n    {% endif %}\n  {%- endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.013912, "supported_languages": null}, "macro.dbt_spark.spark__drop_relation": {"name": "spark__drop_relation", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__drop_relation", "macro_sql": "{% macro spark__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }}\n  {%- endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.014647, "supported_languages": null}, "macro.dbt_spark.spark__generate_database_name": {"name": "spark__generate_database_name", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__generate_database_name", "macro_sql": "{% macro spark__generate_database_name(custom_database_name=none, node=none) -%}\n  {% do return(None) %}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.015187, "supported_languages": null}, "macro.dbt_spark.spark__persist_docs": {"name": "spark__persist_docs", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__persist_docs", "macro_sql": "{% macro spark__persist_docs(relation, model, for_relation, for_columns) -%}\n  {% if for_columns and config.persist_column_docs() and model.columns %}\n    {% do alter_column_comment(relation, model.columns) %}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.alter_column_comment"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.0160909, "supported_languages": null}, "macro.dbt_spark.spark__alter_column_comment": {"name": "spark__alter_column_comment", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__alter_column_comment", "macro_sql": "{% macro spark__alter_column_comment(relation, column_dict) %}\n  {% if config.get('file_format', validator=validation.any[basestring]) in ['delta', 'hudi', 'iceberg'] %}\n    {% for column_name in column_dict %}\n      {% set comment = column_dict[column_name]['description'] %}\n      {% set escaped_comment = comment | replace('\\'', '\\\\\\'') %}\n      {% set comment_query %}\n        {% if relation.is_iceberg %}\n          alter table {{ relation }} alter column\n              {{ adapter.quote(column_name) if column_dict[column_name]['quote'] else column_name }}\n              comment '{{ escaped_comment }}';\n        {% else %}\n          alter table {{ relation }} change column\n              {{ adapter.quote(column_name) if column_dict[column_name]['quote'] else column_name }}\n              comment '{{ escaped_comment }}';\n        {% endif %}\n      {% endset %}\n      {% do run_query(comment_query) %}\n    {% endfor %}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.01918, "supported_languages": null}, "macro.dbt_spark.spark__make_temp_relation": {"name": "spark__make_temp_relation", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__make_temp_relation", "macro_sql": "{% macro spark__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(path = {\n        \"identifier\": tmp_identifier\n    }) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.020212, "supported_languages": null}, "macro.dbt_spark.spark__alter_column_type": {"name": "spark__alter_column_type", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__alter_column_type", "macro_sql": "{% macro spark__alter_column_type(relation, column_name, new_column_type) -%}\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} alter column {{ column_name }} type {{ new_column_type }};\n  {% endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.020973, "supported_languages": null}, "macro.dbt_spark.spark__alter_relation_add_remove_columns": {"name": "spark__alter_relation_add_remove_columns", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__alter_relation_add_remove_columns", "macro_sql": "{% macro spark__alter_relation_add_remove_columns(relation, add_columns, remove_columns) %}\n\n  {% if remove_columns %}\n    {% if relation.is_delta %}\n      {% set platform_name = 'Delta Lake' %}\n    {% elif relation.is_iceberg %}\n      {% set platform_name = 'Iceberg' %}\n    {% else %}\n      {% set platform_name = 'Apache Spark' %}\n    {% endif %}\n    {{ exceptions.raise_compiler_error(platform_name + ' does not support dropping columns from tables') }}\n  {% endif %}\n\n  {% if add_columns is none %}\n    {% set add_columns = [] %}\n  {% endif %}\n\n  {% set sql -%}\n\n     alter {{ relation.type }} {{ relation }}\n\n       {% if add_columns %} add columns {% endif %}\n            {% for column in add_columns %}\n               {{ column.name }} {{ column.data_type }}{{ ',' if not loop.last }}\n            {% endfor %}\n\n  {%- endset -%}\n\n  {% do run_query(sql) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.023861, "supported_languages": null}, "macro.dbt_spark.spark__copy_grants": {"name": "spark__copy_grants", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/apply_grants.sql", "original_file_path": "macros/apply_grants.sql", "unique_id": "macro.dbt_spark.spark__copy_grants", "macro_sql": "{% macro spark__copy_grants() %}\n\n    {% if config.materialized == 'view' %}\n        {#-- Spark views don't copy grants when they're replaced --#}\n        {{ return(False) }}\n\n    {% else %}\n      {#-- This depends on how we're replacing the table, which depends on its file format\n        -- Just play it safe by assuming that grants have been copied over, and need to be checked / possibly revoked\n        -- We can make this more efficient in the future\n      #}\n        {{ return(True) }}\n\n    {% endif %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.025835, "supported_languages": null}, "macro.dbt_spark.spark__get_grant_sql": {"name": "spark__get_grant_sql", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/apply_grants.sql", "original_file_path": "macros/apply_grants.sql", "unique_id": "macro.dbt_spark.spark__get_grant_sql", "macro_sql": "\n\n\n{%- macro spark__get_grant_sql(relation, privilege, grantees) -%}\n    grant {{ privilege }} on {{ relation }} to {{ adapter.quote(grantees[0]) }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.026531, "supported_languages": null}, "macro.dbt_spark.spark__get_revoke_sql": {"name": "spark__get_revoke_sql", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/apply_grants.sql", "original_file_path": "macros/apply_grants.sql", "unique_id": "macro.dbt_spark.spark__get_revoke_sql", "macro_sql": "\n\n\n{%- macro spark__get_revoke_sql(relation, privilege, grantees) -%}\n    revoke {{ privilege }} on {{ relation }} from {{ adapter.quote(grantees[0]) }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.027222, "supported_languages": null}, "macro.dbt_spark.spark__support_multiple_grantees_per_dcl_statement": {"name": "spark__support_multiple_grantees_per_dcl_statement", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/apply_grants.sql", "original_file_path": "macros/apply_grants.sql", "unique_id": "macro.dbt_spark.spark__support_multiple_grantees_per_dcl_statement", "macro_sql": "\n\n\n{%- macro spark__support_multiple_grantees_per_dcl_statement() -%}\n    {{ return(False) }}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.02761, "supported_languages": null}, "macro.dbt_spark.spark__call_dcl_statements": {"name": "spark__call_dcl_statements", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/apply_grants.sql", "original_file_path": "macros/apply_grants.sql", "unique_id": "macro.dbt_spark.spark__call_dcl_statements", "macro_sql": "{% macro spark__call_dcl_statements(dcl_statement_list) %}\n    {% for dcl_statement in dcl_statement_list %}\n        {% call statement('grant_or_revoke') %}\n            {{ dcl_statement }}\n        {% endcall %}\n    {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.028399, "supported_languages": null}, "macro.dbt_spark.spark__get_binding_char": {"name": "spark__get_binding_char", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "unique_id": "macro.dbt_spark.spark__get_binding_char", "macro_sql": "{% macro spark__get_binding_char() %}\n  {{ return('?' if target.method == 'odbc' else '%s') }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.032792, "supported_languages": null}, "macro.dbt_spark.spark__reset_csv_table": {"name": "spark__reset_csv_table", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "unique_id": "macro.dbt_spark.spark__reset_csv_table", "macro_sql": "{% macro spark__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% if old_relation %}\n        {{ adapter.drop_relation(old_relation) }}\n    {% endif %}\n    {% set sql = create_csv_table(model, agate_table) %}\n    {{ return(sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.create_csv_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.033925, "supported_languages": null}, "macro.dbt_spark.spark__load_csv_rows": {"name": "spark__load_csv_rows", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "unique_id": "macro.dbt_spark.spark__load_csv_rows", "macro_sql": "{% macro spark__load_csv_rows(model, agate_table) %}\n\n  {% set batch_size = get_batch_size() %}\n  {% set column_override = model['config'].get('column_types', {}) %}\n\n  {% set statements = [] %}\n\n  {% for chunk in agate_table.rows | batch(batch_size) %}\n      {% set bindings = [] %}\n\n      {% for row in chunk %}\n          {% do bindings.extend(row) %}\n      {% endfor %}\n\n      {% set sql %}\n          insert into {{ this.render() }} values\n          {% for row in chunk -%}\n              ({%- for col_name in agate_table.column_names -%}\n                  {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n                  {%- set type = column_override.get(col_name, inferred_type) -%}\n                    cast({{ get_binding_char() }} as {{type}})\n                  {%- if not loop.last%},{%- endif %}\n              {%- endfor -%})\n              {%- if not loop.last%},{%- endif %}\n          {%- endfor %}\n      {% endset %}\n\n      {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n      {% if loop.index0 == 0 %}\n          {% do statements.append(sql) %}\n      {% endif %}\n  {% endfor %}\n\n  {# Return SQL so we can render it out into the compiled files #}\n  {{ return(statements[0]) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_batch_size", "macro.dbt.get_binding_char"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.038342, "supported_languages": null}, "macro.dbt_spark.spark__create_csv_table": {"name": "spark__create_csv_table", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "unique_id": "macro.dbt_spark.spark__create_csv_table", "macro_sql": "{% macro spark__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n    {{ file_format_clause() }}\n    {{ partition_cols(label=\"partitioned by\") }}\n    {{ clustered_cols(label=\"clustered by\") }}\n    {{ location_clause() }}\n    {{ comment_clause() }}\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.file_format_clause", "macro.dbt_spark.partition_cols", "macro.dbt_spark.clustered_cols", "macro.dbt_spark.location_clause", "macro.dbt_spark.comment_clause", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.042054, "supported_languages": null}, "macro.dbt_spark.materialization_view_spark": {"name": "materialization_view_spark", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/view.sql", "original_file_path": "macros/materializations/view.sql", "unique_id": "macro.dbt_spark.materialization_view_spark", "macro_sql": "{% materialization view, adapter='spark' -%}\n    {{ return(create_or_replace_view()) }}\n{%- endmaterialization %}", "depends_on": {"macros": ["macro.dbt.create_or_replace_view"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.04267, "supported_languages": ["sql"]}, "macro.dbt_spark.materialization_table_spark": {"name": "materialization_table_spark", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/table.sql", "original_file_path": "macros/materializations/table.sql", "unique_id": "macro.dbt_spark.materialization_table_spark", "macro_sql": "{% materialization table, adapter = 'spark', supported_languages=['sql', 'python'] %}\n  {%- set language = model['language'] -%}\n  {%- set identifier = model['alias'] -%}\n  {%- set grant_config = config.get('grants') -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier,\n                                                schema=schema,\n                                                database=database,\n                                                type='table') -%}\n\n  {{ run_hooks(pre_hooks) }}\n\n  -- setup: if the target relation already exists, drop it\n  -- in case if the existing and future table is delta or iceberg, we want to do a\n  -- create or replace table instead of dropping, so we don't have the table unavailable\n  {% if old_relation is not none %}\n    {% set is_delta = (old_relation.is_delta and config.get('file_format', validator=validation.any[basestring]) == 'delta') %}\n    {% set is_iceberg = (old_relation.is_iceberg and config.get('file_format', validator=validation.any[basestring]) == 'iceberg') %}\n    {% set old_relation_type = old_relation.type %}\n  {% else %}\n    {% set is_delta = false %}\n    {% set is_iceberg = false %}\n    {% set old_relation_type = target_relation.type %}\n  {% endif %}\n\n  {% if not is_delta and not is_iceberg %}\n    {% set existing_relation = target_relation %}\n    {{ adapter.drop_relation(existing_relation.incorporate(type=old_relation_type)) }}\n  {% endif %}\n\n  -- build model\n  {%- call statement('main', language=language) -%}\n    {{ create_table_as(False, target_relation, compiled_code, language) }}\n  {%- endcall -%}\n\n  {% set should_revoke = should_revoke(old_relation, full_refresh_mode=True) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {% do persist_constraints(target_relation, model) %}\n\n  {{ run_hooks(post_hooks) }}\n\n  {{ return({'relations': [target_relation]})}}\n\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt.run_hooks", "macro.dbt.statement", "macro.dbt.create_table_as", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs", "macro.dbt_spark.persist_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.0541189, "supported_languages": ["sql", "python"]}, "macro.dbt_spark.py_write_table": {"name": "py_write_table", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/table.sql", "original_file_path": "macros/materializations/table.sql", "unique_id": "macro.dbt_spark.py_write_table", "macro_sql": "{% macro py_write_table(compiled_code, target_relation) %}\n{{ compiled_code }}\n# --- Autogenerated dbt materialization code. --- #\ndbt = dbtObj(spark.table)\ndf = model(dbt, spark)\n\n# make sure pyspark exists in the namepace, for 7.3.x-scala2.12 it does not exist\nimport pyspark\n# make sure pandas exists before using it\ntry:\n  import pandas\n  pandas_available = True\nexcept ImportError:\n  pandas_available = False\n\n# make sure pyspark.pandas exists before using it\ntry:\n  import pyspark.pandas\n  pyspark_pandas_api_available = True\nexcept ImportError:\n  pyspark_pandas_api_available = False\n\n# make sure databricks.koalas exists before using it\ntry:\n  import databricks.koalas\n  koalas_available = True\nexcept ImportError:\n  koalas_available = False\n\n# preferentially convert pandas DataFrames to pandas-on-Spark or Koalas DataFrames first\n# since they know how to convert pandas DataFrames better than `spark.createDataFrame(df)`\n# and converting from pandas-on-Spark to Spark DataFrame has no overhead\nif pyspark_pandas_api_available and pandas_available and isinstance(df, pandas.core.frame.DataFrame):\n  df = pyspark.pandas.frame.DataFrame(df)\nelif koalas_available and pandas_available and isinstance(df, pandas.core.frame.DataFrame):\n  df = databricks.koalas.frame.DataFrame(df)\n\n# convert to pyspark.sql.dataframe.DataFrame\nif isinstance(df, pyspark.sql.dataframe.DataFrame):\n  pass  # since it is already a Spark DataFrame\nelif pyspark_pandas_api_available and isinstance(df, pyspark.pandas.frame.DataFrame):\n  df = df.to_spark()\nelif koalas_available and isinstance(df, databricks.koalas.frame.DataFrame):\n  df = df.to_spark()\nelif pandas_available and isinstance(df, pandas.core.frame.DataFrame):\n  df = spark.createDataFrame(df)\nelse:\n  msg = f\"{type(df)} is not a supported type for dbt Python materialization\"\n  raise Exception(msg)\n\ndf.write.mode(\"overwrite\").format(\"delta\").option(\"overwriteSchema\", \"true\").saveAsTable(\"{{ target_relation }}\")\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.0551941, "supported_languages": null}, "macro.dbt_spark.py_script_comment": {"name": "py_script_comment", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/table.sql", "original_file_path": "macros/materializations/table.sql", "unique_id": "macro.dbt_spark.py_script_comment", "macro_sql": "{%macro py_script_comment()%}\n# how to execute python model in notebook\n# dbt = dbtObj(spark.table)\n# df = model(dbt, spark)\n{%endmacro%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.055485, "supported_languages": null}, "macro.dbt_spark.spark__snapshot_hash_arguments": {"name": "spark__snapshot_hash_arguments", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_spark.spark__snapshot_hash_arguments", "macro_sql": "{% macro spark__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as string ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.0761201, "supported_languages": null}, "macro.dbt_spark.spark__snapshot_string_as_time": {"name": "spark__snapshot_string_as_time", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_spark.spark__snapshot_string_as_time", "macro_sql": "{% macro spark__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"to_timestamp('\" ~ timestamp ~ \"')\" -%}\n    {{ return(result) }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.07673, "supported_languages": null}, "macro.dbt_spark.spark__snapshot_merge_sql": {"name": "spark__snapshot_merge_sql", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_spark.spark__snapshot_merge_sql", "macro_sql": "{% macro spark__snapshot_merge_sql(target, source, insert_cols) -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n    {% if target.is_iceberg %}\n      {# create view only supports a name (no catalog, or schema) #}\n      using {{ source.identifier }} as DBT_INTERNAL_SOURCE\n    {% else %}\n      using {{ source }} as DBT_INTERNAL_SOURCE\n    {% endif %}\n    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id\n    when matched\n     and DBT_INTERNAL_DEST.dbt_valid_to is null\n     and DBT_INTERNAL_SOURCE.dbt_change_type in ('update', 'delete')\n        then update\n        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to\n\n    when not matched\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'\n        then insert *\n    ;\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.0776372, "supported_languages": null}, "macro.dbt_spark.spark_build_snapshot_staging_table": {"name": "spark_build_snapshot_staging_table", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_spark.spark_build_snapshot_staging_table", "macro_sql": "{% macro spark_build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_identifier = target_relation.identifier ~ '__dbt_tmp' %}\n\n    {% if target_relation.is_iceberg %}\n      {# iceberg catalog does not support create view, but regular spark does. We removed the catalog and schema #}\n      {%- set tmp_relation = api.Relation.create(identifier=tmp_identifier,\n                                                    schema=none,\n                                                    database=none,\n                                                    type='view') -%}\n    {% else %}\n      {%- set tmp_relation = api.Relation.create(identifier=tmp_identifier,\n                                                    schema=target_relation.schema,\n                                                    database=none,\n                                                    type='view') -%}\n    {% endif %}\n\n    {% set select = snapshot_staging_table(strategy, sql, target_relation) %}\n\n    {# needs to be a non-temp view so that its columns can be ascertained via `describe` #}\n    {% call statement('build_snapshot_staging_relation') %}\n        {{ create_view_as(tmp_relation, select) }}\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.snapshot_staging_table", "macro.dbt.statement", "macro.dbt.create_view_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.080176, "supported_languages": null}, "macro.dbt_spark.spark__post_snapshot": {"name": "spark__post_snapshot", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_spark.spark__post_snapshot", "macro_sql": "{% macro spark__post_snapshot(staging_relation) %}\n    {% do adapter.drop_relation(staging_relation) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.080679, "supported_languages": null}, "macro.dbt_spark.spark__create_columns": {"name": "spark__create_columns", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_spark.spark__create_columns", "macro_sql": "{% macro spark__create_columns(relation, columns) %}\n    {% if columns|length > 0 %}\n    {% call statement() %}\n      alter table {{ relation }} add columns (\n        {% for column in columns %}\n          `{{ column.name }}` {{ column.data_type }} {{- ',' if not loop.last -}}\n        {% endfor %}\n      );\n    {% endcall %}\n    {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.0819929, "supported_languages": null}, "macro.dbt_spark.materialization_snapshot_spark": {"name": "materialization_snapshot_spark", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_spark.materialization_snapshot_spark", "macro_sql": "{% materialization snapshot, adapter='spark' %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n  {%- set file_format = config.get('file_format', 'parquet') -%}\n  {%- set grant_config = config.get('grants') -%}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=none,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if file_format not in ['delta', 'iceberg', 'hudi'] -%}\n    {% set invalid_format_msg -%}\n      Invalid file format: {{ file_format }}\n      Snapshot functionality requires file_format be set to 'delta' or 'iceberg' or 'hudi'\n    {%- endset %}\n    {% do exceptions.raise_compiler_error(invalid_format_msg) %}\n  {% endif %}\n\n  {%- if target_relation_exists -%}\n    {%- if not target_relation.is_delta and not target_relation.is_iceberg and not target_relation.is_hudi -%}\n      {% set invalid_format_msg -%}\n        The existing table {{ model.schema }}.{{ target_table }} is in another format than 'delta' or 'iceberg' or 'hudi'\n      {%- endset %}\n      {% do exceptions.raise_compiler_error(invalid_format_msg) %}\n    {% endif %}\n  {% endif %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.schema) %}\n  {% endif %}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['compiled_code']) %}\n      {% set final_sql = create_table_as(False, target_relation, build_sql) %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = spark_build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% set final_sql = snapshot_merge_sql(\n            target = target_relation,\n            source = staging_table,\n            insert_cols = quoted_source_columns\n         )\n      %}\n\n  {% endif %}\n\n  {% call statement('main') %}\n      {{ final_sql }}\n  {% endcall %}\n\n  {% set should_revoke = should_revoke(target_relation_exists, full_refresh_mode) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt.get_or_create_relation", "macro.dbt.create_schema", "macro.dbt.run_hooks", "macro.dbt.strategy_dispatch", "macro.dbt.build_snapshot_table", "macro.dbt.create_table_as", "macro.dbt_spark.spark_build_snapshot_staging_table", "macro.dbt.create_columns", "macro.dbt.snapshot_merge_sql", "macro.dbt.statement", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs", "macro.dbt.post_snapshot"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.094221, "supported_languages": ["sql"]}, "macro.dbt_spark.spark__get_merge_update_columns": {"name": "spark__get_merge_update_columns", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/incremental/column_helpers.sql", "original_file_path": "macros/materializations/incremental/column_helpers.sql", "unique_id": "macro.dbt_spark.spark__get_merge_update_columns", "macro_sql": "{% macro spark__get_merge_update_columns(merge_update_columns, merge_exclude_columns, dest_columns) %}\n  {%- set default_cols = None -%}\n\n  {%- if merge_update_columns and merge_exclude_columns -%}\n    {{ exceptions.raise_compiler_error(\n        'Model cannot specify merge_update_columns and merge_exclude_columns. Please update model to use only one config'\n    )}}\n  {%- elif merge_update_columns -%}\n    {%- set update_columns = merge_update_columns -%}\n  {%- elif merge_exclude_columns -%}\n    {%- set update_columns = [] -%}\n    {%- for column in dest_columns -%}\n      {% if column.column | lower not in merge_exclude_columns | map(\"lower\") | list %}\n        {%- do update_columns.append(column.quoted) -%}\n      {% endif %}\n    {%- endfor -%}\n  {%- else -%}\n    {%- set update_columns = default_cols -%}\n  {%- endif -%}\n\n  {{ return(update_columns) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.097125, "supported_languages": null}, "macro.dbt_spark.dbt_spark_validate_get_file_format": {"name": "dbt_spark_validate_get_file_format", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/incremental/validate.sql", "original_file_path": "macros/materializations/incremental/validate.sql", "unique_id": "macro.dbt_spark.dbt_spark_validate_get_file_format", "macro_sql": "{% macro dbt_spark_validate_get_file_format(raw_file_format) %}\n  {#-- Validate the file format #}\n\n  {% set accepted_formats = ['text', 'csv', 'json', 'jdbc', 'parquet', 'orc', 'hive', 'delta', 'iceberg', 'libsvm', 'hudi'] %}\n\n  {% set invalid_file_format_msg -%}\n    Invalid file format provided: {{ raw_file_format }}\n    Expected one of: {{ accepted_formats | join(', ') }}\n  {%- endset %}\n\n  {% if raw_file_format not in accepted_formats %}\n    {% do exceptions.raise_compiler_error(invalid_file_format_msg) %}\n  {% endif %}\n\n  {% do return(raw_file_format) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.1008792, "supported_languages": null}, "macro.dbt_spark.dbt_spark_validate_get_incremental_strategy": {"name": "dbt_spark_validate_get_incremental_strategy", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/incremental/validate.sql", "original_file_path": "macros/materializations/incremental/validate.sql", "unique_id": "macro.dbt_spark.dbt_spark_validate_get_incremental_strategy", "macro_sql": "{% macro dbt_spark_validate_get_incremental_strategy(raw_strategy, file_format) %}\n  {#-- Validate the incremental strategy #}\n\n  {% set invalid_strategy_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    Expected one of: 'append', 'merge', 'insert_overwrite'\n  {%- endset %}\n\n  {% set invalid_merge_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    You can only choose this strategy when file_format is set to 'delta' or 'iceberg' or 'hudi'\n  {%- endset %}\n\n  {% set invalid_insert_overwrite_delta_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    You cannot use this strategy when file_format is set to 'delta' or 'iceberg'\n    Use the 'append' or 'merge' strategy instead\n  {%- endset %}\n\n  {% set invalid_insert_overwrite_endpoint_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    You cannot use this strategy when connecting via endpoint\n    Use the 'append' or 'merge' strategy instead\n  {%- endset %}\n\n  {% if raw_strategy not in ['append', 'merge', 'insert_overwrite'] %}\n    {% do exceptions.raise_compiler_error(invalid_strategy_msg) %}\n  {%-else %}\n    {% if raw_strategy == 'merge' and file_format not in ['delta', 'iceberg', 'hudi'] %}\n      {% do exceptions.raise_compiler_error(invalid_merge_msg) %}\n    {% endif %}\n    {% if raw_strategy == 'insert_overwrite' and file_format == 'delta' %}\n      {% do exceptions.raise_compiler_error(invalid_insert_overwrite_delta_msg) %}\n    {% endif %}\n    {% if raw_strategy == 'insert_overwrite' and target.endpoint %}\n      {% do exceptions.raise_compiler_error(invalid_insert_overwrite_endpoint_msg) %}\n    {% endif %}\n  {% endif %}\n\n  {% do return(raw_strategy) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.104346, "supported_languages": null}, "macro.dbt_spark.get_insert_overwrite_sql": {"name": "get_insert_overwrite_sql", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_spark.get_insert_overwrite_sql", "macro_sql": "{% macro get_insert_overwrite_sql(source_relation, target_relation, existing_relation) %}\n\n    {%- set dest_columns = adapter.get_columns_in_relation(target_relation) -%}\n    {%- set dest_cols_csv = dest_columns | map(attribute='quoted') | join(', ') -%}\n    {% if existing_relation.is_iceberg %}\n      {# removed table from statement for iceberg #}\n      insert overwrite {{ target_relation }}\n      {# removed partition_cols for iceberg as well #}\n    {% else %}\n      insert overwrite table {{ target_relation }}\n      {{ partition_cols(label=\"partition\") }}\n    {% endif %}\n    select {{dest_cols_csv}} from {{ source_relation }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.partition_cols"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.109594, "supported_languages": null}, "macro.dbt_spark.get_insert_into_sql": {"name": "get_insert_into_sql", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_spark.get_insert_into_sql", "macro_sql": "{% macro get_insert_into_sql(source_relation, target_relation) %}\n\n    {%- set dest_columns = adapter.get_columns_in_relation(target_relation) -%}\n    {%- set dest_cols_csv = dest_columns | map(attribute='quoted') | join(', ') -%}\n    insert into table {{ target_relation }}\n    select {{dest_cols_csv}} from {{ source_relation }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.110639, "supported_languages": null}, "macro.dbt_spark.spark__get_merge_sql": {"name": "spark__get_merge_sql", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_spark.spark__get_merge_sql", "macro_sql": "{% macro spark__get_merge_sql(target, source, unique_key, dest_columns, incremental_predicates) %}\n  {# need dest_columns for merge_exclude_columns, default to use \"*\" #}\n  {%- set predicates = [] if incremental_predicates is none else [] + incremental_predicates -%}\n  {%- set dest_columns = adapter.get_columns_in_relation(target) -%}\n  {%- set merge_update_columns = config.get('merge_update_columns') -%}\n  {%- set merge_exclude_columns = config.get('merge_exclude_columns') -%}\n  {%- set update_columns = get_merge_update_columns(merge_update_columns, merge_exclude_columns, dest_columns) -%}\n\n  {% if unique_key %}\n      {% if unique_key is sequence and unique_key is not mapping and unique_key is not string %}\n          {% for key in unique_key %}\n              {% set this_key_match %}\n                  DBT_INTERNAL_SOURCE.{{ key }} = DBT_INTERNAL_DEST.{{ key }}\n              {% endset %}\n              {% do predicates.append(this_key_match) %}\n          {% endfor %}\n      {% else %}\n          {% set unique_key_match %}\n              DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n          {% endset %}\n          {% do predicates.append(unique_key_match) %}\n      {% endif %}\n  {% else %}\n      {% do predicates.append('FALSE') %}\n  {% endif %}\n\n  {{ sql_header if sql_header is not none }}\n\n  merge into {{ target }} as DBT_INTERNAL_DEST\n      using {{ source }} as DBT_INTERNAL_SOURCE\n      on {{ predicates | join(' and ') }}\n\n      when matched then update set\n        {% if update_columns -%}{%- for column_name in update_columns %}\n            {{ column_name }} = DBT_INTERNAL_SOURCE.{{ column_name }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n        {%- else %} * {% endif %}\n\n      when not matched then insert *\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_merge_update_columns"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.115252, "supported_languages": null}, "macro.dbt_spark.dbt_spark_get_incremental_sql": {"name": "dbt_spark_get_incremental_sql", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_spark.dbt_spark_get_incremental_sql", "macro_sql": "{% macro dbt_spark_get_incremental_sql(strategy, source, target, existing, unique_key, incremental_predicates) %}\n  {%- if strategy == 'append' -%}\n    {#-- insert new records into existing table, without updating or overwriting #}\n    {{ get_insert_into_sql(source, target) }}\n  {%- elif strategy == 'insert_overwrite' -%}\n    {#-- insert statements don't like CTEs, so support them via a temp view #}\n    {{ get_insert_overwrite_sql(source, target, existing) }}\n  {%- elif strategy == 'merge' -%}\n  {#-- merge all columns for datasources which implement MERGE INTO (e.g. databricks, iceberg) - schema changes are handled for us #}\n    {{ get_merge_sql(target, source, unique_key, dest_columns=none, incremental_predicates=incremental_predicates) }}\n  {%- else -%}\n    {% set no_sql_for_strategy_msg -%}\n      No known SQL for the incremental strategy provided: {{ strategy }}\n    {%- endset %}\n    {%- do exceptions.raise_compiler_error(no_sql_for_strategy_msg) -%}\n  {%- endif -%}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.get_insert_into_sql", "macro.dbt_spark.get_insert_overwrite_sql", "macro.dbt.get_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.117325, "supported_languages": null}, "macro.dbt_spark.materialization_incremental_spark": {"name": "materialization_incremental_spark", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/incremental/incremental.sql", "original_file_path": "macros/materializations/incremental/incremental.sql", "unique_id": "macro.dbt_spark.materialization_incremental_spark", "macro_sql": "{% materialization incremental, adapter='spark', supported_languages=['sql', 'python'] -%}\n  {#-- Validate early so we don't run SQL if the file_format + strategy combo is invalid --#}\n  {%- set raw_file_format = config.get('file_format', default='parquet') -%}\n  {%- set raw_strategy = config.get('incremental_strategy') or 'append' -%}\n  {%- set grant_config = config.get('grants') -%}\n\n  {%- set file_format = dbt_spark_validate_get_file_format(raw_file_format) -%}\n  {%- set strategy = dbt_spark_validate_get_incremental_strategy(raw_strategy, file_format) -%}\n\n  {#-- Set vars --#}\n\n  {%- set unique_key = config.get('unique_key', none) -%}\n  {%- set partition_by = config.get('partition_by', none) -%}\n  {%- set language = model['language'] -%}\n  {%- set on_schema_change = incremental_validate_on_schema_change(config.get('on_schema_change'), default='ignore') -%}\n  {%- set incremental_predicates = config.get('predicates', none) or config.get('incremental_predicates', none) -%}\n  {%- set target_relation = this -%}\n  {%- set existing_relation = load_relation(this) -%}\n  {%- set tmp_relation = make_temp_relation(this) -%}\n\n  {#-- for SQL model we will create temp view that doesn't have database and schema --#}\n  {%- if language == 'sql'-%}\n    {%- set tmp_relation = tmp_relation.include(database=false, schema=false) -%}\n  {%- endif -%}\n\n  {#-- Set Overwrite Mode --#}\n  {%- if strategy == 'insert_overwrite' and partition_by -%}\n    {%- call statement() -%}\n      set spark.sql.sources.partitionOverwriteMode = DYNAMIC\n    {%- endcall -%}\n  {%- endif -%}\n\n  {#-- Run pre-hooks --#}\n  {{ run_hooks(pre_hooks) }}\n\n  {#-- Incremental run logic --#}\n  {%- if existing_relation is none -%}\n    {#-- Relation must be created --#}\n    {%- call statement('main', language=language) -%}\n      {{ create_table_as(False, target_relation, compiled_code, language) }}\n    {%- endcall -%}\n    {% do persist_constraints(target_relation, model) %}\n  {%- elif existing_relation.is_view or should_full_refresh() -%}\n    {#-- Relation must be dropped & recreated --#}\n    {% set is_delta = (file_format == 'delta' and existing_relation.is_delta) %}\n    {% if not is_delta %} {#-- If Delta, we will `create or replace` below, so no need to drop --#}\n      {% do adapter.drop_relation(existing_relation) %}\n    {% endif %}\n    {%- call statement('main', language=language) -%}\n      {{ create_table_as(False, target_relation, compiled_code, language) }}\n    {%- endcall -%}\n    {% do persist_constraints(target_relation, model) %}\n  {%- else -%}\n    {#-- Relation must be merged --#}\n    {%- call statement('create_tmp_relation', language=language) -%}\n      {{ create_table_as(True, tmp_relation, compiled_code, language) }}\n    {%- endcall -%}\n    {%- do process_schema_changes(on_schema_change, tmp_relation, existing_relation) -%}\n    {%- call statement('main') -%}\n      {{ dbt_spark_get_incremental_sql(strategy, tmp_relation, target_relation, existing_relation, unique_key, incremental_predicates) }}\n    {%- endcall -%}\n    {%- if language == 'python' -%}\n      {#--\n      This is yucky.\n      See note in dbt-spark/dbt/include/spark/macros/adapters.sql\n      re: python models and temporary views.\n\n      Also, why do neither drop_relation or adapter.drop_relation work here?!\n      --#}\n      {% call statement('drop_relation') -%}\n        drop table if exists {{ tmp_relation }}\n      {%- endcall %}\n    {%- endif -%}\n  {%- endif -%}\n\n  {% set should_revoke = should_revoke(existing_relation, full_refresh_mode) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "depends_on": {"macros": ["macro.dbt_spark.dbt_spark_validate_get_file_format", "macro.dbt_spark.dbt_spark_validate_get_incremental_strategy", "macro.dbt.incremental_validate_on_schema_change", "macro.dbt.load_relation", "macro.dbt.make_temp_relation", "macro.dbt.statement", "macro.dbt.run_hooks", "macro.dbt.create_table_as", "macro.dbt_spark.persist_constraints", "macro.dbt.should_full_refresh", "macro.dbt.process_schema_changes", "macro.dbt_spark.dbt_spark_get_incremental_sql", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.128758, "supported_languages": ["sql", "python"]}, "macro.dbt_spark.spark__concat": {"name": "spark__concat", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/concat.sql", "original_file_path": "macros/utils/concat.sql", "unique_id": "macro.dbt_spark.spark__concat", "macro_sql": "{% macro spark__concat(fields) -%}\n    concat({{ fields|join(', ') }})\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.129385, "supported_languages": null}, "macro.dbt_spark.assert_not_null": {"name": "assert_not_null", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/assert_not_null.sql", "original_file_path": "macros/utils/assert_not_null.sql", "unique_id": "macro.dbt_spark.assert_not_null", "macro_sql": "{% macro assert_not_null(function, arg) -%}\n  {{ return(adapter.dispatch('assert_not_null', 'dbt')(function, arg)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__assert_not_null"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.130361, "supported_languages": null}, "macro.dbt_spark.spark__assert_not_null": {"name": "spark__assert_not_null", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/assert_not_null.sql", "original_file_path": "macros/utils/assert_not_null.sql", "unique_id": "macro.dbt_spark.spark__assert_not_null", "macro_sql": "{% macro spark__assert_not_null(function, arg) %}\n\n    coalesce({{function}}({{arg}}), nvl2({{function}}({{arg}}), assert_true({{function}}({{arg}}) is not null), null))\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.131039, "supported_languages": null}, "macro.dbt_spark.spark__dateadd": {"name": "spark__dateadd", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/dateadd.sql", "original_file_path": "macros/utils/dateadd.sql", "unique_id": "macro.dbt_spark.spark__dateadd", "macro_sql": "{% macro spark__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    {%- set clock_component -%}\n        {# make sure the dates + timestamps are real, otherwise raise an error asap #}\n        to_unix_timestamp({{ assert_not_null('to_timestamp', from_date_or_timestamp) }})\n        - to_unix_timestamp({{ assert_not_null('date', from_date_or_timestamp) }})\n    {%- endset -%}\n\n    {%- if datepart in ['day', 'week'] -%}\n\n        {%- set multiplier = 7 if datepart == 'week' else 1 -%}\n\n        to_timestamp(\n            to_unix_timestamp(\n                date_add(\n                    {{ assert_not_null('date', from_date_or_timestamp) }},\n                    cast({{interval}} * {{multiplier}} as int)\n                )\n            ) + {{clock_component}}\n        )\n\n    {%- elif datepart in ['month', 'quarter', 'year'] -%}\n\n        {%- set multiplier -%}\n            {%- if datepart == 'month' -%} 1\n            {%- elif datepart == 'quarter' -%} 3\n            {%- elif datepart == 'year' -%} 12\n            {%- endif -%}\n        {%- endset -%}\n\n        to_timestamp(\n            to_unix_timestamp(\n                add_months(\n                    {{ assert_not_null('date', from_date_or_timestamp) }},\n                    cast({{interval}} * {{multiplier}} as int)\n                )\n            ) + {{clock_component}}\n        )\n\n    {%- elif datepart in ('hour', 'minute', 'second', 'millisecond', 'microsecond') -%}\n\n        {%- set multiplier -%}\n            {%- if datepart == 'hour' -%} 3600\n            {%- elif datepart == 'minute' -%} 60\n            {%- elif datepart == 'second' -%} 1\n            {%- elif datepart == 'millisecond' -%} (1/1000000)\n            {%- elif datepart == 'microsecond' -%} (1/1000000)\n            {%- endif -%}\n        {%- endset -%}\n\n        to_timestamp(\n            {{ assert_not_null('to_unix_timestamp', from_date_or_timestamp) }}\n            + cast({{interval}} * {{multiplier}} as int)\n        )\n\n    {%- else -%}\n\n        {{ exceptions.raise_compiler_error(\"macro dateadd not implemented for datepart ~ '\" ~ datepart ~ \"' ~ on Spark\") }}\n\n    {%- endif -%}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.assert_not_null"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.138894, "supported_languages": null}, "macro.dbt_spark.spark__current_timestamp": {"name": "spark__current_timestamp", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/timestamps.sql", "original_file_path": "macros/utils/timestamps.sql", "unique_id": "macro.dbt_spark.spark__current_timestamp", "macro_sql": "{% macro spark__current_timestamp() -%}\n    current_timestamp()\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.1392782, "supported_languages": null}, "macro.dbt_spark.spark__escape_single_quotes": {"name": "spark__escape_single_quotes", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/escape_single_quotes.sql", "original_file_path": "macros/utils/escape_single_quotes.sql", "unique_id": "macro.dbt_spark.spark__escape_single_quotes", "macro_sql": "{% macro spark__escape_single_quotes(expression) -%}\n{{ expression | replace(\"'\",\"\\\\'\") }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.139889, "supported_languages": null}, "macro.dbt_spark.spark__listagg": {"name": "spark__listagg", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/listagg.sql", "original_file_path": "macros/utils/listagg.sql", "unique_id": "macro.dbt_spark.spark__listagg", "macro_sql": "{% macro spark__listagg(measure, delimiter_text, order_by_clause, limit_num) -%}\n\n  {% if order_by_clause %}\n    {{ exceptions.warn(\"order_by_clause is not supported for listagg on Spark/Databricks\") }}\n  {% endif %}\n\n  {% set collect_list %} collect_list({{ measure }}) {% endset %}\n\n  {% set limited %} slice({{ collect_list }}, 1, {{ limit_num }}) {% endset %}\n\n  {% set collected = limited if limit_num else collect_list %}\n\n  {% set final %} array_join({{ collected }}, {{ delimiter_text }}) {% endset %}\n\n  {% do return(final) %}\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.142199, "supported_languages": null}, "macro.dbt_spark.spark__datediff": {"name": "spark__datediff", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/datediff.sql", "original_file_path": "macros/utils/datediff.sql", "unique_id": "macro.dbt_spark.spark__datediff", "macro_sql": "{% macro spark__datediff(first_date, second_date, datepart) %}\n\n    {%- if datepart in ['day', 'week', 'month', 'quarter', 'year'] -%}\n\n        {# make sure the dates are real, otherwise raise an error asap #}\n        {% set first_date = assert_not_null('date', first_date) %}\n        {% set second_date = assert_not_null('date', second_date) %}\n\n    {%- endif -%}\n\n    {%- if datepart == 'day' -%}\n\n        datediff({{second_date}}, {{first_date}})\n\n    {%- elif datepart == 'week' -%}\n\n        case when {{first_date}} < {{second_date}}\n            then floor(datediff({{second_date}}, {{first_date}})/7)\n            else ceil(datediff({{second_date}}, {{first_date}})/7)\n            end\n\n        -- did we cross a week boundary (Sunday)?\n        + case\n            when {{first_date}} < {{second_date}} and dayofweek({{second_date}}) < dayofweek({{first_date}}) then 1\n            when {{first_date}} > {{second_date}} and dayofweek({{second_date}}) > dayofweek({{first_date}}) then -1\n            else 0 end\n\n    {%- elif datepart == 'month' -%}\n\n        case when {{first_date}} < {{second_date}}\n            then floor(months_between(date({{second_date}}), date({{first_date}})))\n            else ceil(months_between(date({{second_date}}), date({{first_date}})))\n            end\n\n        -- did we cross a month boundary?\n        + case\n            when {{first_date}} < {{second_date}} and dayofmonth({{second_date}}) < dayofmonth({{first_date}}) then 1\n            when {{first_date}} > {{second_date}} and dayofmonth({{second_date}}) > dayofmonth({{first_date}}) then -1\n            else 0 end\n\n    {%- elif datepart == 'quarter' -%}\n\n        case when {{first_date}} < {{second_date}}\n            then floor(months_between(date({{second_date}}), date({{first_date}}))/3)\n            else ceil(months_between(date({{second_date}}), date({{first_date}}))/3)\n            end\n\n        -- did we cross a quarter boundary?\n        + case\n            when {{first_date}} < {{second_date}} and (\n                (dayofyear({{second_date}}) - (quarter({{second_date}}) * 365/4))\n                < (dayofyear({{first_date}}) - (quarter({{first_date}}) * 365/4))\n            ) then 1\n            when {{first_date}} > {{second_date}} and (\n                (dayofyear({{second_date}}) - (quarter({{second_date}}) * 365/4))\n                > (dayofyear({{first_date}}) - (quarter({{first_date}}) * 365/4))\n            ) then -1\n            else 0 end\n\n    {%- elif datepart == 'year' -%}\n\n        year({{second_date}}) - year({{first_date}})\n\n    {%- elif datepart in ('hour', 'minute', 'second', 'millisecond', 'microsecond') -%}\n\n        {%- set divisor -%}\n            {%- if datepart == 'hour' -%} 3600\n            {%- elif datepart == 'minute' -%} 60\n            {%- elif datepart == 'second' -%} 1\n            {%- elif datepart == 'millisecond' -%} (1/1000)\n            {%- elif datepart == 'microsecond' -%} (1/1000000)\n            {%- endif -%}\n        {%- endset -%}\n\n        case when {{first_date}} < {{second_date}}\n            then ceil((\n                {# make sure the timestamps are real, otherwise raise an error asap #}\n                {{ assert_not_null('to_unix_timestamp', assert_not_null('to_timestamp', second_date)) }}\n                - {{ assert_not_null('to_unix_timestamp', assert_not_null('to_timestamp', first_date)) }}\n            ) / {{divisor}})\n            else floor((\n                {{ assert_not_null('to_unix_timestamp', assert_not_null('to_timestamp', second_date)) }}\n                - {{ assert_not_null('to_unix_timestamp', assert_not_null('to_timestamp', first_date)) }}\n            ) / {{divisor}})\n            end\n\n            {% if datepart == 'millisecond' %}\n                + cast(date_format({{second_date}}, 'SSS') as int)\n                - cast(date_format({{first_date}}, 'SSS') as int)\n            {% endif %}\n\n            {% if datepart == 'microsecond' %}\n                {% set capture_str = '[0-9]{4}-[0-9]{2}-[0-9]{2}.[0-9]{2}:[0-9]{2}:[0-9]{2}.([0-9]{6})' %}\n                -- Spark doesn't really support microseconds, so this is a massive hack!\n                -- It will only work if the timestamp-string is of the format\n                -- 'yyyy-MM-dd-HH mm.ss.SSSSSS'\n                + cast(regexp_extract({{second_date}}, '{{capture_str}}', 1) as int)\n                - cast(regexp_extract({{first_date}}, '{{capture_str}}', 1) as int)\n            {% endif %}\n\n    {%- else -%}\n\n        {{ exceptions.raise_compiler_error(\"macro datediff not implemented for datepart ~ '\" ~ datepart ~ \"' ~ on Spark\") }}\n\n    {%- endif -%}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.assert_not_null"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.161452, "supported_languages": null}, "macro.dbt_spark.spark__any_value": {"name": "spark__any_value", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/any_value.sql", "original_file_path": "macros/utils/any_value.sql", "unique_id": "macro.dbt_spark.spark__any_value", "macro_sql": "{% macro spark__any_value(expression) -%}\n    {#-- return any value (non-deterministic)  --#}\n    first({{ expression }})\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.1620128, "supported_languages": null}, "macro.dbt_spark.spark__array_concat": {"name": "spark__array_concat", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/array_concat.sql", "original_file_path": "macros/utils/array_concat.sql", "unique_id": "macro.dbt_spark.spark__array_concat", "macro_sql": "{% macro spark__array_concat(array_1, array_2) -%}\n    concat({{ array_1 }}, {{ array_2 }})\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.162582, "supported_languages": null}, "macro.dbt_spark.spark__bool_or": {"name": "spark__bool_or", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/bool_or.sql", "original_file_path": "macros/utils/bool_or.sql", "unique_id": "macro.dbt_spark.spark__bool_or", "macro_sql": "{% macro spark__bool_or(expression) -%}\n\n    max({{ expression }})\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.16308, "supported_languages": null}, "macro.dbt_spark.spark__split_part": {"name": "spark__split_part", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/split_part.sql", "original_file_path": "macros/utils/split_part.sql", "unique_id": "macro.dbt_spark.spark__split_part", "macro_sql": "{% macro spark__split_part(string_text, delimiter_text, part_number) %}\n\n    {% set delimiter_expr %}\n\n        -- escape if starts with a special character\n        case when regexp_extract({{ delimiter_text }}, '([^A-Za-z0-9])(.*)', 1) != '_'\n            then concat('\\\\', {{ delimiter_text }})\n            else {{ delimiter_text }} end\n\n    {% endset %}\n\n    {% set split_part_expr %}\n\n    split(\n        {{ string_text }},\n        {{ delimiter_expr }}\n        )[({{ part_number - 1 }})]\n\n    {% endset %}\n\n    {{ return(split_part_expr) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.1647801, "supported_languages": null}, "macro.dbt_spark.spark__array_construct": {"name": "spark__array_construct", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/array_construct.sql", "original_file_path": "macros/utils/array_construct.sql", "unique_id": "macro.dbt_spark.spark__array_construct", "macro_sql": "{% macro spark__array_construct(inputs, data_type) -%}\n    array( {{ inputs|join(' , ') }} )\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.165388, "supported_languages": null}, "macro.dbt_spark.spark__array_append": {"name": "spark__array_append", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/array_append.sql", "original_file_path": "macros/utils/array_append.sql", "unique_id": "macro.dbt_spark.spark__array_append", "macro_sql": "{% macro spark__array_append(array, new_element) -%}\n    {{ array_concat(array, array_construct([new_element])) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.array_concat", "macro.springbricks_integration_tests.array_construct"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.1660612, "supported_languages": null}, "macro.dbt.run_hooks": {"name": "run_hooks", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "unique_id": "macro.dbt.run_hooks", "macro_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.169253, "supported_languages": null}, "macro.dbt.make_hook_config": {"name": "make_hook_config", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "unique_id": "macro.dbt.make_hook_config", "macro_sql": "{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.169903, "supported_languages": null}, "macro.dbt.before_begin": {"name": "before_begin", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "unique_id": "macro.dbt.before_begin", "macro_sql": "{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.make_hook_config"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.170398, "supported_languages": null}, "macro.dbt.in_transaction": {"name": "in_transaction", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "unique_id": "macro.dbt.in_transaction", "macro_sql": "{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.make_hook_config"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.1708958, "supported_languages": null}, "macro.dbt.after_commit": {"name": "after_commit", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "unique_id": "macro.dbt.after_commit", "macro_sql": "{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.make_hook_config"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.171392, "supported_languages": null}, "macro.dbt.set_sql_header": {"name": "set_sql_header", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/configs.sql", "original_file_path": "macros/materializations/configs.sql", "unique_id": "macro.dbt.set_sql_header", "macro_sql": "{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.1725, "supported_languages": null}, "macro.dbt.should_full_refresh": {"name": "should_full_refresh", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/configs.sql", "original_file_path": "macros/materializations/configs.sql", "unique_id": "macro.dbt.should_full_refresh", "macro_sql": "{% macro should_full_refresh() %}\n  {% set config_full_refresh = config.get('full_refresh') %}\n  {% if config_full_refresh is none %}\n    {% set config_full_refresh = flags.FULL_REFRESH %}\n  {% endif %}\n  {% do return(config_full_refresh) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.1735091, "supported_languages": null}, "macro.dbt.should_store_failures": {"name": "should_store_failures", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/configs.sql", "original_file_path": "macros/materializations/configs.sql", "unique_id": "macro.dbt.should_store_failures", "macro_sql": "{% macro should_store_failures() %}\n  {% set config_store_failures = config.get('store_failures') %}\n  {% if config_store_failures is none %}\n    {% set config_store_failures = flags.STORE_FAILURES %}\n  {% endif %}\n  {% do return(config_store_failures) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.174516, "supported_languages": null}, "macro.dbt.snapshot_merge_sql": {"name": "snapshot_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/snapshot_merge.sql", "original_file_path": "macros/materializations/snapshots/snapshot_merge.sql", "unique_id": "macro.dbt.snapshot_merge_sql", "macro_sql": "{% macro snapshot_merge_sql(target, source, insert_cols) -%}\n  {{ adapter.dispatch('snapshot_merge_sql', 'dbt')(target, source, insert_cols) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__snapshot_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.1757681, "supported_languages": null}, "macro.dbt.default__snapshot_merge_sql": {"name": "default__snapshot_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/snapshot_merge.sql", "original_file_path": "macros/materializations/snapshots/snapshot_merge.sql", "unique_id": "macro.dbt.default__snapshot_merge_sql", "macro_sql": "{% macro default__snapshot_merge_sql(target, source, insert_cols) -%}\n    {%- set insert_cols_csv = insert_cols | join(', ') -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n    using {{ source }} as DBT_INTERNAL_SOURCE\n    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id\n\n    when matched\n     and DBT_INTERNAL_DEST.dbt_valid_to is null\n     and DBT_INTERNAL_SOURCE.dbt_change_type in ('update', 'delete')\n        then update\n        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to\n\n    when not matched\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'\n        then insert ({{ insert_cols_csv }})\n        values ({{ insert_cols_csv }})\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.17666, "supported_languages": null}, "macro.dbt.strategy_dispatch": {"name": "strategy_dispatch", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "unique_id": "macro.dbt.strategy_dispatch", "macro_sql": "{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.186176, "supported_languages": null}, "macro.dbt.snapshot_hash_arguments": {"name": "snapshot_hash_arguments", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "unique_id": "macro.dbt.snapshot_hash_arguments", "macro_sql": "{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter.dispatch('snapshot_hash_arguments', 'dbt')(args) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__snapshot_hash_arguments"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.186739, "supported_languages": null}, "macro.dbt.default__snapshot_hash_arguments": {"name": "default__snapshot_hash_arguments", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "unique_id": "macro.dbt.default__snapshot_hash_arguments", "macro_sql": "{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.187488, "supported_languages": null}, "macro.dbt.snapshot_timestamp_strategy": {"name": "snapshot_timestamp_strategy", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "unique_id": "macro.dbt.snapshot_timestamp_strategy", "macro_sql": "{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n    {% set invalidate_hard_deletes = config.get('invalidate_hard_deletes', false) %}\n\n    {#/*\n        The snapshot relation might not have an {{ updated_at }} value if the\n        snapshot strategy is changed from `check` to `timestamp`. We\n        should use a dbt-created column for the comparison in the snapshot\n        table instead of assuming that the user-supplied {{ updated_at }}\n        will be present in the historical data.\n\n        See https://github.com/dbt-labs/dbt-core/issues/2350\n    */ #}\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.dbt_valid_from < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr,\n        \"invalidate_hard_deletes\": invalidate_hard_deletes\n    }) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.snapshot_hash_arguments"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.18978, "supported_languages": null}, "macro.dbt.snapshot_string_as_time": {"name": "snapshot_string_as_time", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "unique_id": "macro.dbt.snapshot_string_as_time", "macro_sql": "{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter.dispatch('snapshot_string_as_time', 'dbt')(timestamp) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__snapshot_string_as_time"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.1903338, "supported_languages": null}, "macro.dbt.default__snapshot_string_as_time": {"name": "default__snapshot_string_as_time", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "unique_id": "macro.dbt.default__snapshot_string_as_time", "macro_sql": "{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.190917, "supported_languages": null}, "macro.dbt.snapshot_check_all_get_existing_columns": {"name": "snapshot_check_all_get_existing_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "unique_id": "macro.dbt.snapshot_check_all_get_existing_columns", "macro_sql": "{% macro snapshot_check_all_get_existing_columns(node, target_exists, check_cols_config) -%}\n    {%- if not target_exists -%}\n        {#-- no table yet -> return whatever the query does --#}\n        {{ return((false, query_columns)) }}\n    {%- endif -%}\n\n    {#-- handle any schema changes --#}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=node.alias) -%}\n\n    {% if check_cols_config == 'all' %}\n        {%- set query_columns = get_columns_in_query(node['compiled_code']) -%}\n\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {#-- query for proper casing/quoting, to support comparison below --#}\n        {%- set select_check_cols_from_target -%}\n            {#-- N.B. The whitespace below is necessary to avoid edge case issue with comments --#}\n            {#-- See: https://github.com/dbt-labs/dbt-core/issues/6781 --#}\n            select {{ check_cols_config | join(', ') }} from (\n                {{ node['compiled_code'] }}\n            ) subq\n        {%- endset -%}\n        {% set query_columns = get_columns_in_query(select_check_cols_from_target) %}\n\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set existing_cols = adapter.get_columns_in_relation(target_relation) | map(attribute = 'name') | list -%}\n    {%- set ns = namespace() -%} {#-- handle for-loop scoping with a namespace --#}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(adapter.quote(col)) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return((ns.column_added, intersection)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.get_columns_in_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.195394, "supported_languages": null}, "macro.dbt.snapshot_check_strategy": {"name": "snapshot_check_strategy", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "unique_id": "macro.dbt.snapshot_check_strategy", "macro_sql": "{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set invalidate_hard_deletes = config.get('invalidate_hard_deletes', false) %}\n    {% set updated_at = config.get('updated_at', snapshot_get_time()) %}\n\n    {% set column_added = false %}\n\n    {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists, check_cols_config) %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        {{ get_true_sql() }}\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        (\n            (({{ snapshotted_rel }}.{{ col }} is null) and not ({{ current_rel }}.{{ col }} is null))\n            or\n            ((not {{ snapshotted_rel }}.{{ col }} is null) and ({{ current_rel }}.{{ col }} is null))\n        )\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr,\n        \"invalidate_hard_deletes\": invalidate_hard_deletes\n    }) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.snapshot_get_time", "macro.dbt.snapshot_check_all_get_existing_columns", "macro.dbt.get_true_sql", "macro.dbt.snapshot_hash_arguments"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.1995578, "supported_languages": null}, "macro.dbt.create_columns": {"name": "create_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.create_columns", "macro_sql": "{% macro create_columns(relation, columns) %}\n  {{ adapter.dispatch('create_columns', 'dbt')(relation, columns) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__create_columns"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.209374, "supported_languages": null}, "macro.dbt.default__create_columns": {"name": "default__create_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.default__create_columns", "macro_sql": "{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.2103128, "supported_languages": null}, "macro.dbt.post_snapshot": {"name": "post_snapshot", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.post_snapshot", "macro_sql": "{% macro post_snapshot(staging_relation) %}\n  {{ adapter.dispatch('post_snapshot', 'dbt')(staging_relation) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__post_snapshot"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.210884, "supported_languages": null}, "macro.dbt.default__post_snapshot": {"name": "default__post_snapshot", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.default__post_snapshot", "macro_sql": "{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.211209, "supported_languages": null}, "macro.dbt.get_true_sql": {"name": "get_true_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.get_true_sql", "macro_sql": "{% macro get_true_sql() %}\n  {{ adapter.dispatch('get_true_sql', 'dbt')() }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_true_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.211709, "supported_languages": null}, "macro.dbt.default__get_true_sql": {"name": "default__get_true_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.default__get_true_sql", "macro_sql": "{% macro default__get_true_sql() %}\n    {{ return('TRUE') }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.21212, "supported_languages": null}, "macro.dbt.snapshot_staging_table": {"name": "snapshot_staging_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.snapshot_staging_table", "macro_sql": "{% macro snapshot_staging_table(strategy, source_sql, target_relation) -%}\n  {{ adapter.dispatch('snapshot_staging_table', 'dbt')(strategy, source_sql, target_relation) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__snapshot_staging_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.212805, "supported_languages": null}, "macro.dbt.default__snapshot_staging_table": {"name": "default__snapshot_staging_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.default__snapshot_staging_table", "macro_sql": "{% macro default__snapshot_staging_table(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n        where dbt_valid_to is null\n\n    ),\n\n    insertions_source_data as (\n\n        select\n            *,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to,\n            {{ strategy.scd_id }} as dbt_scd_id\n\n        from snapshot_query\n    ),\n\n    updates_source_data as (\n\n        select\n            *,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            {{ strategy.updated_at }} as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    {%- if strategy.invalidate_hard_deletes %}\n\n    deletes_source_data as (\n\n        select\n            *,\n            {{ strategy.unique_key }} as dbt_unique_key\n        from snapshot_query\n    ),\n    {% endif %}\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from insertions_source_data as source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            source_data.*,\n            snapshotted_data.dbt_scd_id\n\n        from updates_source_data as source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where (\n            {{ strategy.row_changed }}\n        )\n    )\n\n    {%- if strategy.invalidate_hard_deletes -%}\n    ,\n\n    deletes as (\n\n        select\n            'delete' as dbt_change_type,\n            source_data.*,\n            {{ snapshot_get_time() }} as dbt_valid_from,\n            {{ snapshot_get_time() }} as dbt_updated_at,\n            {{ snapshot_get_time() }} as dbt_valid_to,\n            snapshotted_data.dbt_scd_id\n\n        from snapshotted_data\n        left join deletes_source_data as source_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where source_data.dbt_unique_key is null\n    )\n    {%- endif %}\n\n    select * from insertions\n    union all\n    select * from updates\n    {%- if strategy.invalidate_hard_deletes %}\n    union all\n    select * from deletes\n    {%- endif %}\n\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.snapshot_get_time"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.215644, "supported_languages": null}, "macro.dbt.build_snapshot_table": {"name": "build_snapshot_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.build_snapshot_table", "macro_sql": "{% macro build_snapshot_table(strategy, sql) -%}\n  {{ adapter.dispatch('build_snapshot_table', 'dbt')(strategy, sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__build_snapshot_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.216287, "supported_languages": null}, "macro.dbt.default__build_snapshot_table": {"name": "default__build_snapshot_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.default__build_snapshot_table", "macro_sql": "{% macro default__build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.217119, "supported_languages": null}, "macro.dbt.build_snapshot_staging_table": {"name": "build_snapshot_staging_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.build_snapshot_staging_table", "macro_sql": "{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set temp_relation = make_temp_relation(target_relation) %}\n\n    {% set select = snapshot_staging_table(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation') %}\n        {{ create_table_as(True, temp_relation, select) }}\n    {% endcall %}\n\n    {% do return(temp_relation) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.make_temp_relation", "macro.dbt.snapshot_staging_table", "macro.dbt.statement", "macro.dbt.create_table_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.218503, "supported_languages": null}, "macro.dbt.materialization_snapshot_default": {"name": "materialization_snapshot_default", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/snapshot.sql", "original_file_path": "macros/materializations/snapshots/snapshot.sql", "unique_id": "macro.dbt.materialization_snapshot_default", "macro_sql": "{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n  -- grab current tables grants config for comparision later on\n  {%- set grant_config = config.get('grants') -%}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['compiled_code']) %}\n      {% set final_sql = create_table_as(False, target_relation, build_sql) %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% set final_sql = snapshot_merge_sql(\n            target = target_relation,\n            source = staging_table,\n            insert_cols = quoted_source_columns\n         )\n      %}\n\n  {% endif %}\n\n  {% call statement('main') %}\n      {{ final_sql }}\n  {% endcall %}\n\n  {% set should_revoke = should_revoke(target_relation_exists, full_refresh_mode=False) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {% if not target_relation_exists %}\n    {% do create_indexes(target_relation) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt.get_or_create_relation", "macro.dbt.run_hooks", "macro.dbt.strategy_dispatch", "macro.dbt.build_snapshot_table", "macro.dbt.create_table_as", "macro.dbt.build_snapshot_staging_table", "macro.dbt.create_columns", "macro.dbt.snapshot_merge_sql", "macro.dbt.statement", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs", "macro.dbt.create_indexes", "macro.dbt.post_snapshot"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.235559, "supported_languages": ["sql"]}, "macro.dbt.materialization_test_default": {"name": "materialization_test_default", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/tests/test.sql", "original_file_path": "macros/materializations/tests/test.sql", "unique_id": "macro.dbt.materialization_test_default", "macro_sql": "{%- materialization test, default -%}\n\n  {% set relations = [] %}\n\n  {% if should_store_failures() %}\n\n    {% set identifier = model['alias'] %}\n    {% set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n    {% set target_relation = api.Relation.create(\n        identifier=identifier, schema=schema, database=database, type='table') -%} %}\n\n    {% if old_relation %}\n        {% do adapter.drop_relation(old_relation) %}\n    {% endif %}\n\n    {% call statement(auto_begin=True) %}\n        {{ create_table_as(False, target_relation, sql) }}\n    {% endcall %}\n\n    {% do relations.append(target_relation) %}\n\n    {% set main_sql %}\n        select *\n        from {{ target_relation }}\n    {% endset %}\n\n    {{ adapter.commit() }}\n\n  {% else %}\n\n      {% set main_sql = sql %}\n\n  {% endif %}\n\n  {% set limit = config.get('limit') %}\n  {% set fail_calc = config.get('fail_calc') %}\n  {% set warn_if = config.get('warn_if') %}\n  {% set error_if = config.get('error_if') %}\n\n  {% call statement('main', fetch_result=True) -%}\n\n    {{ get_test_sql(main_sql, fail_calc, warn_if, error_if, limit)}}\n\n  {%- endcall %}\n\n  {{ return({'relations': relations}) }}\n\n{%- endmaterialization -%}", "depends_on": {"macros": ["macro.dbt.should_store_failures", "macro.dbt.statement", "macro.dbt.create_table_as", "macro.dbt.get_test_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.241596, "supported_languages": ["sql"]}, "macro.dbt.get_test_sql": {"name": "get_test_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/tests/helpers.sql", "original_file_path": "macros/materializations/tests/helpers.sql", "unique_id": "macro.dbt.get_test_sql", "macro_sql": "{% macro get_test_sql(main_sql, fail_calc, warn_if, error_if, limit) -%}\n  {{ adapter.dispatch('get_test_sql', 'dbt')(main_sql, fail_calc, warn_if, error_if, limit) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_test_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.2428951, "supported_languages": null}, "macro.dbt.default__get_test_sql": {"name": "default__get_test_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/tests/helpers.sql", "original_file_path": "macros/materializations/tests/helpers.sql", "unique_id": "macro.dbt.default__get_test_sql", "macro_sql": "{% macro default__get_test_sql(main_sql, fail_calc, warn_if, error_if, limit) -%}\n    select\n      {{ fail_calc }} as failures,\n      {{ fail_calc }} {{ warn_if }} as should_warn,\n      {{ fail_calc }} {{ error_if }} as should_error\n    from (\n      {{ main_sql }}\n      {{ \"limit \" ~ limit if limit != none }}\n    ) dbt_internal_test\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.243885, "supported_languages": null}, "macro.dbt.get_where_subquery": {"name": "get_where_subquery", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/tests/where_subquery.sql", "original_file_path": "macros/materializations/tests/where_subquery.sql", "unique_id": "macro.dbt.get_where_subquery", "macro_sql": "{% macro get_where_subquery(relation) -%}\n    {% do return(adapter.dispatch('get_where_subquery', 'dbt')(relation)) %}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_where_subquery"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.2449841, "supported_languages": null}, "macro.dbt.default__get_where_subquery": {"name": "default__get_where_subquery", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/tests/where_subquery.sql", "original_file_path": "macros/materializations/tests/where_subquery.sql", "unique_id": "macro.dbt.default__get_where_subquery", "macro_sql": "{% macro default__get_where_subquery(relation) -%}\n    {% set where = config.get('where', '') %}\n    {% if where %}\n        {%- set filtered -%}\n            (select * from {{ relation }} where {{ where }}) dbt_subquery\n        {%- endset -%}\n        {% do return(filtered) %}\n    {%- else -%}\n        {% do return(relation) %}\n    {%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.246219, "supported_languages": null}, "macro.dbt.get_quoted_csv": {"name": "get_quoted_csv", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/column_helpers.sql", "original_file_path": "macros/materializations/models/incremental/column_helpers.sql", "unique_id": "macro.dbt.get_quoted_csv", "macro_sql": "{% macro get_quoted_csv(column_names) %}\n\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.250394, "supported_languages": null}, "macro.dbt.diff_columns": {"name": "diff_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/column_helpers.sql", "original_file_path": "macros/materializations/models/incremental/column_helpers.sql", "unique_id": "macro.dbt.diff_columns", "macro_sql": "{% macro diff_columns(source_columns, target_columns) %}\n\n  {% set result = [] %}\n  {% set source_names = source_columns | map(attribute = 'column') | list %}\n  {% set target_names = target_columns | map(attribute = 'column') | list %}\n\n   {# --check whether the name attribute exists in the target - this does not perform a data type check #}\n   {% for sc in source_columns %}\n     {% if sc.name not in target_names %}\n        {{ result.append(sc) }}\n     {% endif %}\n   {% endfor %}\n\n  {{ return(result) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.252165, "supported_languages": null}, "macro.dbt.diff_column_data_types": {"name": "diff_column_data_types", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/column_helpers.sql", "original_file_path": "macros/materializations/models/incremental/column_helpers.sql", "unique_id": "macro.dbt.diff_column_data_types", "macro_sql": "{% macro diff_column_data_types(source_columns, target_columns) %}\n\n  {% set result = [] %}\n  {% for sc in source_columns %}\n    {% set tc = target_columns | selectattr(\"name\", \"equalto\", sc.name) | list | first %}\n    {% if tc %}\n      {% if sc.data_type != tc.data_type and not sc.can_expand_to(other_column=tc) %}\n        {{ result.append( { 'column_name': tc.name, 'new_type': sc.data_type } ) }}\n      {% endif %}\n    {% endif %}\n  {% endfor %}\n\n  {{ return(result) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.2542741, "supported_languages": null}, "macro.dbt.get_merge_update_columns": {"name": "get_merge_update_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/column_helpers.sql", "original_file_path": "macros/materializations/models/incremental/column_helpers.sql", "unique_id": "macro.dbt.get_merge_update_columns", "macro_sql": "{% macro get_merge_update_columns(merge_update_columns, merge_exclude_columns, dest_columns) %}\n  {{ return(adapter.dispatch('get_merge_update_columns', 'dbt')(merge_update_columns, merge_exclude_columns, dest_columns)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__get_merge_update_columns"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.2550368, "supported_languages": null}, "macro.dbt.default__get_merge_update_columns": {"name": "default__get_merge_update_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/column_helpers.sql", "original_file_path": "macros/materializations/models/incremental/column_helpers.sql", "unique_id": "macro.dbt.default__get_merge_update_columns", "macro_sql": "{% macro default__get_merge_update_columns(merge_update_columns, merge_exclude_columns, dest_columns) %}\n  {%- set default_cols = dest_columns | map(attribute=\"quoted\") | list -%}\n\n  {%- if merge_update_columns and merge_exclude_columns -%}\n    {{ exceptions.raise_compiler_error(\n        'Model cannot specify merge_update_columns and merge_exclude_columns. Please update model to use only one config'\n    )}}\n  {%- elif merge_update_columns -%}\n    {%- set update_columns = merge_update_columns -%}\n  {%- elif merge_exclude_columns -%}\n    {%- set update_columns = [] -%}\n    {%- for column in dest_columns -%}\n      {% if column.column | lower not in merge_exclude_columns | map(\"lower\") | list %}\n        {%- do update_columns.append(column.quoted) -%}\n      {% endif %}\n    {%- endfor -%}\n  {%- else -%}\n    {%- set update_columns = default_cols -%}\n  {%- endif -%}\n\n  {{ return(update_columns) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.257327, "supported_languages": null}, "macro.dbt.get_merge_sql": {"name": "get_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "unique_id": "macro.dbt.get_merge_sql", "macro_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, incremental_predicates=none) -%}\n   -- back compat for old kwarg name\n  {% set incremental_predicates = kwargs.get('predicates', incremental_predicates) %}\n  {{ adapter.dispatch('get_merge_sql', 'dbt')(target, source, unique_key, dest_columns, incremental_predicates) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.272324, "supported_languages": null}, "macro.dbt.default__get_merge_sql": {"name": "default__get_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "unique_id": "macro.dbt.default__get_merge_sql", "macro_sql": "{% macro default__get_merge_sql(target, source, unique_key, dest_columns, incremental_predicates=none) -%}\n    {%- set predicates = [] if incremental_predicates is none else [] + incremental_predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n    {%- set merge_update_columns = config.get('merge_update_columns') -%}\n    {%- set merge_exclude_columns = config.get('merge_exclude_columns') -%}\n    {%- set update_columns = get_merge_update_columns(merge_update_columns, merge_exclude_columns, dest_columns) -%}\n    {%- set sql_header = config.get('sql_header', none) -%}\n\n    {% if unique_key %}\n        {% if unique_key is sequence and unique_key is not mapping and unique_key is not string %}\n            {% for key in unique_key %}\n                {% set this_key_match %}\n                    DBT_INTERNAL_SOURCE.{{ key }} = DBT_INTERNAL_DEST.{{ key }}\n                {% endset %}\n                {% do predicates.append(this_key_match) %}\n            {% endfor %}\n        {% else %}\n            {% set unique_key_match %}\n                DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n            {% endset %}\n            {% do predicates.append(unique_key_match) %}\n        {% endif %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    {{ sql_header if sql_header is not none }}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{\"(\" ~ predicates | join(\") and (\") ~ \")\"}}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column_name in update_columns -%}\n            {{ column_name }} = DBT_INTERNAL_SOURCE.{{ column_name }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_quoted_csv", "macro.dbt.get_merge_update_columns"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.2778418, "supported_languages": null}, "macro.dbt.get_delete_insert_merge_sql": {"name": "get_delete_insert_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "unique_id": "macro.dbt.get_delete_insert_merge_sql", "macro_sql": "{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns, incremental_predicates) -%}\n  {{ adapter.dispatch('get_delete_insert_merge_sql', 'dbt')(target, source, unique_key, dest_columns, incremental_predicates) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_delete_insert_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.2786748, "supported_languages": null}, "macro.dbt.default__get_delete_insert_merge_sql": {"name": "default__get_delete_insert_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "unique_id": "macro.dbt.default__get_delete_insert_merge_sql", "macro_sql": "{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns, incremental_predicates) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key %}\n        {% if unique_key is sequence and unique_key is not string %}\n            delete from {{target }}\n            using {{ source }}\n            where (\n                {% for key in unique_key %}\n                    {{ source }}.{{ key }} = {{ target }}.{{ key }}\n                    {{ \"and \" if not loop.last}}\n                {% endfor %}\n                {% if incremental_predicates %}\n                    {% for predicate in incremental_predicates %}\n                        and {{ predicate }}\n                    {% endfor %}\n                {% endif %}\n            );\n        {% else %}\n            delete from {{ target }}\n            where (\n                {{ unique_key }}) in (\n                select ({{ unique_key }})\n                from {{ source }}\n            )\n            {%- if incremental_predicates %}\n                {% for predicate in incremental_predicates %}\n                    and {{ predicate }}\n                {% endfor %}\n            {%- endif -%};\n\n        {% endif %}\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    )\n\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.get_quoted_csv"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.281867, "supported_languages": null}, "macro.dbt.get_insert_overwrite_merge_sql": {"name": "get_insert_overwrite_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "unique_id": "macro.dbt.get_insert_overwrite_merge_sql", "macro_sql": "{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates, include_sql_header=false) -%}\n  {{ adapter.dispatch('get_insert_overwrite_merge_sql', 'dbt')(target, source, dest_columns, predicates, include_sql_header) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_insert_overwrite_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.282722, "supported_languages": null}, "macro.dbt.default__get_insert_overwrite_merge_sql": {"name": "default__get_insert_overwrite_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "unique_id": "macro.dbt.default__get_insert_overwrite_merge_sql", "macro_sql": "{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates, include_sql_header) -%}\n    {#-- The only time include_sql_header is True: --#}\n    {#-- BigQuery + insert_overwrite strategy + \"static\" partitions config --#}\n    {#-- We should consider including the sql header at the materialization level instead --#}\n\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n    {%- set sql_header = config.get('sql_header', none) -%}\n\n    {{ sql_header if sql_header is not none and include_sql_header }}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n\n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_quoted_csv"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.2847738, "supported_languages": null}, "macro.dbt.is_incremental": {"name": "is_incremental", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/is_incremental.sql", "original_file_path": "macros/materializations/models/incremental/is_incremental.sql", "unique_id": "macro.dbt.is_incremental", "macro_sql": "{% macro is_incremental() %}\n    {#-- do not run introspective queries in parsing #}\n    {% if not execute %}\n        {{ return(False) }}\n    {% else %}\n        {% set relation = adapter.get_relation(this.database, this.schema, this.table) %}\n        {{ return(relation is not none\n                  and relation.type == 'table'\n                  and model.config.materialized == 'incremental'\n                  and not should_full_refresh()) }}\n    {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.should_full_refresh"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.2866821, "supported_languages": null}, "macro.dbt.get_incremental_append_sql": {"name": "get_incremental_append_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.get_incremental_append_sql", "macro_sql": "{% macro get_incremental_append_sql(arg_dict) %}\n\n  {{ return(adapter.dispatch('get_incremental_append_sql', 'dbt')(arg_dict)) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_incremental_append_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.289089, "supported_languages": null}, "macro.dbt.default__get_incremental_append_sql": {"name": "default__get_incremental_append_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.default__get_incremental_append_sql", "macro_sql": "{% macro default__get_incremental_append_sql(arg_dict) %}\n\n  {% do return(get_insert_into_sql(arg_dict[\"target_relation\"], arg_dict[\"temp_relation\"], arg_dict[\"dest_columns\"])) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_insert_into_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.289854, "supported_languages": null}, "macro.dbt.get_incremental_delete_insert_sql": {"name": "get_incremental_delete_insert_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.get_incremental_delete_insert_sql", "macro_sql": "{% macro get_incremental_delete_insert_sql(arg_dict) %}\n\n  {{ return(adapter.dispatch('get_incremental_delete_insert_sql', 'dbt')(arg_dict)) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_incremental_delete_insert_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.29047, "supported_languages": null}, "macro.dbt.default__get_incremental_delete_insert_sql": {"name": "default__get_incremental_delete_insert_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.default__get_incremental_delete_insert_sql", "macro_sql": "{% macro default__get_incremental_delete_insert_sql(arg_dict) %}\n\n  {% do return(get_delete_insert_merge_sql(arg_dict[\"target_relation\"], arg_dict[\"temp_relation\"], arg_dict[\"unique_key\"], arg_dict[\"dest_columns\"], arg_dict[\"incremental_predicates\"])) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_delete_insert_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.291425, "supported_languages": null}, "macro.dbt.get_incremental_merge_sql": {"name": "get_incremental_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.get_incremental_merge_sql", "macro_sql": "{% macro get_incremental_merge_sql(arg_dict) %}\n\n  {{ return(adapter.dispatch('get_incremental_merge_sql', 'dbt')(arg_dict)) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_incremental_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.292046, "supported_languages": null}, "macro.dbt.default__get_incremental_merge_sql": {"name": "default__get_incremental_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.default__get_incremental_merge_sql", "macro_sql": "{% macro default__get_incremental_merge_sql(arg_dict) %}\n\n  {% do return(get_merge_sql(arg_dict[\"target_relation\"], arg_dict[\"temp_relation\"], arg_dict[\"unique_key\"], arg_dict[\"dest_columns\"], arg_dict[\"incremental_predicates\"])) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.292999, "supported_languages": null}, "macro.dbt.get_incremental_insert_overwrite_sql": {"name": "get_incremental_insert_overwrite_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.get_incremental_insert_overwrite_sql", "macro_sql": "{% macro get_incremental_insert_overwrite_sql(arg_dict) %}\n\n  {{ return(adapter.dispatch('get_incremental_insert_overwrite_sql', 'dbt')(arg_dict)) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_incremental_insert_overwrite_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.2936199, "supported_languages": null}, "macro.dbt.default__get_incremental_insert_overwrite_sql": {"name": "default__get_incremental_insert_overwrite_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.default__get_incremental_insert_overwrite_sql", "macro_sql": "{% macro default__get_incremental_insert_overwrite_sql(arg_dict) %}\n\n  {% do return(get_insert_overwrite_merge_sql(arg_dict[\"target_relation\"], arg_dict[\"temp_relation\"], arg_dict[\"dest_columns\"], arg_dict[\"incremental_predicates\"])) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_insert_overwrite_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.2944798, "supported_languages": null}, "macro.dbt.get_incremental_default_sql": {"name": "get_incremental_default_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.get_incremental_default_sql", "macro_sql": "{% macro get_incremental_default_sql(arg_dict) %}\n\n  {{ return(adapter.dispatch('get_incremental_default_sql', 'dbt')(arg_dict)) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_incremental_default_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.295104, "supported_languages": null}, "macro.dbt.default__get_incremental_default_sql": {"name": "default__get_incremental_default_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.default__get_incremental_default_sql", "macro_sql": "{% macro default__get_incremental_default_sql(arg_dict) %}\n\n  {% do return(get_incremental_append_sql(arg_dict)) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_incremental_append_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.2956202, "supported_languages": null}, "macro.dbt.get_insert_into_sql": {"name": "get_insert_into_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.get_insert_into_sql", "macro_sql": "{% macro get_insert_into_sql(target_relation, temp_relation, dest_columns) %}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    insert into {{ target_relation }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ temp_relation }}\n    )\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_quoted_csv"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.296533, "supported_languages": null}, "macro.dbt.materialization_incremental_default": {"name": "materialization_incremental_default", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/incremental.sql", "original_file_path": "macros/materializations/models/incremental/incremental.sql", "unique_id": "macro.dbt.materialization_incremental_default", "macro_sql": "{% materialization incremental, default -%}\n\n  -- relations\n  {%- set existing_relation = load_cached_relation(this) -%}\n  {%- set target_relation = this.incorporate(type='table') -%}\n  {%- set temp_relation = make_temp_relation(target_relation)-%}\n  {%- set intermediate_relation = make_intermediate_relation(target_relation)-%}\n  {%- set backup_relation_type = 'table' if existing_relation is none else existing_relation.type -%}\n  {%- set backup_relation = make_backup_relation(target_relation, backup_relation_type) -%}\n\n  -- configs\n  {%- set unique_key = config.get('unique_key') -%}\n  {%- set full_refresh_mode = (should_full_refresh()  or existing_relation.is_view) -%}\n  {%- set on_schema_change = incremental_validate_on_schema_change(config.get('on_schema_change'), default='ignore') -%}\n\n  -- the temp_ and backup_ relations should not already exist in the database; get_relation\n  -- will return None in that case. Otherwise, we get a relation that we can drop\n  -- later, before we try to use this name for the current operation. This has to happen before\n  -- BEGIN, in a separate transaction\n  {%- set preexisting_intermediate_relation = load_cached_relation(intermediate_relation)-%}\n  {%- set preexisting_backup_relation = load_cached_relation(backup_relation) -%}\n   -- grab current tables grants config for comparision later on\n  {% set grant_config = config.get('grants') %}\n  {{ drop_relation_if_exists(preexisting_intermediate_relation) }}\n  {{ drop_relation_if_exists(preexisting_backup_relation) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set to_drop = [] %}\n\n  {% if existing_relation is none %}\n      {% set build_sql = get_create_table_as_sql(False, target_relation, sql) %}\n  {% elif full_refresh_mode %}\n      {% set build_sql = get_create_table_as_sql(False, intermediate_relation, sql) %}\n      {% set need_swap = true %}\n  {% else %}\n    {% do run_query(get_create_table_as_sql(True, temp_relation, sql)) %}\n    {% do adapter.expand_target_column_types(\n             from_relation=temp_relation,\n             to_relation=target_relation) %}\n    {#-- Process schema changes. Returns dict of changes if successful. Use source columns for upserting/merging --#}\n    {% set dest_columns = process_schema_changes(on_schema_change, temp_relation, existing_relation) %}\n    {% if not dest_columns %}\n      {% set dest_columns = adapter.get_columns_in_relation(existing_relation) %}\n    {% endif %}\n\n    {#-- Get the incremental_strategy, the macro to use for the strategy, and build the sql --#}\n    {% set incremental_strategy = config.get('incremental_strategy') or 'default' %}\n    {% set incremental_predicates = config.get('predicates', none) or config.get('incremental_predicates', none) %}\n    {% set strategy_sql_macro_func = adapter.get_incremental_strategy_macro(context, incremental_strategy) %}\n    {% set strategy_arg_dict = ({'target_relation': target_relation, 'temp_relation': temp_relation, 'unique_key': unique_key, 'dest_columns': dest_columns, 'incremental_predicates': incremental_predicates }) %}\n    {% set build_sql = strategy_sql_macro_func(strategy_arg_dict) %}\n\n  {% endif %}\n\n  {% call statement(\"main\") %}\n      {{ build_sql }}\n  {% endcall %}\n\n  {% if need_swap %}\n      {% do adapter.rename_relation(target_relation, backup_relation) %}\n      {% do adapter.rename_relation(intermediate_relation, target_relation) %}\n      {% do to_drop.append(backup_relation) %}\n  {% endif %}\n\n  {% set should_revoke = should_revoke(existing_relation, full_refresh_mode) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {% if existing_relation is none or existing_relation.is_view or should_full_refresh() %}\n    {% do create_indexes(target_relation) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {% do adapter.commit() %}\n\n  {% for rel in to_drop %}\n      {% do adapter.drop_relation(rel) %}\n  {% endfor %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "depends_on": {"macros": ["macro.dbt.load_cached_relation", "macro.dbt.make_temp_relation", "macro.dbt.make_intermediate_relation", "macro.dbt.make_backup_relation", "macro.dbt.should_full_refresh", "macro.dbt.incremental_validate_on_schema_change", "macro.dbt.drop_relation_if_exists", "macro.dbt.run_hooks", "macro.dbt.get_create_table_as_sql", "macro.dbt.run_query", "macro.dbt.process_schema_changes", "macro.dbt.statement", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs", "macro.dbt.create_indexes"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.311139, "supported_languages": ["sql"]}, "macro.dbt.incremental_validate_on_schema_change": {"name": "incremental_validate_on_schema_change", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/on_schema_change.sql", "original_file_path": "macros/materializations/models/incremental/on_schema_change.sql", "unique_id": "macro.dbt.incremental_validate_on_schema_change", "macro_sql": "{% macro incremental_validate_on_schema_change(on_schema_change, default='ignore') %}\n\n   {% if on_schema_change not in ['sync_all_columns', 'append_new_columns', 'fail', 'ignore'] %}\n\n     {% set log_message = 'Invalid value for on_schema_change (%s) specified. Setting default value of %s.' % (on_schema_change, default) %}\n     {% do log(log_message) %}\n\n     {{ return(default) }}\n\n   {% else %}\n\n     {{ return(on_schema_change) }}\n\n   {% endif %}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.324755, "supported_languages": null}, "macro.dbt.check_for_schema_changes": {"name": "check_for_schema_changes", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/on_schema_change.sql", "original_file_path": "macros/materializations/models/incremental/on_schema_change.sql", "unique_id": "macro.dbt.check_for_schema_changes", "macro_sql": "{% macro check_for_schema_changes(source_relation, target_relation) %}\n\n  {% set schema_changed = False %}\n\n  {%- set source_columns = adapter.get_columns_in_relation(source_relation) -%}\n  {%- set target_columns = adapter.get_columns_in_relation(target_relation) -%}\n  {%- set source_not_in_target = diff_columns(source_columns, target_columns) -%}\n  {%- set target_not_in_source = diff_columns(target_columns, source_columns) -%}\n\n  {% set new_target_types = diff_column_data_types(source_columns, target_columns) %}\n\n  {% if source_not_in_target != [] %}\n    {% set schema_changed = True %}\n  {% elif target_not_in_source != [] or new_target_types != [] %}\n    {% set schema_changed = True %}\n  {% elif new_target_types != [] %}\n    {% set schema_changed = True %}\n  {% endif %}\n\n  {% set changes_dict = {\n    'schema_changed': schema_changed,\n    'source_not_in_target': source_not_in_target,\n    'target_not_in_source': target_not_in_source,\n    'source_columns': source_columns,\n    'target_columns': target_columns,\n    'new_target_types': new_target_types\n  } %}\n\n  {% set msg %}\n    In {{ target_relation }}:\n        Schema changed: {{ schema_changed }}\n        Source columns not in target: {{ source_not_in_target }}\n        Target columns not in source: {{ target_not_in_source }}\n        New column types: {{ new_target_types }}\n  {% endset %}\n\n  {% do log(msg) %}\n\n  {{ return(changes_dict) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.diff_columns", "macro.dbt.diff_column_data_types"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.328634, "supported_languages": null}, "macro.dbt.sync_column_schemas": {"name": "sync_column_schemas", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/on_schema_change.sql", "original_file_path": "macros/materializations/models/incremental/on_schema_change.sql", "unique_id": "macro.dbt.sync_column_schemas", "macro_sql": "{% macro sync_column_schemas(on_schema_change, target_relation, schema_changes_dict) %}\n\n  {%- set add_to_target_arr = schema_changes_dict['source_not_in_target'] -%}\n\n  {%- if on_schema_change == 'append_new_columns'-%}\n     {%- if add_to_target_arr | length > 0 -%}\n       {%- do alter_relation_add_remove_columns(target_relation, add_to_target_arr, none) -%}\n     {%- endif -%}\n\n  {% elif on_schema_change == 'sync_all_columns' %}\n     {%- set remove_from_target_arr = schema_changes_dict['target_not_in_source'] -%}\n     {%- set new_target_types = schema_changes_dict['new_target_types'] -%}\n\n     {% if add_to_target_arr | length > 0 or remove_from_target_arr | length > 0 %}\n       {%- do alter_relation_add_remove_columns(target_relation, add_to_target_arr, remove_from_target_arr) -%}\n     {% endif %}\n\n     {% if new_target_types != [] %}\n       {% for ntt in new_target_types %}\n         {% set column_name = ntt['column_name'] %}\n         {% set new_type = ntt['new_type'] %}\n         {% do alter_column_type(target_relation, column_name, new_type) %}\n       {% endfor %}\n     {% endif %}\n\n  {% endif %}\n\n  {% set schema_change_message %}\n    In {{ target_relation }}:\n        Schema change approach: {{ on_schema_change }}\n        Columns added: {{ add_to_target_arr }}\n        Columns removed: {{ remove_from_target_arr }}\n        Data types changed: {{ new_target_types }}\n  {% endset %}\n\n  {% do log(schema_change_message) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.alter_relation_add_remove_columns", "macro.dbt.alter_column_type"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.3324401, "supported_languages": null}, "macro.dbt.process_schema_changes": {"name": "process_schema_changes", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/on_schema_change.sql", "original_file_path": "macros/materializations/models/incremental/on_schema_change.sql", "unique_id": "macro.dbt.process_schema_changes", "macro_sql": "{% macro process_schema_changes(on_schema_change, source_relation, target_relation) %}\n\n    {% if on_schema_change == 'ignore' %}\n\n     {{ return({}) }}\n\n    {% else %}\n\n      {% set schema_changes_dict = check_for_schema_changes(source_relation, target_relation) %}\n\n      {% if schema_changes_dict['schema_changed'] %}\n\n        {% if on_schema_change == 'fail' %}\n\n          {% set fail_msg %}\n              The source and target schemas on this incremental model are out of sync!\n              They can be reconciled in several ways:\n                - set the `on_schema_change` config to either append_new_columns or sync_all_columns, depending on your situation.\n                - Re-run the incremental model with `full_refresh: True` to update the target schema.\n                - update the schema manually and re-run the process.\n\n              Additional troubleshooting context:\n                 Source columns not in target: {{ schema_changes_dict['source_not_in_target'] }}\n                 Target columns not in source: {{ schema_changes_dict['target_not_in_source'] }}\n                 New column types: {{ schema_changes_dict['new_target_types'] }}\n          {% endset %}\n\n          {% do exceptions.raise_compiler_error(fail_msg) %}\n\n        {# -- unless we ignore, run the sync operation per the config #}\n        {% else %}\n\n          {% do sync_column_schemas(on_schema_change, target_relation, schema_changes_dict) %}\n\n        {% endif %}\n\n      {% endif %}\n\n      {{ return(schema_changes_dict['source_columns']) }}\n\n    {% endif %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.check_for_schema_changes", "macro.dbt.sync_column_schemas"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.3351629, "supported_languages": null}, "macro.dbt.get_table_columns_and_constraints": {"name": "get_table_columns_and_constraints", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/table/columns_spec_ddl.sql", "original_file_path": "macros/materializations/models/table/columns_spec_ddl.sql", "unique_id": "macro.dbt.get_table_columns_and_constraints", "macro_sql": "{%- macro get_table_columns_and_constraints() -%}\n  {{ adapter.dispatch('get_table_columns_and_constraints', 'dbt')() }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__get_table_columns_and_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.337846, "supported_languages": null}, "macro.dbt.default__get_table_columns_and_constraints": {"name": "default__get_table_columns_and_constraints", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/table/columns_spec_ddl.sql", "original_file_path": "macros/materializations/models/table/columns_spec_ddl.sql", "unique_id": "macro.dbt.default__get_table_columns_and_constraints", "macro_sql": "{% macro default__get_table_columns_and_constraints() -%}\n  {{ return(table_columns_and_constraints()) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.table_columns_and_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.338258, "supported_languages": null}, "macro.dbt.table_columns_and_constraints": {"name": "table_columns_and_constraints", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/table/columns_spec_ddl.sql", "original_file_path": "macros/materializations/models/table/columns_spec_ddl.sql", "unique_id": "macro.dbt.table_columns_and_constraints", "macro_sql": "{% macro table_columns_and_constraints() %}\n  {# loop through user_provided_columns to create DDL with data types and constraints #}\n    {%- set raw_column_constraints = adapter.render_raw_columns_constraints(raw_columns=model['columns']) -%}\n    {%- set raw_model_constraints = adapter.render_raw_model_constraints(raw_constraints=model['constraints']) -%}\n    (\n    {% for c in raw_column_constraints -%}\n      {{ c }}{{ \",\" if not loop.last or raw_model_constraints }}\n    {% endfor %}\n    {% for c in raw_model_constraints -%}\n        {{ c }}{{ \",\" if not loop.last }}\n    {% endfor -%}\n    )\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.339962, "supported_languages": null}, "macro.dbt.get_assert_columns_equivalent": {"name": "get_assert_columns_equivalent", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/table/columns_spec_ddl.sql", "original_file_path": "macros/materializations/models/table/columns_spec_ddl.sql", "unique_id": "macro.dbt.get_assert_columns_equivalent", "macro_sql": "\n\n{%- macro get_assert_columns_equivalent(sql) -%}\n  {{ adapter.dispatch('get_assert_columns_equivalent', 'dbt')(sql) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__get_assert_columns_equivalent"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.340517, "supported_languages": null}, "macro.dbt.default__get_assert_columns_equivalent": {"name": "default__get_assert_columns_equivalent", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/table/columns_spec_ddl.sql", "original_file_path": "macros/materializations/models/table/columns_spec_ddl.sql", "unique_id": "macro.dbt.default__get_assert_columns_equivalent", "macro_sql": "{% macro default__get_assert_columns_equivalent(sql) -%}\n  {{ return(assert_columns_equivalent(sql)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.assert_columns_equivalent"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.3409789, "supported_languages": null}, "macro.dbt.assert_columns_equivalent": {"name": "assert_columns_equivalent", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/table/columns_spec_ddl.sql", "original_file_path": "macros/materializations/models/table/columns_spec_ddl.sql", "unique_id": "macro.dbt.assert_columns_equivalent", "macro_sql": "{% macro assert_columns_equivalent(sql) %}\n\n  {#-- First ensure the user has defined 'columns' in yaml specification --#}\n  {%- set user_defined_columns = model['columns'] -%}\n  {%- if not user_defined_columns -%}\n      {{ exceptions.raise_contract_error([], []) }}\n  {%- endif -%}\n\n  {#-- Obtain the column schema provided by sql file. #}\n  {%- set sql_file_provided_columns = get_column_schema_from_query(sql, config.get('sql_header', none)) -%}\n  {#--Obtain the column schema provided by the schema file by generating an 'empty schema' query from the model's columns. #}\n  {%- set schema_file_provided_columns = get_column_schema_from_query(get_empty_schema_sql(user_defined_columns)) -%}\n\n  {#-- create dictionaries with name and formatted data type and strings for exception #}\n  {%- set sql_columns = format_columns(sql_file_provided_columns) -%}\n  {%- set yaml_columns = format_columns(schema_file_provided_columns)  -%}\n\n  {%- if sql_columns|length != yaml_columns|length -%}\n    {%- do exceptions.raise_contract_error(yaml_columns, sql_columns) -%}\n  {%- endif -%}\n\n  {%- for sql_col in sql_columns -%}\n    {%- set yaml_col = [] -%}\n    {%- for this_col in yaml_columns -%}\n      {%- if this_col['name'] == sql_col['name'] -%}\n        {%- do yaml_col.append(this_col) -%}\n        {%- break -%}\n      {%- endif -%}\n    {%- endfor -%}\n    {%- if not yaml_col -%}\n      {#-- Column with name not found in yaml #}\n      {%- do exceptions.raise_contract_error(yaml_columns, sql_columns) -%}\n    {%- endif -%}\n    {%- if sql_col['formatted'] != yaml_col[0]['formatted'] -%}\n      {#-- Column data types don't match #}\n      {%- do exceptions.raise_contract_error(yaml_columns, sql_columns) -%}\n    {%- endif -%}\n  {%- endfor -%}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_column_schema_from_query", "macro.dbt.get_empty_schema_sql", "macro.dbt.format_columns"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.345006, "supported_languages": null}, "macro.dbt.format_columns": {"name": "format_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/table/columns_spec_ddl.sql", "original_file_path": "macros/materializations/models/table/columns_spec_ddl.sql", "unique_id": "macro.dbt.format_columns", "macro_sql": "{% macro format_columns(columns) %}\n  {% set formatted_columns = [] %}\n  {% for column in columns %}\n    {%- set formatted_column = adapter.dispatch('format_column', 'dbt')(column) -%}\n    {%- do formatted_columns.append(formatted_column) -%}\n  {% endfor %}\n  {{ return(formatted_columns) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__format_column"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.346242, "supported_languages": null}, "macro.dbt.default__format_column": {"name": "default__format_column", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/table/columns_spec_ddl.sql", "original_file_path": "macros/materializations/models/table/columns_spec_ddl.sql", "unique_id": "macro.dbt.default__format_column", "macro_sql": "{% macro default__format_column(column) -%}\n  {% set data_type = column.dtype %}\n  {% set formatted = column.column.lower() ~ \" \" ~ data_type %}\n  {{ return({'name': column.name, 'data_type': data_type, 'formatted': formatted}) }}\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.347351, "supported_languages": null}, "macro.dbt.materialization_table_default": {"name": "materialization_table_default", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/table/table.sql", "original_file_path": "macros/materializations/models/table/table.sql", "unique_id": "macro.dbt.materialization_table_default", "macro_sql": "{% materialization table, default %}\n\n  {%- set existing_relation = load_cached_relation(this) -%}\n  {%- set target_relation = this.incorporate(type='table') %}\n  {%- set intermediate_relation =  make_intermediate_relation(target_relation) -%}\n  -- the intermediate_relation should not already exist in the database; get_relation\n  -- will return None in that case. Otherwise, we get a relation that we can drop\n  -- later, before we try to use this name for the current operation\n  {%- set preexisting_intermediate_relation = load_cached_relation(intermediate_relation) -%}\n  /*\n      See ../view/view.sql for more information about this relation.\n  */\n  {%- set backup_relation_type = 'table' if existing_relation is none else existing_relation.type -%}\n  {%- set backup_relation = make_backup_relation(target_relation, backup_relation_type) -%}\n  -- as above, the backup_relation should not already exist\n  {%- set preexisting_backup_relation = load_cached_relation(backup_relation) -%}\n  -- grab current tables grants config for comparision later on\n  {% set grant_config = config.get('grants') %}\n\n  -- drop the temp relations if they exist already in the database\n  {{ drop_relation_if_exists(preexisting_intermediate_relation) }}\n  {{ drop_relation_if_exists(preexisting_backup_relation) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ get_create_table_as_sql(False, intermediate_relation, sql) }}\n  {%- endcall %}\n\n  -- cleanup\n  {% if existing_relation is not none %}\n      {{ adapter.rename_relation(existing_relation, backup_relation) }}\n  {% endif %}\n\n  {{ adapter.rename_relation(intermediate_relation, target_relation) }}\n\n  {% do create_indexes(target_relation) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {% set should_revoke = should_revoke(existing_relation, full_refresh_mode=True) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  -- finally, drop the existing/backup relation after the commit\n  {{ drop_relation_if_exists(backup_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt.load_cached_relation", "macro.dbt.make_intermediate_relation", "macro.dbt.make_backup_relation", "macro.dbt.drop_relation_if_exists", "macro.dbt.run_hooks", "macro.dbt.statement", "macro.dbt.get_create_table_as_sql", "macro.dbt.create_indexes", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.35493, "supported_languages": ["sql"]}, "macro.dbt.get_create_table_as_sql": {"name": "get_create_table_as_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/table/create_table_as.sql", "original_file_path": "macros/materializations/models/table/create_table_as.sql", "unique_id": "macro.dbt.get_create_table_as_sql", "macro_sql": "{% macro get_create_table_as_sql(temporary, relation, sql) -%}\n  {{ adapter.dispatch('get_create_table_as_sql', 'dbt')(temporary, relation, sql) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_create_table_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.357273, "supported_languages": null}, "macro.dbt.default__get_create_table_as_sql": {"name": "default__get_create_table_as_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/table/create_table_as.sql", "original_file_path": "macros/materializations/models/table/create_table_as.sql", "unique_id": "macro.dbt.default__get_create_table_as_sql", "macro_sql": "{% macro default__get_create_table_as_sql(temporary, relation, sql) -%}\n  {{ return(create_table_as(temporary, relation, sql)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.create_table_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.357885, "supported_languages": null}, "macro.dbt.create_table_as": {"name": "create_table_as", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/table/create_table_as.sql", "original_file_path": "macros/materializations/models/table/create_table_as.sql", "unique_id": "macro.dbt.create_table_as", "macro_sql": "{% macro create_table_as(temporary, relation, compiled_code, language='sql') -%}\n  {# backward compatibility for create_table_as that does not support language #}\n  {% if language == \"sql\" %}\n    {{ adapter.dispatch('create_table_as', 'dbt')(temporary, relation, compiled_code)}}\n  {% else %}\n    {{ adapter.dispatch('create_table_as', 'dbt')(temporary, relation, compiled_code, language) }}\n  {% endif %}\n\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__create_table_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.3592708, "supported_languages": null}, "macro.dbt.default__create_table_as": {"name": "default__create_table_as", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/table/create_table_as.sql", "original_file_path": "macros/materializations/models/table/create_table_as.sql", "unique_id": "macro.dbt.default__create_table_as", "macro_sql": "{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  {% set contract_config = config.get('contract') %}\n  {% if contract_config.enforced %}\n    {{ get_assert_columns_equivalent(sql) }}\n    {{ get_table_columns_and_constraints() }}\n    {%- set sql = get_select_subquery(sql) %}\n  {% endif %}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.get_assert_columns_equivalent", "macro.dbt.get_table_columns_and_constraints", "macro.dbt.get_select_subquery"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.361398, "supported_languages": null}, "macro.dbt.default__get_column_names": {"name": "default__get_column_names", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/table/create_table_as.sql", "original_file_path": "macros/materializations/models/table/create_table_as.sql", "unique_id": "macro.dbt.default__get_column_names", "macro_sql": "{% macro default__get_column_names() %}\n  {#- loop through user_provided_columns to get column names -#}\n    {%- set user_provided_columns = model['columns'] -%}\n    {%- for i in user_provided_columns %}\n      {%- set col = user_provided_columns[i] -%}\n      {%- set col_name = adapter.quote(col['name']) if col.get('quote') else col['name'] -%}\n      {{ col_name }}{{ \", \" if not loop.last }}\n    {%- endfor -%}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.362887, "supported_languages": null}, "macro.dbt.get_select_subquery": {"name": "get_select_subquery", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/table/create_table_as.sql", "original_file_path": "macros/materializations/models/table/create_table_as.sql", "unique_id": "macro.dbt.get_select_subquery", "macro_sql": "{% macro get_select_subquery(sql) %}\n  {{ return(adapter.dispatch('get_select_subquery', 'dbt')(sql)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_select_subquery"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.363515, "supported_languages": null}, "macro.dbt.default__get_select_subquery": {"name": "default__get_select_subquery", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/table/create_table_as.sql", "original_file_path": "macros/materializations/models/table/create_table_as.sql", "unique_id": "macro.dbt.default__get_select_subquery", "macro_sql": "{% macro default__get_select_subquery(sql) %}\n    select {{ adapter.dispatch('get_column_names', 'dbt')() }}\n    from (\n        {{ sql }}\n    ) as model_subq\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_column_names"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.364116, "supported_languages": null}, "macro.dbt.materialization_view_default": {"name": "materialization_view_default", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/view/view.sql", "original_file_path": "macros/materializations/models/view/view.sql", "unique_id": "macro.dbt.materialization_view_default", "macro_sql": "{%- materialization view, default -%}\n\n  {%- set existing_relation = load_cached_relation(this) -%}\n  {%- set target_relation = this.incorporate(type='view') -%}\n  {%- set intermediate_relation =  make_intermediate_relation(target_relation) -%}\n\n  -- the intermediate_relation should not already exist in the database; get_relation\n  -- will return None in that case. Otherwise, we get a relation that we can drop\n  -- later, before we try to use this name for the current operation\n  {%- set preexisting_intermediate_relation = load_cached_relation(intermediate_relation) -%}\n  /*\n     This relation (probably) doesn't exist yet. If it does exist, it's a leftover from\n     a previous run, and we're going to try to drop it immediately. At the end of this\n     materialization, we're going to rename the \"existing_relation\" to this identifier,\n     and then we're going to drop it. In order to make sure we run the correct one of:\n       - drop view ...\n       - drop table ...\n\n     We need to set the type of this relation to be the type of the existing_relation, if it exists,\n     or else \"view\" as a sane default if it does not. Note that if the existing_relation does not\n     exist, then there is nothing to move out of the way and subsequentally drop. In that case,\n     this relation will be effectively unused.\n  */\n  {%- set backup_relation_type = 'view' if existing_relation is none else existing_relation.type -%}\n  {%- set backup_relation = make_backup_relation(target_relation, backup_relation_type) -%}\n  -- as above, the backup_relation should not already exist\n  {%- set preexisting_backup_relation = load_cached_relation(backup_relation) -%}\n  -- grab current tables grants config for comparision later on\n  {% set grant_config = config.get('grants') %}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- drop the temp relations if they exist already in the database\n  {{ drop_relation_if_exists(preexisting_intermediate_relation) }}\n  {{ drop_relation_if_exists(preexisting_backup_relation) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ get_create_view_as_sql(intermediate_relation, sql) }}\n  {%- endcall %}\n\n  -- cleanup\n  -- move the existing view out of the way\n  {% if existing_relation is not none %}\n    {{ adapter.rename_relation(existing_relation, backup_relation) }}\n  {% endif %}\n  {{ adapter.rename_relation(intermediate_relation, target_relation) }}\n\n  {% set should_revoke = should_revoke(existing_relation, full_refresh_mode=True) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {{ drop_relation_if_exists(backup_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization -%}", "depends_on": {"macros": ["macro.dbt.load_cached_relation", "macro.dbt.make_intermediate_relation", "macro.dbt.make_backup_relation", "macro.dbt.run_hooks", "macro.dbt.drop_relation_if_exists", "macro.dbt.statement", "macro.dbt.get_create_view_as_sql", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.371474, "supported_languages": ["sql"]}, "macro.dbt.handle_existing_table": {"name": "handle_existing_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/view/helpers.sql", "original_file_path": "macros/materializations/models/view/helpers.sql", "unique_id": "macro.dbt.handle_existing_table", "macro_sql": "{% macro handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter.dispatch('handle_existing_table', 'dbt')(full_refresh, old_relation) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__handle_existing_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.37241, "supported_languages": null}, "macro.dbt.default__handle_existing_table": {"name": "default__handle_existing_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/view/helpers.sql", "original_file_path": "macros/materializations/models/view/helpers.sql", "unique_id": "macro.dbt.default__handle_existing_table", "macro_sql": "{% macro default__handle_existing_table(full_refresh, old_relation) %}\n    {{ log(\"Dropping relation \" ~ old_relation ~ \" because it is of type \" ~ old_relation.type) }}\n    {{ adapter.drop_relation(old_relation) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.373138, "supported_languages": null}, "macro.dbt.create_or_replace_view": {"name": "create_or_replace_view", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/view/create_or_replace_view.sql", "original_file_path": "macros/materializations/models/view/create_or_replace_view.sql", "unique_id": "macro.dbt.create_or_replace_view", "macro_sql": "{% macro create_or_replace_view() %}\n  {%- set identifier = model['alias'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set target_relation = api.Relation.create(\n      identifier=identifier, schema=schema, database=database,\n      type='view') -%}\n  {% set grant_config = config.get('grants') %}\n\n  {{ run_hooks(pre_hooks) }}\n\n  -- If there's a table with the same name and we weren't told to full refresh,\n  -- that's an error. If we were told to full refresh, drop it. This behavior differs\n  -- for Snowflake and BigQuery, so multiple dispatch is used.\n  {%- if old_relation is not none and old_relation.is_table -%}\n    {{ handle_existing_table(should_full_refresh(), old_relation) }}\n  {%- endif -%}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ get_create_view_as_sql(target_relation, sql) }}\n  {%- endcall %}\n\n  {% set should_revoke = should_revoke(exists_as_view, full_refresh_mode=True) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n  {{ run_hooks(post_hooks) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_hooks", "macro.dbt.handle_existing_table", "macro.dbt.should_full_refresh", "macro.dbt.statement", "macro.dbt.get_create_view_as_sql", "macro.dbt.should_revoke", "macro.dbt.apply_grants"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.377602, "supported_languages": null}, "macro.dbt.get_create_view_as_sql": {"name": "get_create_view_as_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/view/create_view_as.sql", "original_file_path": "macros/materializations/models/view/create_view_as.sql", "unique_id": "macro.dbt.get_create_view_as_sql", "macro_sql": "{% macro get_create_view_as_sql(relation, sql) -%}\n  {{ adapter.dispatch('get_create_view_as_sql', 'dbt')(relation, sql) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_create_view_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.3788311, "supported_languages": null}, "macro.dbt.default__get_create_view_as_sql": {"name": "default__get_create_view_as_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/view/create_view_as.sql", "original_file_path": "macros/materializations/models/view/create_view_as.sql", "unique_id": "macro.dbt.default__get_create_view_as_sql", "macro_sql": "{% macro default__get_create_view_as_sql(relation, sql) -%}\n  {{ return(create_view_as(relation, sql)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.create_view_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.379377, "supported_languages": null}, "macro.dbt.create_view_as": {"name": "create_view_as", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/view/create_view_as.sql", "original_file_path": "macros/materializations/models/view/create_view_as.sql", "unique_id": "macro.dbt.create_view_as", "macro_sql": "{% macro create_view_as(relation, sql) -%}\n  {{ adapter.dispatch('create_view_as', 'dbt')(relation, sql) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__create_view_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.3799832, "supported_languages": null}, "macro.dbt.default__create_view_as": {"name": "default__create_view_as", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/view/create_view_as.sql", "original_file_path": "macros/materializations/models/view/create_view_as.sql", "unique_id": "macro.dbt.default__create_view_as", "macro_sql": "{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }}\n    {% set contract_config = config.get('contract') %}\n    {% if contract_config.enforced %}\n      {{ get_assert_columns_equivalent(sql) }}\n    {%- endif %}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.get_assert_columns_equivalent"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.381352, "supported_languages": null}, "macro.dbt.materialization_seed_default": {"name": "materialization_seed_default", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/seed.sql", "original_file_path": "macros/materializations/seeds/seed.sql", "unique_id": "macro.dbt.materialization_seed_default", "macro_sql": "{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (should_full_refresh()) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set grant_config = config.get('grants') -%}\n  {%- set agate_table = load_agate_table() -%}\n  -- grab current tables grants config for comparision later on\n\n  {%- do store_result('agate_table', response='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set code = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set rows_affected = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', code ~ ' ' ~ rows_affected, code, rows_affected) %}\n    {{ get_csv_sql(create_table_sql, sql) }};\n  {% endcall %}\n\n  {% set target_relation = this.incorporate(type='table') %}\n\n  {% set should_revoke = should_revoke(old_relation, full_refresh_mode) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {% if full_refresh_mode or not exists_as_table %}\n    {% do create_indexes(target_relation) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt.should_full_refresh", "macro.dbt.run_hooks", "macro.dbt.reset_csv_table", "macro.dbt.create_csv_table", "macro.dbt.load_csv_rows", "macro.dbt.noop_statement", "macro.dbt.get_csv_sql", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs", "macro.dbt.create_indexes"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.390996, "supported_languages": ["sql"]}, "macro.dbt.create_csv_table": {"name": "create_csv_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.create_csv_table", "macro_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter.dispatch('create_csv_table', 'dbt')(model, agate_table) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__create_csv_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.402876, "supported_languages": null}, "macro.dbt.default__create_csv_table": {"name": "default__create_csv_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.default__create_csv_table", "macro_sql": "{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.406003, "supported_languages": null}, "macro.dbt.reset_csv_table": {"name": "reset_csv_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.reset_csv_table", "macro_sql": "{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter.dispatch('reset_csv_table', 'dbt')(model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__reset_csv_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.406826, "supported_languages": null}, "macro.dbt.default__reset_csv_table": {"name": "default__reset_csv_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.default__reset_csv_table", "macro_sql": "{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.create_csv_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.408525, "supported_languages": null}, "macro.dbt.get_csv_sql": {"name": "get_csv_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.get_csv_sql", "macro_sql": "{% macro get_csv_sql(create_or_truncate_sql, insert_sql) %}\n    {{ adapter.dispatch('get_csv_sql', 'dbt')(create_or_truncate_sql, insert_sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_csv_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4092171, "supported_languages": null}, "macro.dbt.default__get_csv_sql": {"name": "default__get_csv_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.default__get_csv_sql", "macro_sql": "{% macro default__get_csv_sql(create_or_truncate_sql, insert_sql) %}\n    {{ create_or_truncate_sql }};\n    -- dbt seed --\n    {{ insert_sql }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.409712, "supported_languages": null}, "macro.dbt.get_binding_char": {"name": "get_binding_char", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.get_binding_char", "macro_sql": "{% macro get_binding_char() -%}\n  {{ adapter.dispatch('get_binding_char', 'dbt')() }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_binding_char"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.410223, "supported_languages": null}, "macro.dbt.default__get_binding_char": {"name": "default__get_binding_char", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.default__get_binding_char", "macro_sql": "{% macro default__get_binding_char() %}\n  {{ return('%s') }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.410654, "supported_languages": null}, "macro.dbt.get_batch_size": {"name": "get_batch_size", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.get_batch_size", "macro_sql": "{% macro get_batch_size() -%}\n  {{ return(adapter.dispatch('get_batch_size', 'dbt')()) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_batch_size"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.411229, "supported_languages": null}, "macro.dbt.default__get_batch_size": {"name": "default__get_batch_size", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.default__get_batch_size", "macro_sql": "{% macro default__get_batch_size() %}\n  {{ return(10000) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.411655, "supported_languages": null}, "macro.dbt.get_seed_column_quoted_csv": {"name": "get_seed_column_quoted_csv", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.get_seed_column_quoted_csv", "macro_sql": "{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.413322, "supported_languages": null}, "macro.dbt.load_csv_rows": {"name": "load_csv_rows", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.load_csv_rows", "macro_sql": "{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter.dispatch('load_csv_rows', 'dbt')(model, agate_table) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__load_csv_rows"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4139872, "supported_languages": null}, "macro.dbt.default__load_csv_rows": {"name": "default__load_csv_rows", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.default__load_csv_rows", "macro_sql": "{% macro default__load_csv_rows(model, agate_table) %}\n\n  {% set batch_size = get_batch_size() %}\n\n  {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n  {% set bindings = [] %}\n\n  {% set statements = [] %}\n\n  {% for chunk in agate_table.rows | batch(batch_size) %}\n      {% set bindings = [] %}\n\n      {% for row in chunk %}\n          {% do bindings.extend(row) %}\n      {% endfor %}\n\n      {% set sql %}\n          insert into {{ this.render() }} ({{ cols_sql }}) values\n          {% for row in chunk -%}\n              ({%- for column in agate_table.column_names -%}\n                  {{ get_binding_char() }}\n                  {%- if not loop.last%},{%- endif %}\n              {%- endfor -%})\n              {%- if not loop.last%},{%- endif %}\n          {%- endfor %}\n      {% endset %}\n\n      {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n      {% if loop.index0 == 0 %}\n          {% do statements.append(sql) %}\n      {% endif %}\n  {% endfor %}\n\n  {# Return SQL so we can render it out into the compiled files #}\n  {{ return(statements[0]) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_batch_size", "macro.dbt.get_seed_column_quoted_csv", "macro.dbt.get_binding_char"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.418186, "supported_languages": null}, "macro.dbt.generate_alias_name": {"name": "generate_alias_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/get_custom_name/get_custom_alias.sql", "original_file_path": "macros/get_custom_name/get_custom_alias.sql", "unique_id": "macro.dbt.generate_alias_name", "macro_sql": "{% macro generate_alias_name(custom_alias_name=none, node=none) -%}\n    {% do return(adapter.dispatch('generate_alias_name', 'dbt')(custom_alias_name, node)) %}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__generate_alias_name"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.419443, "supported_languages": null}, "macro.dbt.default__generate_alias_name": {"name": "default__generate_alias_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/get_custom_name/get_custom_alias.sql", "original_file_path": "macros/get_custom_name/get_custom_alias.sql", "unique_id": "macro.dbt.default__generate_alias_name", "macro_sql": "{% macro default__generate_alias_name(custom_alias_name=none, node=none) -%}\n\n    {%- if custom_alias_name -%}\n\n        {{ custom_alias_name | trim }}\n\n    {%- elif node.version -%}\n\n        {{ return(node.name ~ \"_v\" ~ (node.version | replace(\".\", \"_\"))) }}\n\n    {%- else -%}\n\n        {{ node.name }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.420655, "supported_languages": null}, "macro.dbt.generate_schema_name": {"name": "generate_schema_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/get_custom_name/get_custom_schema.sql", "original_file_path": "macros/get_custom_name/get_custom_schema.sql", "unique_id": "macro.dbt.generate_schema_name", "macro_sql": "{% macro generate_schema_name(custom_schema_name=none, node=none) -%}\n    {{ return(adapter.dispatch('generate_schema_name', 'dbt')(custom_schema_name, node)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__generate_schema_name"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.422136, "supported_languages": null}, "macro.dbt.default__generate_schema_name": {"name": "default__generate_schema_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/get_custom_name/get_custom_schema.sql", "original_file_path": "macros/get_custom_name/get_custom_schema.sql", "unique_id": "macro.dbt.default__generate_schema_name", "macro_sql": "{% macro default__generate_schema_name(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if custom_schema_name is none -%}\n\n        {{ default_schema }}\n\n    {%- else -%}\n\n        {{ default_schema }}_{{ custom_schema_name | trim }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.422996, "supported_languages": null}, "macro.dbt.generate_schema_name_for_env": {"name": "generate_schema_name_for_env", "resource_type": "macro", "package_name": "dbt", "path": "macros/get_custom_name/get_custom_schema.sql", "original_file_path": "macros/get_custom_name/get_custom_schema.sql", "unique_id": "macro.dbt.generate_schema_name_for_env", "macro_sql": "{% macro generate_schema_name_for_env(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if target.name == 'prod' and custom_schema_name is not none -%}\n\n        {{ custom_schema_name | trim }}\n\n    {%- else -%}\n\n        {{ default_schema }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4239411, "supported_languages": null}, "macro.dbt.generate_database_name": {"name": "generate_database_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/get_custom_name/get_custom_database.sql", "original_file_path": "macros/get_custom_name/get_custom_database.sql", "unique_id": "macro.dbt.generate_database_name", "macro_sql": "{% macro generate_database_name(custom_database_name=none, node=none) -%}\n    {% do return(adapter.dispatch('generate_database_name', 'dbt')(custom_database_name, node)) %}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__generate_database_name"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.425131, "supported_languages": null}, "macro.dbt.default__generate_database_name": {"name": "default__generate_database_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/get_custom_name/get_custom_database.sql", "original_file_path": "macros/get_custom_name/get_custom_database.sql", "unique_id": "macro.dbt.default__generate_database_name", "macro_sql": "{% macro default__generate_database_name(custom_database_name=none, node=none) -%}\n    {%- set default_database = target.database -%}\n    {%- if custom_database_name is none -%}\n\n        {{ default_database }}\n\n    {%- else -%}\n\n        {{ custom_database_name }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.425972, "supported_languages": null}, "macro.dbt.default__test_relationships": {"name": "default__test_relationships", "resource_type": "macro", "package_name": "dbt", "path": "macros/generic_test_sql/relationships.sql", "original_file_path": "macros/generic_test_sql/relationships.sql", "unique_id": "macro.dbt.default__test_relationships", "macro_sql": "{% macro default__test_relationships(model, column_name, to, field) %}\n\nwith child as (\n    select {{ column_name }} as from_field\n    from {{ model }}\n    where {{ column_name }} is not null\n),\n\nparent as (\n    select {{ field }} as to_field\n    from {{ to }}\n)\n\nselect\n    from_field\n\nfrom child\nleft join parent\n    on child.from_field = parent.to_field\n\nwhere parent.to_field is null\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4270132, "supported_languages": null}, "macro.dbt.default__test_not_null": {"name": "default__test_not_null", "resource_type": "macro", "package_name": "dbt", "path": "macros/generic_test_sql/not_null.sql", "original_file_path": "macros/generic_test_sql/not_null.sql", "unique_id": "macro.dbt.default__test_not_null", "macro_sql": "{% macro default__test_not_null(model, column_name) %}\n\n{% set column_list = '*' if should_store_failures() else column_name %}\n\nselect {{ column_list }}\nfrom {{ model }}\nwhere {{ column_name }} is null\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.should_store_failures"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.427959, "supported_languages": null}, "macro.dbt.default__test_unique": {"name": "default__test_unique", "resource_type": "macro", "package_name": "dbt", "path": "macros/generic_test_sql/unique.sql", "original_file_path": "macros/generic_test_sql/unique.sql", "unique_id": "macro.dbt.default__test_unique", "macro_sql": "{% macro default__test_unique(model, column_name) %}\n\nselect\n    {{ column_name }} as unique_field,\n    count(*) as n_records\n\nfrom {{ model }}\nwhere {{ column_name }} is not null\ngroup by {{ column_name }}\nhaving count(*) > 1\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.428738, "supported_languages": null}, "macro.dbt.default__test_accepted_values": {"name": "default__test_accepted_values", "resource_type": "macro", "package_name": "dbt", "path": "macros/generic_test_sql/accepted_values.sql", "original_file_path": "macros/generic_test_sql/accepted_values.sql", "unique_id": "macro.dbt.default__test_accepted_values", "macro_sql": "{% macro default__test_accepted_values(model, column_name, values, quote=True) %}\n\nwith all_values as (\n\n    select\n        {{ column_name }} as value_field,\n        count(*) as n_records\n\n    from {{ model }}\n    group by {{ column_name }}\n\n)\n\nselect *\nfrom all_values\nwhere value_field not in (\n    {% for value in values -%}\n        {% if quote -%}\n        '{{ value }}'\n        {%- else -%}\n        {{ value }}\n        {%- endif -%}\n        {%- if not loop.last -%},{%- endif %}\n    {%- endfor %}\n)\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.43047, "supported_languages": null}, "macro.dbt.statement": {"name": "statement", "resource_type": "macro", "package_name": "dbt", "path": "macros/etc/statement.sql", "original_file_path": "macros/etc/statement.sql", "unique_id": "macro.dbt.statement", "macro_sql": "\n{%- macro statement(name=None, fetch_result=False, auto_begin=True, language='sql') -%}\n  {%- if execute: -%}\n    {%- set compiled_code = caller() -%}\n\n    {%- if name == 'main' -%}\n      {{ log('Writing runtime {} for node \"{}\"'.format(language, model['unique_id'])) }}\n      {{ write(compiled_code) }}\n    {%- endif -%}\n    {%- if language == 'sql'-%}\n      {%- set res, table = adapter.execute(compiled_code, auto_begin=auto_begin, fetch=fetch_result) -%}\n    {%- elif language == 'python' -%}\n      {%- set res = submit_python_job(model, compiled_code) -%}\n      {#-- TODO: What should table be for python models? --#}\n      {%- set table = None -%}\n    {%- else -%}\n      {% do exceptions.raise_compiler_error(\"statement macro didn't get supported language\") %}\n    {%- endif -%}\n\n    {%- if name is not none -%}\n      {{ store_result(name, response=res, agate_table=table) }}\n    {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.434795, "supported_languages": null}, "macro.dbt.noop_statement": {"name": "noop_statement", "resource_type": "macro", "package_name": "dbt", "path": "macros/etc/statement.sql", "original_file_path": "macros/etc/statement.sql", "unique_id": "macro.dbt.noop_statement", "macro_sql": "{% macro noop_statement(name=None, message=None, code=None, rows_affected=None, res=None) -%}\n  {%- set sql = caller() -%}\n\n  {%- if name == 'main' -%}\n    {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n    {{ write(sql) }}\n  {%- endif -%}\n\n  {%- if name is not none -%}\n    {{ store_raw_result(name, message=message, code=code, rows_affected=rows_affected, agate_table=res) }}\n  {%- endif -%}\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.436637, "supported_languages": null}, "macro.dbt.run_query": {"name": "run_query", "resource_type": "macro", "package_name": "dbt", "path": "macros/etc/statement.sql", "original_file_path": "macros/etc/statement.sql", "unique_id": "macro.dbt.run_query", "macro_sql": "{% macro run_query(sql) %}\n  {% call statement(\"run_query_statement\", fetch_result=true, auto_begin=false) %}\n    {{ sql }}\n  {% endcall %}\n\n  {% do return(load_result(\"run_query_statement\").table) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4375958, "supported_languages": null}, "macro.dbt.convert_datetime": {"name": "convert_datetime", "resource_type": "macro", "package_name": "dbt", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "unique_id": "macro.dbt.convert_datetime", "macro_sql": "{% macro convert_datetime(date_str, date_fmt) %}\n\n  {% set error_msg -%}\n      The provided partition date '{{ date_str }}' does not match the expected format '{{ date_fmt }}'\n  {%- endset %}\n\n  {% set res = try_or_compiler_error(error_msg, modules.datetime.datetime.strptime, date_str.strip(), date_fmt) %}\n  {{ return(res) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4422789, "supported_languages": null}, "macro.dbt.dates_in_range": {"name": "dates_in_range", "resource_type": "macro", "package_name": "dbt", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "unique_id": "macro.dbt.dates_in_range", "macro_sql": "{% macro dates_in_range(start_date_str, end_date_str=none, in_fmt=\"%Y%m%d\", out_fmt=\"%Y%m%d\") %}\n    {% set end_date_str = start_date_str if end_date_str is none else end_date_str %}\n\n    {% set start_date = convert_datetime(start_date_str, in_fmt) %}\n    {% set end_date = convert_datetime(end_date_str, in_fmt) %}\n\n    {% set day_count = (end_date - start_date).days %}\n    {% if day_count < 0 %}\n        {% set msg -%}\n            Partiton start date is after the end date ({{ start_date }}, {{ end_date }})\n        {%- endset %}\n\n        {{ exceptions.raise_compiler_error(msg, model) }}\n    {% endif %}\n\n    {% set date_list = [] %}\n    {% for i in range(0, day_count + 1) %}\n        {% set the_date = (modules.datetime.timedelta(days=i) + start_date) %}\n        {% if not out_fmt %}\n            {% set _ = date_list.append(the_date) %}\n        {% else %}\n            {% set _ = date_list.append(the_date.strftime(out_fmt)) %}\n        {% endif %}\n    {% endfor %}\n\n    {{ return(date_list) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.convert_datetime"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4462469, "supported_languages": null}, "macro.dbt.partition_range": {"name": "partition_range", "resource_type": "macro", "package_name": "dbt", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "unique_id": "macro.dbt.partition_range", "macro_sql": "{% macro partition_range(raw_partition_date, date_fmt='%Y%m%d') %}\n    {% set partition_range = (raw_partition_date | string).split(\",\") %}\n\n    {% if (partition_range | length) == 1 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = none %}\n    {% elif (partition_range | length) == 2 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = partition_range[1] %}\n    {% else %}\n      {{ exceptions.raise_compiler_error(\"Invalid partition time. Expected format: {Start Date}[,{End Date}]. Got: \" ~ raw_partition_date) }}\n    {% endif %}\n\n    {{ return(dates_in_range(start_date, end_date, in_fmt=date_fmt)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.dates_in_range"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.448619, "supported_languages": null}, "macro.dbt.py_current_timestring": {"name": "py_current_timestring", "resource_type": "macro", "package_name": "dbt", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "unique_id": "macro.dbt.py_current_timestring", "macro_sql": "{% macro py_current_timestring() %}\n    {% set dt = modules.datetime.datetime.now() %}\n    {% do return(dt.strftime(\"%Y%m%d%H%M%S%f\")) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4493911, "supported_languages": null}, "macro.dbt.except": {"name": "except", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/except.sql", "original_file_path": "macros/utils/except.sql", "unique_id": "macro.dbt.except", "macro_sql": "{% macro except() %}\n  {{ return(adapter.dispatch('except', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__except"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4501278, "supported_languages": null}, "macro.dbt.default__except": {"name": "default__except", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/except.sql", "original_file_path": "macros/utils/except.sql", "unique_id": "macro.dbt.default__except", "macro_sql": "{% macro default__except() %}\n\n    except\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.450403, "supported_languages": null}, "macro.dbt.replace": {"name": "replace", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/replace.sql", "original_file_path": "macros/utils/replace.sql", "unique_id": "macro.dbt.replace", "macro_sql": "{% macro replace(field, old_chars, new_chars) -%}\n    {{ return(adapter.dispatch('replace', 'dbt') (field, old_chars, new_chars)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__replace"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.451403, "supported_languages": null}, "macro.dbt.default__replace": {"name": "default__replace", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/replace.sql", "original_file_path": "macros/utils/replace.sql", "unique_id": "macro.dbt.default__replace", "macro_sql": "{% macro default__replace(field, old_chars, new_chars) %}\n\n    replace(\n        {{ field }},\n        {{ old_chars }},\n        {{ new_chars }}\n    )\n\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.451961, "supported_languages": null}, "macro.dbt.concat": {"name": "concat", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/concat.sql", "original_file_path": "macros/utils/concat.sql", "unique_id": "macro.dbt.concat", "macro_sql": "{% macro concat(fields) -%}\n  {{ return(adapter.dispatch('concat', 'dbt')(fields)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__concat"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4527402, "supported_languages": null}, "macro.dbt.default__concat": {"name": "default__concat", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/concat.sql", "original_file_path": "macros/utils/concat.sql", "unique_id": "macro.dbt.default__concat", "macro_sql": "{% macro default__concat(fields) -%}\n    {{ fields|join(' || ') }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.453165, "supported_languages": null}, "macro.dbt.length": {"name": "length", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/length.sql", "original_file_path": "macros/utils/length.sql", "unique_id": "macro.dbt.length", "macro_sql": "{% macro length(expression) -%}\n    {{ return(adapter.dispatch('length', 'dbt') (expression)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__length"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.45397, "supported_languages": null}, "macro.dbt.default__length": {"name": "default__length", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/length.sql", "original_file_path": "macros/utils/length.sql", "unique_id": "macro.dbt.default__length", "macro_sql": "{% macro default__length(expression) %}\n\n    length(\n        {{ expression }}\n    )\n\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.45434, "supported_languages": null}, "macro.dbt.dateadd": {"name": "dateadd", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/dateadd.sql", "original_file_path": "macros/utils/dateadd.sql", "unique_id": "macro.dbt.dateadd", "macro_sql": "{% macro dateadd(datepart, interval, from_date_or_timestamp) %}\n  {{ return(adapter.dispatch('dateadd', 'dbt')(datepart, interval, from_date_or_timestamp)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.springbricks_integration_tests.databricks__dateadd"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4553988, "supported_languages": null}, "macro.dbt.default__dateadd": {"name": "default__dateadd", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/dateadd.sql", "original_file_path": "macros/utils/dateadd.sql", "unique_id": "macro.dbt.default__dateadd", "macro_sql": "{% macro default__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    dateadd(\n        {{ datepart }},\n        {{ interval }},\n        {{ from_date_or_timestamp }}\n        )\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.455959, "supported_languages": null}, "macro.dbt.intersect": {"name": "intersect", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/intersect.sql", "original_file_path": "macros/utils/intersect.sql", "unique_id": "macro.dbt.intersect", "macro_sql": "{% macro intersect() %}\n  {{ return(adapter.dispatch('intersect', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__intersect"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.456683, "supported_languages": null}, "macro.dbt.default__intersect": {"name": "default__intersect", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/intersect.sql", "original_file_path": "macros/utils/intersect.sql", "unique_id": "macro.dbt.default__intersect", "macro_sql": "{% macro default__intersect() %}\n\n    intersect\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.456959, "supported_languages": null}, "macro.dbt.escape_single_quotes": {"name": "escape_single_quotes", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/escape_single_quotes.sql", "original_file_path": "macros/utils/escape_single_quotes.sql", "unique_id": "macro.dbt.escape_single_quotes", "macro_sql": "{% macro escape_single_quotes(expression) %}\n      {{ return(adapter.dispatch('escape_single_quotes', 'dbt') (expression)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__escape_single_quotes"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.457792, "supported_languages": null}, "macro.dbt.default__escape_single_quotes": {"name": "default__escape_single_quotes", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/escape_single_quotes.sql", "original_file_path": "macros/utils/escape_single_quotes.sql", "unique_id": "macro.dbt.default__escape_single_quotes", "macro_sql": "{% macro default__escape_single_quotes(expression) -%}\n{{ expression | replace(\"'\",\"''\") }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4582698, "supported_languages": null}, "macro.dbt.right": {"name": "right", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/right.sql", "original_file_path": "macros/utils/right.sql", "unique_id": "macro.dbt.right", "macro_sql": "{% macro right(string_text, length_expression) -%}\n    {{ return(adapter.dispatch('right', 'dbt') (string_text, length_expression)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__right"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4591832, "supported_languages": null}, "macro.dbt.default__right": {"name": "default__right", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/right.sql", "original_file_path": "macros/utils/right.sql", "unique_id": "macro.dbt.default__right", "macro_sql": "{% macro default__right(string_text, length_expression) %}\n\n    right(\n        {{ string_text }},\n        {{ length_expression }}\n    )\n\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.459666, "supported_languages": null}, "macro.dbt.listagg": {"name": "listagg", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/listagg.sql", "original_file_path": "macros/utils/listagg.sql", "unique_id": "macro.dbt.listagg", "macro_sql": "{% macro listagg(measure, delimiter_text=\"','\", order_by_clause=none, limit_num=none) -%}\n    {{ return(adapter.dispatch('listagg', 'dbt') (measure, delimiter_text, order_by_clause, limit_num)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__listagg"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.461437, "supported_languages": null}, "macro.dbt.default__listagg": {"name": "default__listagg", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/listagg.sql", "original_file_path": "macros/utils/listagg.sql", "unique_id": "macro.dbt.default__listagg", "macro_sql": "{% macro default__listagg(measure, delimiter_text, order_by_clause, limit_num) -%}\n\n    {% if limit_num -%}\n    array_to_string(\n        array_slice(\n            array_agg(\n                {{ measure }}\n            ){% if order_by_clause -%}\n            within group ({{ order_by_clause }})\n            {%- endif %}\n            ,0\n            ,{{ limit_num }}\n        ),\n        {{ delimiter_text }}\n        )\n    {%- else %}\n    listagg(\n        {{ measure }},\n        {{ delimiter_text }}\n        )\n        {% if order_by_clause -%}\n        within group ({{ order_by_clause }})\n        {%- endif %}\n    {%- endif %}\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.462804, "supported_languages": null}, "macro.dbt.datediff": {"name": "datediff", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/datediff.sql", "original_file_path": "macros/utils/datediff.sql", "unique_id": "macro.dbt.datediff", "macro_sql": "{% macro datediff(first_date, second_date, datepart) %}\n  {{ return(adapter.dispatch('datediff', 'dbt')(first_date, second_date, datepart)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__datediff"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.463864, "supported_languages": null}, "macro.dbt.default__datediff": {"name": "default__datediff", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/datediff.sql", "original_file_path": "macros/utils/datediff.sql", "unique_id": "macro.dbt.default__datediff", "macro_sql": "{% macro default__datediff(first_date, second_date, datepart) -%}\n\n    datediff(\n        {{ datepart }},\n        {{ first_date }},\n        {{ second_date }}\n        )\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.46443, "supported_languages": null}, "macro.dbt.safe_cast": {"name": "safe_cast", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/safe_cast.sql", "original_file_path": "macros/utils/safe_cast.sql", "unique_id": "macro.dbt.safe_cast", "macro_sql": "{% macro safe_cast(field, type) %}\n  {{ return(adapter.dispatch('safe_cast', 'dbt') (field, type)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__safe_cast"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4653509, "supported_languages": null}, "macro.dbt.default__safe_cast": {"name": "default__safe_cast", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/safe_cast.sql", "original_file_path": "macros/utils/safe_cast.sql", "unique_id": "macro.dbt.default__safe_cast", "macro_sql": "{% macro default__safe_cast(field, type) %}\n    {# most databases don't support this function yet\n    so we just need to use cast #}\n    cast({{field}} as {{type}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4660218, "supported_languages": null}, "macro.dbt.hash": {"name": "hash", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/hash.sql", "original_file_path": "macros/utils/hash.sql", "unique_id": "macro.dbt.hash", "macro_sql": "{% macro hash(field) -%}\n  {{ return(adapter.dispatch('hash', 'dbt') (field)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__hash"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.466826, "supported_languages": null}, "macro.dbt.default__hash": {"name": "default__hash", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/hash.sql", "original_file_path": "macros/utils/hash.sql", "unique_id": "macro.dbt.default__hash", "macro_sql": "{% macro default__hash(field) -%}\n    md5(cast({{ field }} as {{ api.Column.translate_type('string') }}))\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.46736, "supported_languages": null}, "macro.dbt.cast_bool_to_text": {"name": "cast_bool_to_text", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/cast_bool_to_text.sql", "original_file_path": "macros/utils/cast_bool_to_text.sql", "unique_id": "macro.dbt.cast_bool_to_text", "macro_sql": "{% macro cast_bool_to_text(field) %}\n  {{ adapter.dispatch('cast_bool_to_text', 'dbt') (field) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__cast_bool_to_text"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.468132, "supported_languages": null}, "macro.dbt.default__cast_bool_to_text": {"name": "default__cast_bool_to_text", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/cast_bool_to_text.sql", "original_file_path": "macros/utils/cast_bool_to_text.sql", "unique_id": "macro.dbt.default__cast_bool_to_text", "macro_sql": "{% macro default__cast_bool_to_text(field) %}\n    cast({{ field }} as {{ api.Column.translate_type('string') }})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4686668, "supported_languages": null}, "macro.dbt.any_value": {"name": "any_value", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/any_value.sql", "original_file_path": "macros/utils/any_value.sql", "unique_id": "macro.dbt.any_value", "macro_sql": "{% macro any_value(expression) -%}\n    {{ return(adapter.dispatch('any_value', 'dbt') (expression)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__any_value"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.469461, "supported_languages": null}, "macro.dbt.default__any_value": {"name": "default__any_value", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/any_value.sql", "original_file_path": "macros/utils/any_value.sql", "unique_id": "macro.dbt.default__any_value", "macro_sql": "{% macro default__any_value(expression) -%}\n\n    any_value({{ expression }})\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4698272, "supported_languages": null}, "macro.dbt.position": {"name": "position", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/position.sql", "original_file_path": "macros/utils/position.sql", "unique_id": "macro.dbt.position", "macro_sql": "{% macro position(substring_text, string_text) -%}\n    {{ return(adapter.dispatch('position', 'dbt') (substring_text, string_text)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__position"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.470725, "supported_languages": null}, "macro.dbt.default__position": {"name": "default__position", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/position.sql", "original_file_path": "macros/utils/position.sql", "unique_id": "macro.dbt.default__position", "macro_sql": "{% macro default__position(substring_text, string_text) %}\n\n    position(\n        {{ substring_text }} in {{ string_text }}\n    )\n\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.471183, "supported_languages": null}, "macro.dbt.string_literal": {"name": "string_literal", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/literal.sql", "original_file_path": "macros/utils/literal.sql", "unique_id": "macro.dbt.string_literal", "macro_sql": "{%- macro string_literal(value) -%}\n  {{ return(adapter.dispatch('string_literal', 'dbt') (value)) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__string_literal"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.471959, "supported_languages": null}, "macro.dbt.default__string_literal": {"name": "default__string_literal", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/literal.sql", "original_file_path": "macros/utils/literal.sql", "unique_id": "macro.dbt.default__string_literal", "macro_sql": "{% macro default__string_literal(value) -%}\n    '{{ value }}'\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.472321, "supported_languages": null}, "macro.dbt.type_string": {"name": "type_string", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.type_string", "macro_sql": "\n\n{%- macro type_string() -%}\n  {{ return(adapter.dispatch('type_string', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__type_string"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.474855, "supported_languages": null}, "macro.dbt.default__type_string": {"name": "default__type_string", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.default__type_string", "macro_sql": "{% macro default__type_string() %}\n    {{ return(api.Column.translate_type(\"string\")) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4753768, "supported_languages": null}, "macro.dbt.type_timestamp": {"name": "type_timestamp", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.type_timestamp", "macro_sql": "\n\n{%- macro type_timestamp() -%}\n  {{ return(adapter.dispatch('type_timestamp', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__type_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4759219, "supported_languages": null}, "macro.dbt.default__type_timestamp": {"name": "default__type_timestamp", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.default__type_timestamp", "macro_sql": "{% macro default__type_timestamp() %}\n    {{ return(api.Column.translate_type(\"timestamp\")) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.476439, "supported_languages": null}, "macro.dbt.type_float": {"name": "type_float", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.type_float", "macro_sql": "\n\n{%- macro type_float() -%}\n  {{ return(adapter.dispatch('type_float', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__type_float"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.476982, "supported_languages": null}, "macro.dbt.default__type_float": {"name": "default__type_float", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.default__type_float", "macro_sql": "{% macro default__type_float() %}\n    {{ return(api.Column.translate_type(\"float\")) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4774961, "supported_languages": null}, "macro.dbt.type_numeric": {"name": "type_numeric", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.type_numeric", "macro_sql": "\n\n{%- macro type_numeric() -%}\n  {{ return(adapter.dispatch('type_numeric', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__type_numeric"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4780369, "supported_languages": null}, "macro.dbt.default__type_numeric": {"name": "default__type_numeric", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.default__type_numeric", "macro_sql": "{% macro default__type_numeric() %}\n    {{ return(api.Column.numeric_type(\"numeric\", 28, 6)) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.478623, "supported_languages": null}, "macro.dbt.type_bigint": {"name": "type_bigint", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.type_bigint", "macro_sql": "\n\n{%- macro type_bigint() -%}\n  {{ return(adapter.dispatch('type_bigint', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__type_bigint"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4791622, "supported_languages": null}, "macro.dbt.default__type_bigint": {"name": "default__type_bigint", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.default__type_bigint", "macro_sql": "{% macro default__type_bigint() %}\n    {{ return(api.Column.translate_type(\"bigint\")) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.479677, "supported_languages": null}, "macro.dbt.type_int": {"name": "type_int", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.type_int", "macro_sql": "\n\n{%- macro type_int() -%}\n  {{ return(adapter.dispatch('type_int', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__type_int"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4803798, "supported_languages": null}, "macro.dbt.default__type_int": {"name": "default__type_int", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.default__type_int", "macro_sql": "{%- macro default__type_int() -%}\n  {{ return(api.Column.translate_type(\"integer\")) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4808772, "supported_languages": null}, "macro.dbt.type_boolean": {"name": "type_boolean", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.type_boolean", "macro_sql": "\n\n{%- macro type_boolean() -%}\n  {{ return(adapter.dispatch('type_boolean', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__type_boolean"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.48141, "supported_languages": null}, "macro.dbt.default__type_boolean": {"name": "default__type_boolean", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.default__type_boolean", "macro_sql": "{%- macro default__type_boolean() -%}\n  {{ return(api.Column.translate_type(\"boolean\")) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4819012, "supported_languages": null}, "macro.dbt.array_concat": {"name": "array_concat", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/array_concat.sql", "original_file_path": "macros/utils/array_concat.sql", "unique_id": "macro.dbt.array_concat", "macro_sql": "{% macro array_concat(array_1, array_2) -%}\n  {{ return(adapter.dispatch('array_concat', 'dbt')(array_1, array_2)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__array_concat"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.482771, "supported_languages": null}, "macro.dbt.default__array_concat": {"name": "default__array_concat", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/array_concat.sql", "original_file_path": "macros/utils/array_concat.sql", "unique_id": "macro.dbt.default__array_concat", "macro_sql": "{% macro default__array_concat(array_1, array_2) -%}\n    array_cat({{ array_1 }}, {{ array_2 }})\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.483232, "supported_languages": null}, "macro.dbt.bool_or": {"name": "bool_or", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/bool_or.sql", "original_file_path": "macros/utils/bool_or.sql", "unique_id": "macro.dbt.bool_or", "macro_sql": "{% macro bool_or(expression) -%}\n    {{ return(adapter.dispatch('bool_or', 'dbt') (expression)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__bool_or"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.484031, "supported_languages": null}, "macro.dbt.default__bool_or": {"name": "default__bool_or", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/bool_or.sql", "original_file_path": "macros/utils/bool_or.sql", "unique_id": "macro.dbt.default__bool_or", "macro_sql": "{% macro default__bool_or(expression) -%}\n\n    bool_or({{ expression }})\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.484396, "supported_languages": null}, "macro.dbt.last_day": {"name": "last_day", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/last_day.sql", "original_file_path": "macros/utils/last_day.sql", "unique_id": "macro.dbt.last_day", "macro_sql": "{% macro last_day(date, datepart) %}\n  {{ return(adapter.dispatch('last_day', 'dbt') (date, datepart)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__last_day"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.485439, "supported_languages": null}, "macro.dbt.default_last_day": {"name": "default_last_day", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/last_day.sql", "original_file_path": "macros/utils/last_day.sql", "unique_id": "macro.dbt.default_last_day", "macro_sql": "\n\n{%- macro default_last_day(date, datepart) -%}\n    cast(\n        {{dbt.dateadd('day', '-1',\n        dbt.dateadd(datepart, '1', dbt.date_trunc(datepart, date))\n        )}}\n        as date)\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.dateadd", "macro.dbt.date_trunc"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4863, "supported_languages": null}, "macro.dbt.default__last_day": {"name": "default__last_day", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/last_day.sql", "original_file_path": "macros/utils/last_day.sql", "unique_id": "macro.dbt.default__last_day", "macro_sql": "{% macro default__last_day(date, datepart) -%}\n    {{dbt.default_last_day(date, datepart)}}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default_last_day"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.486795, "supported_languages": null}, "macro.dbt.split_part": {"name": "split_part", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/split_part.sql", "original_file_path": "macros/utils/split_part.sql", "unique_id": "macro.dbt.split_part", "macro_sql": "{% macro split_part(string_text, delimiter_text, part_number) %}\n  {{ return(adapter.dispatch('split_part', 'dbt') (string_text, delimiter_text, part_number)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__split_part"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4882739, "supported_languages": null}, "macro.dbt.default__split_part": {"name": "default__split_part", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/split_part.sql", "original_file_path": "macros/utils/split_part.sql", "unique_id": "macro.dbt.default__split_part", "macro_sql": "{% macro default__split_part(string_text, delimiter_text, part_number) %}\n\n    split_part(\n        {{ string_text }},\n        {{ delimiter_text }},\n        {{ part_number }}\n        )\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.488835, "supported_languages": null}, "macro.dbt._split_part_negative": {"name": "_split_part_negative", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/split_part.sql", "original_file_path": "macros/utils/split_part.sql", "unique_id": "macro.dbt._split_part_negative", "macro_sql": "{% macro _split_part_negative(string_text, delimiter_text, part_number) %}\n\n    split_part(\n        {{ string_text }},\n        {{ delimiter_text }},\n          length({{ string_text }})\n          - length(\n              replace({{ string_text }},  {{ delimiter_text }}, '')\n          ) + 2 {{ part_number }}\n        )\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.489578, "supported_languages": null}, "macro.dbt.date_trunc": {"name": "date_trunc", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/date_trunc.sql", "original_file_path": "macros/utils/date_trunc.sql", "unique_id": "macro.dbt.date_trunc", "macro_sql": "{% macro date_trunc(datepart, date) -%}\n  {{ return(adapter.dispatch('date_trunc', 'dbt') (datepart, date)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__date_trunc"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.490449, "supported_languages": null}, "macro.dbt.default__date_trunc": {"name": "default__date_trunc", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/date_trunc.sql", "original_file_path": "macros/utils/date_trunc.sql", "unique_id": "macro.dbt.default__date_trunc", "macro_sql": "{% macro default__date_trunc(datepart, date) -%}\n    date_trunc('{{datepart}}', {{date}})\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.490894, "supported_languages": null}, "macro.dbt.array_construct": {"name": "array_construct", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/array_construct.sql", "original_file_path": "macros/utils/array_construct.sql", "unique_id": "macro.dbt.array_construct", "macro_sql": "{% macro array_construct(inputs=[], data_type=api.Column.translate_type('integer')) -%}\n  {{ return(adapter.dispatch('array_construct', 'dbt')(inputs, data_type)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__array_construct"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.492032, "supported_languages": null}, "macro.dbt.default__array_construct": {"name": "default__array_construct", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/array_construct.sql", "original_file_path": "macros/utils/array_construct.sql", "unique_id": "macro.dbt.default__array_construct", "macro_sql": "{% macro default__array_construct(inputs, data_type) -%}\n    {% if inputs|length > 0 %}\n    array[ {{ inputs|join(' , ') }} ]\n    {% else %}\n    array[]::{{data_type}}[]\n    {% endif %}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.49284, "supported_languages": null}, "macro.dbt.array_append": {"name": "array_append", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/array_append.sql", "original_file_path": "macros/utils/array_append.sql", "unique_id": "macro.dbt.array_append", "macro_sql": "{% macro array_append(array, new_element) -%}\n  {{ return(adapter.dispatch('array_append', 'dbt')(array, new_element)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__array_append"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4937322, "supported_languages": null}, "macro.dbt.default__array_append": {"name": "default__array_append", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/array_append.sql", "original_file_path": "macros/utils/array_append.sql", "unique_id": "macro.dbt.default__array_append", "macro_sql": "{% macro default__array_append(array, new_element) -%}\n    array_append({{ array }}, {{ new_element }})\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.494189, "supported_languages": null}, "macro.dbt.create_schema": {"name": "create_schema", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/schema.sql", "original_file_path": "macros/adapters/schema.sql", "unique_id": "macro.dbt.create_schema", "macro_sql": "{% macro create_schema(relation) -%}\n  {{ adapter.dispatch('create_schema', 'dbt')(relation) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__create_schema"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4953039, "supported_languages": null}, "macro.dbt.default__create_schema": {"name": "default__create_schema", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/schema.sql", "original_file_path": "macros/adapters/schema.sql", "unique_id": "macro.dbt.default__create_schema", "macro_sql": "{% macro default__create_schema(relation) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{ relation.without_identifier() }}\n  {% endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.495938, "supported_languages": null}, "macro.dbt.drop_schema": {"name": "drop_schema", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/schema.sql", "original_file_path": "macros/adapters/schema.sql", "unique_id": "macro.dbt.drop_schema", "macro_sql": "{% macro drop_schema(relation) -%}\n  {{ adapter.dispatch('drop_schema', 'dbt')(relation) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__drop_schema"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.4964979, "supported_languages": null}, "macro.dbt.default__drop_schema": {"name": "default__drop_schema", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/schema.sql", "original_file_path": "macros/adapters/schema.sql", "unique_id": "macro.dbt.default__drop_schema", "macro_sql": "{% macro default__drop_schema(relation) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{ relation.without_identifier() }} cascade\n  {% endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.49729, "supported_languages": null}, "macro.dbt.current_timestamp": {"name": "current_timestamp", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.current_timestamp", "macro_sql": "{%- macro current_timestamp() -%}\n    {{ adapter.dispatch('current_timestamp', 'dbt')() }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_spark.spark__current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.498641, "supported_languages": null}, "macro.dbt.default__current_timestamp": {"name": "default__current_timestamp", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.default__current_timestamp", "macro_sql": "{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter ' + adapter.type()) }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.499138, "supported_languages": null}, "macro.dbt.snapshot_get_time": {"name": "snapshot_get_time", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.snapshot_get_time", "macro_sql": "\n\n{%- macro snapshot_get_time() -%}\n    {{ adapter.dispatch('snapshot_get_time', 'dbt')() }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__snapshot_get_time"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.49963, "supported_languages": null}, "macro.dbt.default__snapshot_get_time": {"name": "default__snapshot_get_time", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.default__snapshot_get_time", "macro_sql": "{% macro default__snapshot_get_time() %}\n    {{ current_timestamp() }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.499997, "supported_languages": null}, "macro.dbt.current_timestamp_backcompat": {"name": "current_timestamp_backcompat", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.current_timestamp_backcompat", "macro_sql": "{% macro current_timestamp_backcompat() %}\n    {{ return(adapter.dispatch('current_timestamp_backcompat', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__current_timestamp_backcompat"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.500561, "supported_languages": null}, "macro.dbt.default__current_timestamp_backcompat": {"name": "default__current_timestamp_backcompat", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.default__current_timestamp_backcompat", "macro_sql": "{% macro default__current_timestamp_backcompat() %}\n    current_timestamp::timestamp\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.5008352, "supported_languages": null}, "macro.dbt.current_timestamp_in_utc_backcompat": {"name": "current_timestamp_in_utc_backcompat", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.current_timestamp_in_utc_backcompat", "macro_sql": "{% macro current_timestamp_in_utc_backcompat() %}\n    {{ return(adapter.dispatch('current_timestamp_in_utc_backcompat', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__current_timestamp_in_utc_backcompat"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.50139, "supported_languages": null}, "macro.dbt.default__current_timestamp_in_utc_backcompat": {"name": "default__current_timestamp_in_utc_backcompat", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.default__current_timestamp_in_utc_backcompat", "macro_sql": "{% macro default__current_timestamp_in_utc_backcompat() %}\n    {{ return(adapter.dispatch('current_timestamp_backcompat', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.current_timestamp_backcompat", "macro.dbt.default__current_timestamp_backcompat"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.501955, "supported_languages": null}, "macro.dbt.get_create_index_sql": {"name": "get_create_index_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "unique_id": "macro.dbt.get_create_index_sql", "macro_sql": "{% macro get_create_index_sql(relation, index_dict) -%}\n  {{ return(adapter.dispatch('get_create_index_sql', 'dbt')(relation, index_dict)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_create_index_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.503273, "supported_languages": null}, "macro.dbt.default__get_create_index_sql": {"name": "default__get_create_index_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "unique_id": "macro.dbt.default__get_create_index_sql", "macro_sql": "{% macro default__get_create_index_sql(relation, index_dict) -%}\n  {% do return(None) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.5037482, "supported_languages": null}, "macro.dbt.create_indexes": {"name": "create_indexes", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "unique_id": "macro.dbt.create_indexes", "macro_sql": "{% macro create_indexes(relation) -%}\n  {{ adapter.dispatch('create_indexes', 'dbt')(relation) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__create_indexes"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.5042849, "supported_languages": null}, "macro.dbt.default__create_indexes": {"name": "default__create_indexes", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "unique_id": "macro.dbt.default__create_indexes", "macro_sql": "{% macro default__create_indexes(relation) -%}\n  {%- set _indexes = config.get('indexes', default=[]) -%}\n\n  {% for _index_dict in _indexes %}\n    {% set create_index_sql = get_create_index_sql(relation, _index_dict) %}\n    {% if create_index_sql %}\n      {% do run_query(create_index_sql) %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_create_index_sql", "macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.5056, "supported_languages": null}, "macro.dbt.make_intermediate_relation": {"name": "make_intermediate_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.make_intermediate_relation", "macro_sql": "{% macro make_intermediate_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter.dispatch('make_intermediate_relation', 'dbt')(base_relation, suffix)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__make_intermediate_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.513799, "supported_languages": null}, "macro.dbt.default__make_intermediate_relation": {"name": "default__make_intermediate_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.default__make_intermediate_relation", "macro_sql": "{% macro default__make_intermediate_relation(base_relation, suffix) %}\n    {{ return(default__make_temp_relation(base_relation, suffix)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__make_temp_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.514356, "supported_languages": null}, "macro.dbt.make_temp_relation": {"name": "make_temp_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.make_temp_relation", "macro_sql": "{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter.dispatch('make_temp_relation', 'dbt')(base_relation, suffix)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__make_temp_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.515083, "supported_languages": null}, "macro.dbt.default__make_temp_relation": {"name": "default__make_temp_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.default__make_temp_relation", "macro_sql": "{% macro default__make_temp_relation(base_relation, suffix) %}\n    {%- set temp_identifier = base_relation.identifier ~ suffix -%}\n    {%- set temp_relation = base_relation.incorporate(\n                                path={\"identifier\": temp_identifier}) -%}\n\n    {{ return(temp_relation) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.516029, "supported_languages": null}, "macro.dbt.make_backup_relation": {"name": "make_backup_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.make_backup_relation", "macro_sql": "{% macro make_backup_relation(base_relation, backup_relation_type, suffix='__dbt_backup') %}\n    {{ return(adapter.dispatch('make_backup_relation', 'dbt')(base_relation, backup_relation_type, suffix)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__make_backup_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.5168278, "supported_languages": null}, "macro.dbt.default__make_backup_relation": {"name": "default__make_backup_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.default__make_backup_relation", "macro_sql": "{% macro default__make_backup_relation(base_relation, backup_relation_type, suffix) %}\n    {%- set backup_identifier = base_relation.identifier ~ suffix -%}\n    {%- set backup_relation = base_relation.incorporate(\n                                  path={\"identifier\": backup_identifier},\n                                  type=backup_relation_type\n    ) -%}\n    {{ return(backup_relation) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.5178518, "supported_languages": null}, "macro.dbt.drop_relation": {"name": "drop_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.drop_relation", "macro_sql": "{% macro drop_relation(relation) -%}\n  {{ return(adapter.dispatch('drop_relation', 'dbt')(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__drop_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.5184672, "supported_languages": null}, "macro.dbt.default__drop_relation": {"name": "default__drop_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.default__drop_relation", "macro_sql": "{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.5191748, "supported_languages": null}, "macro.dbt.truncate_relation": {"name": "truncate_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.truncate_relation", "macro_sql": "{% macro truncate_relation(relation) -%}\n  {{ return(adapter.dispatch('truncate_relation', 'dbt')(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__truncate_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.519948, "supported_languages": null}, "macro.dbt.default__truncate_relation": {"name": "default__truncate_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.default__truncate_relation", "macro_sql": "{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.520503, "supported_languages": null}, "macro.dbt.rename_relation": {"name": "rename_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.rename_relation", "macro_sql": "{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter.dispatch('rename_relation', 'dbt')(from_relation, to_relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__rename_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.521164, "supported_languages": null}, "macro.dbt.default__rename_relation": {"name": "default__rename_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.default__rename_relation", "macro_sql": "{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.522086, "supported_languages": null}, "macro.dbt.get_or_create_relation": {"name": "get_or_create_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.get_or_create_relation", "macro_sql": "{% macro get_or_create_relation(database, schema, identifier, type) -%}\n  {{ return(adapter.dispatch('get_or_create_relation', 'dbt')(database, schema, identifier, type)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_or_create_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.522895, "supported_languages": null}, "macro.dbt.default__get_or_create_relation": {"name": "default__get_or_create_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.default__get_or_create_relation", "macro_sql": "{% macro default__get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.524833, "supported_languages": null}, "macro.dbt.load_cached_relation": {"name": "load_cached_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.load_cached_relation", "macro_sql": "{% macro load_cached_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.525609, "supported_languages": null}, "macro.dbt.load_relation": {"name": "load_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.load_relation", "macro_sql": "{% macro load_relation(relation) %}\n    {{ return(load_cached_relation(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.load_cached_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.526099, "supported_languages": null}, "macro.dbt.drop_relation_if_exists": {"name": "drop_relation_if_exists", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.drop_relation_if_exists", "macro_sql": "{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.526756, "supported_languages": null}, "macro.dbt.collect_freshness": {"name": "collect_freshness", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/freshness.sql", "original_file_path": "macros/adapters/freshness.sql", "unique_id": "macro.dbt.collect_freshness", "macro_sql": "{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter.dispatch('collect_freshness', 'dbt')(source, loaded_at_field, filter))}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__collect_freshness"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.528, "supported_languages": null}, "macro.dbt.default__collect_freshness": {"name": "default__collect_freshness", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/freshness.sql", "original_file_path": "macros/adapters/freshness.sql", "unique_id": "macro.dbt.default__collect_freshness", "macro_sql": "{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt.current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.529331, "supported_languages": null}, "macro.dbt.copy_grants": {"name": "copy_grants", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.copy_grants", "macro_sql": "{% macro copy_grants() %}\n    {{ return(adapter.dispatch('copy_grants', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__copy_grants"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.533684, "supported_languages": null}, "macro.dbt.default__copy_grants": {"name": "default__copy_grants", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.default__copy_grants", "macro_sql": "{% macro default__copy_grants() %}\n    {{ return(True) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.534085, "supported_languages": null}, "macro.dbt.support_multiple_grantees_per_dcl_statement": {"name": "support_multiple_grantees_per_dcl_statement", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.support_multiple_grantees_per_dcl_statement", "macro_sql": "{% macro support_multiple_grantees_per_dcl_statement() %}\n    {{ return(adapter.dispatch('support_multiple_grantees_per_dcl_statement', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__support_multiple_grantees_per_dcl_statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.5346391, "supported_languages": null}, "macro.dbt.default__support_multiple_grantees_per_dcl_statement": {"name": "default__support_multiple_grantees_per_dcl_statement", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.default__support_multiple_grantees_per_dcl_statement", "macro_sql": "\n\n{%- macro default__support_multiple_grantees_per_dcl_statement() -%}\n    {{ return(True) }}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.53504, "supported_languages": null}, "macro.dbt.should_revoke": {"name": "should_revoke", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.should_revoke", "macro_sql": "{% macro should_revoke(existing_relation, full_refresh_mode=True) %}\n\n    {% if not existing_relation %}\n        {#-- The table doesn't already exist, so no grants to copy over --#}\n        {{ return(False) }}\n    {% elif full_refresh_mode %}\n        {#-- The object is being REPLACED -- whether grants are copied over depends on the value of user config --#}\n        {{ return(copy_grants()) }}\n    {% else %}\n        {#-- The table is being merged/upserted/inserted -- grants will be carried over --#}\n        {{ return(True) }}\n    {% endif %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.copy_grants"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.536169, "supported_languages": null}, "macro.dbt.get_show_grant_sql": {"name": "get_show_grant_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.get_show_grant_sql", "macro_sql": "{% macro get_show_grant_sql(relation) %}\n    {{ return(adapter.dispatch(\"get_show_grant_sql\", \"dbt\")(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_show_grant_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.5368, "supported_languages": null}, "macro.dbt.default__get_show_grant_sql": {"name": "default__get_show_grant_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.default__get_show_grant_sql", "macro_sql": "{% macro default__get_show_grant_sql(relation) %}\n    show grants on {{ relation }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.537167, "supported_languages": null}, "macro.dbt.get_grant_sql": {"name": "get_grant_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.get_grant_sql", "macro_sql": "{% macro get_grant_sql(relation, privilege, grantees) %}\n    {{ return(adapter.dispatch('get_grant_sql', 'dbt')(relation, privilege, grantees)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__get_grant_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.5379121, "supported_languages": null}, "macro.dbt.default__get_grant_sql": {"name": "default__get_grant_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.default__get_grant_sql", "macro_sql": "\n\n{%- macro default__get_grant_sql(relation, privilege, grantees) -%}\n    grant {{ privilege }} on {{ relation }} to {{ grantees | join(', ') }}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.53856, "supported_languages": null}, "macro.dbt.get_revoke_sql": {"name": "get_revoke_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.get_revoke_sql", "macro_sql": "{% macro get_revoke_sql(relation, privilege, grantees) %}\n    {{ return(adapter.dispatch('get_revoke_sql', 'dbt')(relation, privilege, grantees)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__get_revoke_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.539307, "supported_languages": null}, "macro.dbt.default__get_revoke_sql": {"name": "default__get_revoke_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.default__get_revoke_sql", "macro_sql": "\n\n{%- macro default__get_revoke_sql(relation, privilege, grantees) -%}\n    revoke {{ privilege }} on {{ relation }} from {{ grantees | join(', ') }}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.539941, "supported_languages": null}, "macro.dbt.get_dcl_statement_list": {"name": "get_dcl_statement_list", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.get_dcl_statement_list", "macro_sql": "{% macro get_dcl_statement_list(relation, grant_config, get_dcl_macro) %}\n    {{ return(adapter.dispatch('get_dcl_statement_list', 'dbt')(relation, grant_config, get_dcl_macro)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_dcl_statement_list"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.5408928, "supported_languages": null}, "macro.dbt.default__get_dcl_statement_list": {"name": "default__get_dcl_statement_list", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.default__get_dcl_statement_list", "macro_sql": "\n\n{%- macro default__get_dcl_statement_list(relation, grant_config, get_dcl_macro) -%}\n    {#\n      -- Unpack grant_config into specific privileges and the set of users who need them granted/revoked.\n      -- Depending on whether this database supports multiple grantees per statement, pass in the list of\n      -- all grantees per privilege, or (if not) template one statement per privilege-grantee pair.\n      -- `get_dcl_macro` will be either `get_grant_sql` or `get_revoke_sql`\n    #}\n    {%- set dcl_statements = [] -%}\n    {%- for privilege, grantees in grant_config.items() %}\n        {%- if support_multiple_grantees_per_dcl_statement() and grantees -%}\n          {%- set dcl = get_dcl_macro(relation, privilege, grantees) -%}\n          {%- do dcl_statements.append(dcl) -%}\n        {%- else -%}\n          {%- for grantee in grantees -%}\n              {% set dcl = get_dcl_macro(relation, privilege, [grantee]) %}\n              {%- do dcl_statements.append(dcl) -%}\n          {% endfor -%}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return(dcl_statements) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.support_multiple_grantees_per_dcl_statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.543046, "supported_languages": null}, "macro.dbt.call_dcl_statements": {"name": "call_dcl_statements", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.call_dcl_statements", "macro_sql": "{% macro call_dcl_statements(dcl_statement_list) %}\n    {{ return(adapter.dispatch(\"call_dcl_statements\", \"dbt\")(dcl_statement_list)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__call_dcl_statements"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.54368, "supported_languages": null}, "macro.dbt.default__call_dcl_statements": {"name": "default__call_dcl_statements", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.default__call_dcl_statements", "macro_sql": "{% macro default__call_dcl_statements(dcl_statement_list) %}\n    {#\n      -- By default, supply all grant + revoke statements in a single semicolon-separated block,\n      -- so that they're all processed together.\n\n      -- Some databases do not support this. Those adapters will need to override this macro\n      -- to run each statement individually.\n    #}\n    {% call statement('grants') %}\n        {% for dcl_statement in dcl_statement_list %}\n            {{ dcl_statement }};\n        {% endfor %}\n    {% endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.544559, "supported_languages": null}, "macro.dbt.apply_grants": {"name": "apply_grants", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.apply_grants", "macro_sql": "{% macro apply_grants(relation, grant_config, should_revoke) %}\n    {{ return(adapter.dispatch(\"apply_grants\", \"dbt\")(relation, grant_config, should_revoke)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__apply_grants"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.545321, "supported_languages": null}, "macro.dbt.default__apply_grants": {"name": "default__apply_grants", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.default__apply_grants", "macro_sql": "{% macro default__apply_grants(relation, grant_config, should_revoke=True) %}\n    {#-- If grant_config is {} or None, this is a no-op --#}\n    {% if grant_config %}\n        {% if should_revoke %}\n            {#-- We think previous grants may have carried over --#}\n            {#-- Show current grants and calculate diffs --#}\n            {% set current_grants_table = run_query(get_show_grant_sql(relation)) %}\n            {% set current_grants_dict = adapter.standardize_grants_dict(current_grants_table) %}\n            {% set needs_granting = diff_of_two_dicts(grant_config, current_grants_dict) %}\n            {% set needs_revoking = diff_of_two_dicts(current_grants_dict, grant_config) %}\n            {% if not (needs_granting or needs_revoking) %}\n                {{ log('On ' ~ relation ~': All grants are in place, no revocation or granting needed.')}}\n            {% endif %}\n        {% else %}\n            {#-- We don't think there's any chance of previous grants having carried over. --#}\n            {#-- Jump straight to granting what the user has configured. --#}\n            {% set needs_revoking = {} %}\n            {% set needs_granting = grant_config %}\n        {% endif %}\n        {% if needs_granting or needs_revoking %}\n            {% set revoke_statement_list = get_dcl_statement_list(relation, needs_revoking, get_revoke_sql) %}\n            {% set grant_statement_list = get_dcl_statement_list(relation, needs_granting, get_grant_sql) %}\n            {% set dcl_statement_list = revoke_statement_list + grant_statement_list %}\n            {% if dcl_statement_list %}\n                {{ call_dcl_statements(dcl_statement_list) }}\n            {% endif %}\n        {% endif %}\n    {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_query", "macro.dbt.get_show_grant_sql", "macro.dbt.get_dcl_statement_list", "macro.dbt.call_dcl_statements"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.5490298, "supported_languages": null}, "macro.dbt.alter_column_comment": {"name": "alter_column_comment", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt.alter_column_comment", "macro_sql": "{% macro alter_column_comment(relation, column_dict) -%}\n  {{ return(adapter.dispatch('alter_column_comment', 'dbt')(relation, column_dict)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__alter_column_comment"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.550923, "supported_languages": null}, "macro.dbt.default__alter_column_comment": {"name": "default__alter_column_comment", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt.default__alter_column_comment", "macro_sql": "{% macro default__alter_column_comment(relation, column_dict) -%}\n  {{ exceptions.raise_not_implemented(\n    'alter_column_comment macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.5514932, "supported_languages": null}, "macro.dbt.alter_relation_comment": {"name": "alter_relation_comment", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt.alter_relation_comment", "macro_sql": "{% macro alter_relation_comment(relation, relation_comment) -%}\n  {{ return(adapter.dispatch('alter_relation_comment', 'dbt')(relation, relation_comment)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__alter_relation_comment"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.552166, "supported_languages": null}, "macro.dbt.default__alter_relation_comment": {"name": "default__alter_relation_comment", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt.default__alter_relation_comment", "macro_sql": "{% macro default__alter_relation_comment(relation, relation_comment) -%}\n  {{ exceptions.raise_not_implemented(\n    'alter_relation_comment macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.5527282, "supported_languages": null}, "macro.dbt.persist_docs": {"name": "persist_docs", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt.persist_docs", "macro_sql": "{% macro persist_docs(relation, model, for_relation=true, for_columns=true) -%}\n  {{ return(adapter.dispatch('persist_docs', 'dbt')(relation, model, for_relation, for_columns)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.5535932, "supported_languages": null}, "macro.dbt.default__persist_docs": {"name": "default__persist_docs", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt.default__persist_docs", "macro_sql": "{% macro default__persist_docs(relation, model, for_relation, for_columns) -%}\n  {% if for_relation and config.persist_relation_docs() and model.description %}\n    {% do run_query(alter_relation_comment(relation, model.description)) %}\n  {% endif %}\n\n  {% if for_columns and config.persist_column_docs() and model.columns %}\n    {% do run_query(alter_column_comment(relation, model.columns)) %}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_query", "macro.dbt.alter_relation_comment", "macro.dbt.alter_column_comment"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.55515, "supported_languages": null}, "macro.dbt.get_catalog": {"name": "get_catalog", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.get_catalog", "macro_sql": "{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter.dispatch('get_catalog', 'dbt')(information_schema, schemas)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_catalog"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.558958, "supported_languages": null}, "macro.dbt.default__get_catalog": {"name": "default__get_catalog", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.default__get_catalog", "macro_sql": "{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.559816, "supported_languages": null}, "macro.dbt.information_schema_name": {"name": "information_schema_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.information_schema_name", "macro_sql": "{% macro information_schema_name(database) %}\n  {{ return(adapter.dispatch('information_schema_name', 'dbt')(database)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__information_schema_name"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.560438, "supported_languages": null}, "macro.dbt.default__information_schema_name": {"name": "default__information_schema_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.default__information_schema_name", "macro_sql": "{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ database }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.56097, "supported_languages": null}, "macro.dbt.list_schemas": {"name": "list_schemas", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.list_schemas", "macro_sql": "{% macro list_schemas(database) -%}\n  {{ return(adapter.dispatch('list_schemas', 'dbt')(database)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__list_schemas"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.5615842, "supported_languages": null}, "macro.dbt.default__list_schemas": {"name": "default__list_schemas", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.default__list_schemas", "macro_sql": "{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.information_schema_name", "macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.562407, "supported_languages": null}, "macro.dbt.check_schema_exists": {"name": "check_schema_exists", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.check_schema_exists", "macro_sql": "{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter.dispatch('check_schema_exists', 'dbt')(information_schema, schema)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__check_schema_exists"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.563086, "supported_languages": null}, "macro.dbt.default__check_schema_exists": {"name": "default__check_schema_exists", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.default__check_schema_exists", "macro_sql": "{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.replace", "macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.564092, "supported_languages": null}, "macro.dbt.list_relations_without_caching": {"name": "list_relations_without_caching", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.list_relations_without_caching", "macro_sql": "{% macro list_relations_without_caching(schema_relation) %}\n  {{ return(adapter.dispatch('list_relations_without_caching', 'dbt')(schema_relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__list_relations_without_caching"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.564723, "supported_languages": null}, "macro.dbt.default__list_relations_without_caching": {"name": "default__list_relations_without_caching", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.default__list_relations_without_caching", "macro_sql": "{% macro default__list_relations_without_caching(schema_relation) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.565283, "supported_languages": null}, "macro.dbt.get_columns_in_relation": {"name": "get_columns_in_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.get_columns_in_relation", "macro_sql": "{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter.dispatch('get_columns_in_relation', 'dbt')(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__get_columns_in_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.57098, "supported_languages": null}, "macro.dbt.default__get_columns_in_relation": {"name": "default__get_columns_in_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.default__get_columns_in_relation", "macro_sql": "{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.571696, "supported_languages": null}, "macro.dbt.sql_convert_columns_in_relation": {"name": "sql_convert_columns_in_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.sql_convert_columns_in_relation", "macro_sql": "{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.572716, "supported_languages": null}, "macro.dbt.get_empty_subquery_sql": {"name": "get_empty_subquery_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.get_empty_subquery_sql", "macro_sql": "{% macro get_empty_subquery_sql(select_sql, select_sql_header=none) -%}\n  {{ return(adapter.dispatch('get_empty_subquery_sql', 'dbt')(select_sql, select_sql_header)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_empty_subquery_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.5734332, "supported_languages": null}, "macro.dbt.default__get_empty_subquery_sql": {"name": "default__get_empty_subquery_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.default__get_empty_subquery_sql", "macro_sql": "{% macro default__get_empty_subquery_sql(select_sql, select_sql_header=none) %}\n    {%- if select_sql_header is not none -%}\n    {{ select_sql_header }}\n    {%- endif -%}\n    select * from (\n        {{ select_sql }}\n    ) as __dbt_sbq\n    where false\n    limit 0\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.574107, "supported_languages": null}, "macro.dbt.get_empty_schema_sql": {"name": "get_empty_schema_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.get_empty_schema_sql", "macro_sql": "{% macro get_empty_schema_sql(columns) -%}\n  {{ return(adapter.dispatch('get_empty_schema_sql', 'dbt')(columns)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_empty_schema_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.5747159, "supported_languages": null}, "macro.dbt.default__get_empty_schema_sql": {"name": "default__get_empty_schema_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.default__get_empty_schema_sql", "macro_sql": "{% macro default__get_empty_schema_sql(columns) %}\n    {%- set col_err = [] -%}\n    select\n    {% for i in columns %}\n      {%- set col = columns[i] -%}\n      {%- if col['data_type'] is not defined -%}\n        {{ col_err.append(col['name']) }}\n      {%- endif -%}\n      {% set col_name = adapter.quote(col['name']) if col.get('quote') else col['name'] %}\n      cast(null as {{ col['data_type'] }}) as {{ col_name }}{{ \", \" if not loop.last }}\n    {%- endfor -%}\n    {%- if (col_err | length) > 0 -%}\n      {{ exceptions.column_type_missing(column_names=col_err) }}\n    {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.577146, "supported_languages": null}, "macro.dbt.get_column_schema_from_query": {"name": "get_column_schema_from_query", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.get_column_schema_from_query", "macro_sql": "{% macro get_column_schema_from_query(select_sql, select_sql_header=none) -%}\n    {% set columns = [] %}\n    {# -- Using an 'empty subquery' here to get the same schema as the given select_sql statement, without necessitating a data scan.#}\n    {% set sql = get_empty_subquery_sql(select_sql, select_sql_header) %}\n    {% set column_schema = adapter.get_column_schema_from_query(sql) %}\n    {{ return(column_schema) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_empty_subquery_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.5782661, "supported_languages": null}, "macro.dbt.get_columns_in_query": {"name": "get_columns_in_query", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.get_columns_in_query", "macro_sql": "{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter.dispatch('get_columns_in_query', 'dbt')(select_sql)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_columns_in_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.578877, "supported_languages": null}, "macro.dbt.default__get_columns_in_query": {"name": "default__get_columns_in_query", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.default__get_columns_in_query", "macro_sql": "{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        {{ get_empty_subquery_sql(select_sql) }}\n    {% endcall %}\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt.get_empty_subquery_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.580008, "supported_languages": null}, "macro.dbt.alter_column_type": {"name": "alter_column_type", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.alter_column_type", "macro_sql": "{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter.dispatch('alter_column_type', 'dbt')(relation, column_name, new_column_type)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__alter_column_type"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.580767, "supported_languages": null}, "macro.dbt.default__alter_column_type": {"name": "default__alter_column_type", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.default__alter_column_type", "macro_sql": "{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.582703, "supported_languages": null}, "macro.dbt.alter_relation_add_remove_columns": {"name": "alter_relation_add_remove_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.alter_relation_add_remove_columns", "macro_sql": "{% macro alter_relation_add_remove_columns(relation, add_columns = none, remove_columns = none) -%}\n  {{ return(adapter.dispatch('alter_relation_add_remove_columns', 'dbt')(relation, add_columns, remove_columns)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__alter_relation_add_remove_columns"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.583533, "supported_languages": null}, "macro.dbt.default__alter_relation_add_remove_columns": {"name": "default__alter_relation_add_remove_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.default__alter_relation_add_remove_columns", "macro_sql": "{% macro default__alter_relation_add_remove_columns(relation, add_columns, remove_columns) %}\n\n  {% if add_columns is none %}\n    {% set add_columns = [] %}\n  {% endif %}\n  {% if remove_columns is none %}\n    {% set remove_columns = [] %}\n  {% endif %}\n\n  {% set sql -%}\n\n     alter {{ relation.type }} {{ relation }}\n\n            {% for column in add_columns %}\n               add column {{ column.name }} {{ column.data_type }}{{ ',' if not loop.last }}\n            {% endfor %}{{ ',' if add_columns and remove_columns }}\n\n            {% for column in remove_columns %}\n                drop column {{ column.name }}{{ ',' if not loop.last }}\n            {% endfor %}\n\n  {%- endset -%}\n\n  {% do run_query(sql) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.5860648, "supported_languages": null}, "macro.dbt.resolve_model_name": {"name": "resolve_model_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/python_model/python.sql", "original_file_path": "macros/python_model/python.sql", "unique_id": "macro.dbt.resolve_model_name", "macro_sql": "{% macro resolve_model_name(input_model_name) %}\n    {{ return(adapter.dispatch('resolve_model_name', 'dbt')(input_model_name)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__resolve_model_name"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.590254, "supported_languages": null}, "macro.dbt.default__resolve_model_name": {"name": "default__resolve_model_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/python_model/python.sql", "original_file_path": "macros/python_model/python.sql", "unique_id": "macro.dbt.default__resolve_model_name", "macro_sql": "\n\n{%- macro default__resolve_model_name(input_model_name) -%}\n    {{  input_model_name | string | replace('\"', '\\\"') }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.590768, "supported_languages": null}, "macro.dbt.build_ref_function": {"name": "build_ref_function", "resource_type": "macro", "package_name": "dbt", "path": "macros/python_model/python.sql", "original_file_path": "macros/python_model/python.sql", "unique_id": "macro.dbt.build_ref_function", "macro_sql": "{% macro build_ref_function(model) %}\n\n    {%- set ref_dict = {} -%}\n    {%- for _ref in model.refs -%}\n        {% set _ref_args = [_ref.get('package'), _ref['name']] if _ref.get('package') else [_ref['name'],] %}\n        {%- set resolved = ref(*_ref_args, v=_ref.get('version')) -%}\n        {%- if _ref.get('version') -%}\n            {% do _ref_args.extend([\"v\" ~ _ref['version']]) %}\n        {%- endif -%}\n       {%- do ref_dict.update({_ref_args | join('.'): resolve_model_name(resolved)}) -%}\n    {%- endfor -%}\n\ndef ref(*args, **kwargs):\n    refs = {{ ref_dict | tojson }}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.resolve_model_name"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.593346, "supported_languages": null}, "macro.dbt.build_source_function": {"name": "build_source_function", "resource_type": "macro", "package_name": "dbt", "path": "macros/python_model/python.sql", "original_file_path": "macros/python_model/python.sql", "unique_id": "macro.dbt.build_source_function", "macro_sql": "{% macro build_source_function(model) %}\n\n    {%- set source_dict = {} -%}\n    {%- for _source in model.sources -%}\n        {%- set resolved = source(*_source) -%}\n        {%- do source_dict.update({_source | join('.'): resolve_model_name(resolved)}) -%}\n    {%- endfor -%}\n\ndef source(*args, dbt_load_df_function):\n    sources = {{ source_dict | tojson }}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.resolve_model_name"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.594666, "supported_languages": null}, "macro.dbt.build_config_dict": {"name": "build_config_dict", "resource_type": "macro", "package_name": "dbt", "path": "macros/python_model/python.sql", "original_file_path": "macros/python_model/python.sql", "unique_id": "macro.dbt.build_config_dict", "macro_sql": "{% macro build_config_dict(model) %}\n    {%- set config_dict = {} -%}\n    {% set config_dbt_used = zip(model.config.config_keys_used, model.config.config_keys_defaults) | list %}\n    {%- for key, default in config_dbt_used -%}\n        {# weird type testing with enum, would be much easier to write this logic in Python! #}\n        {%- if key == \"language\" -%}\n          {%- set value = \"python\" -%}\n        {%- endif -%}\n        {%- set value = model.config.get(key, default) -%}\n        {%- do config_dict.update({key: value}) -%}\n    {%- endfor -%}\nconfig_dict = {{ config_dict }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.5965161, "supported_languages": null}, "macro.dbt.py_script_postfix": {"name": "py_script_postfix", "resource_type": "macro", "package_name": "dbt", "path": "macros/python_model/python.sql", "original_file_path": "macros/python_model/python.sql", "unique_id": "macro.dbt.py_script_postfix", "macro_sql": "{% macro py_script_postfix(model) %}\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\n{{ build_ref_function(model ) }}\n{{ build_source_function(model ) }}\n{{ build_config_dict(model) }}\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"{{ this.database }}\"\n    schema = \"{{ this.schema }}\"\n    identifier = \"{{ this.identifier }}\"\n    {% set this_relation_name = resolve_model_name(this) %}\n    def __repr__(self):\n        return '{{ this_relation_name  }}'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = {{ is_incremental() }}\n\n# COMMAND ----------\n{{py_script_comment()}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.build_ref_function", "macro.dbt.build_source_function", "macro.dbt.build_config_dict", "macro.dbt.resolve_model_name", "macro.dbt.is_incremental", "macro.dbt.py_script_comment"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.598, "supported_languages": null}, "macro.dbt.py_script_comment": {"name": "py_script_comment", "resource_type": "macro", "package_name": "dbt", "path": "macros/python_model/python.sql", "original_file_path": "macros/python_model/python.sql", "unique_id": "macro.dbt.py_script_comment", "macro_sql": "{%macro py_script_comment()%}\n{%endmacro%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.598274, "supported_languages": null}, "macro.dbt.test_unique": {"name": "test_unique", "resource_type": "macro", "package_name": "dbt", "path": "tests/generic/builtin.sql", "original_file_path": "tests/generic/builtin.sql", "unique_id": "macro.dbt.test_unique", "macro_sql": "{% test unique(model, column_name) %}\n    {% set macro = adapter.dispatch('test_unique', 'dbt') %}\n    {{ macro(model, column_name) }}\n{% endtest %}", "depends_on": {"macros": ["macro.dbt.default__test_unique"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.599732, "supported_languages": null}, "macro.dbt.test_not_null": {"name": "test_not_null", "resource_type": "macro", "package_name": "dbt", "path": "tests/generic/builtin.sql", "original_file_path": "tests/generic/builtin.sql", "unique_id": "macro.dbt.test_not_null", "macro_sql": "{% test not_null(model, column_name) %}\n    {% set macro = adapter.dispatch('test_not_null', 'dbt') %}\n    {{ macro(model, column_name) }}\n{% endtest %}", "depends_on": {"macros": ["macro.dbt.default__test_not_null"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.600487, "supported_languages": null}, "macro.dbt.test_accepted_values": {"name": "test_accepted_values", "resource_type": "macro", "package_name": "dbt", "path": "tests/generic/builtin.sql", "original_file_path": "tests/generic/builtin.sql", "unique_id": "macro.dbt.test_accepted_values", "macro_sql": "{% test accepted_values(model, column_name, values, quote=True) %}\n    {% set macro = adapter.dispatch('test_accepted_values', 'dbt') %}\n    {{ macro(model, column_name, values, quote) }}\n{% endtest %}", "depends_on": {"macros": ["macro.dbt.default__test_accepted_values"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.6018949, "supported_languages": null}, "macro.dbt.test_relationships": {"name": "test_relationships", "resource_type": "macro", "package_name": "dbt", "path": "tests/generic/builtin.sql", "original_file_path": "tests/generic/builtin.sql", "unique_id": "macro.dbt.test_relationships", "macro_sql": "{% test relationships(model, column_name, to, field) %}\n    {% set macro = adapter.dispatch('test_relationships', 'dbt') %}\n    {{ macro(model, column_name, to, field) }}\n{% endtest %}", "depends_on": {"macros": ["macro.dbt.default__test_relationships"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1690405243.602785, "supported_languages": null}}, "docs": {"doc.dbt.__overview__": {"name": "__overview__", "resource_type": "doc", "package_name": "dbt", "path": "overview.md", "original_file_path": "docs/overview.md", "unique_id": "doc.dbt.__overview__", "block_contents": "### Welcome!\n\nWelcome to the auto-generated documentation for your dbt project!\n\n### Navigation\n\nYou can use the `Project` and `Database` navigation tabs on the left side of the window to explore the models\nin your project.\n\n#### Project Tab\nThe `Project` tab mirrors the directory structure of your dbt project. In this tab, you can see all of the\nmodels defined in your dbt project, as well as models imported from dbt packages.\n\n#### Database Tab\nThe `Database` tab also exposes your models, but in a format that looks more like a database explorer. This view\nshows relations (tables and views) grouped into database schemas. Note that ephemeral models are _not_ shown\nin this interface, as they do not exist in the database.\n\n### Graph Exploration\nYou can click the blue icon on the bottom-right corner of the page to view the lineage graph of your models.\n\nOn model pages, you'll see the immediate parents and children of the model you're exploring. By clicking the `Expand`\nbutton at the top-right of this lineage pane, you'll be able to see all of the models that are used to build,\nor are built from, the model you're exploring.\n\nOnce expanded, you'll be able to use the `--select` and `--exclude` model selection syntax to filter the\nmodels in the graph. For more information on model selection, check out the [dbt docs](https://docs.getdbt.com/docs/model-selection-syntax).\n\nNote that you can also right-click on models to interactively filter and explore the graph.\n\n---\n\n### More information\n\n- [What is dbt](https://docs.getdbt.com/docs/introduction)?\n- Read the [dbt viewpoint](https://docs.getdbt.com/docs/viewpoint)\n- [Installation](https://docs.getdbt.com/docs/installation)\n- Join the [dbt Community](https://www.getdbt.com/community/) for questions and discussion"}}, "exposures": {}, "metrics": {}, "groups": {}, "selectors": {}, "disabled": {}, "parent_map": {"test.springbricks_integration_tests.asset_try_to_decimal": [], "test.springbricks_integration_tests.assert_dayname": ["seed.springbricks_integration_tests.springbrickstests"], "test.springbricks_integration_tests.timestampadd": ["seed.springbricks_integration_tests.springbrickstests"], "test.springbricks_integration_tests.assert_to_boolean": ["seed.springbricks_integration_tests.springbrickstests"], "test.springbricks_integration_tests.assert_to_array": ["seed.springbricks_integration_tests.springbrickstests"], "test.springbricks_integration_tests.assert_date_from_parts": ["seed.springbricks_integration_tests.springbrickstests"], "test.springbricks_integration_tests.asset_to_decimal": [], "test.springbricks_integration_tests.assert_zeroifnull": ["seed.springbricks_integration_tests.springbrickstests"], "test.springbricks_integration_tests.assert_week": ["seed.springbricks_integration_tests.springbrickstests"], "test.springbricks_integration_tests.assert_md5_binary": ["seed.springbricks_integration_tests.springbrickstests"], "test.springbricks_integration_tests.asset_try_to_numeric": [], "test.springbricks_integration_tests.assert_strtok_to_array": ["seed.springbricks_integration_tests.springbrickstests"], "test.springbricks_integration_tests.timestampdiff": ["seed.springbricks_integration_tests.springbrickstests"], "test.springbricks_integration_tests.asset_to_numeric": [], "test.springbricks_integration_tests.assert_listagg": [], "test.springbricks_integration_tests.assert_base64_encode": [], "test.springbricks_integration_tests.assert_to_time": ["seed.springbricks_integration_tests.springbrickstests"], "test.springbricks_integration_tests.assert_startswith": ["seed.springbricks_integration_tests.springbrickstests"], "test.springbricks_integration_tests.asset_try_to_number": [], "test.springbricks_integration_tests.assert_dayofweekiso": ["seed.springbricks_integration_tests.springbrickstests"], "test.springbricks_integration_tests.assert_listaggdistinct": [], "test.springbricks_integration_tests.timediff": ["seed.springbricks_integration_tests.springbrickstests"], "test.springbricks_integration_tests.assert_contains": ["seed.springbricks_integration_tests.springbrickstests"], "test.springbricks_integration_tests.assert_json_extract_path_text": ["seed.springbricks_integration_tests.springbrickstests"], "test.springbricks_integration_tests.asset_to_number": [], "test.springbricks_integration_tests.assert_monthname": ["seed.springbricks_integration_tests.springbrickstests"], "seed.springbricks_integration_tests.springbrickstests": []}, "child_map": {"test.springbricks_integration_tests.asset_try_to_decimal": [], "test.springbricks_integration_tests.assert_dayname": [], "test.springbricks_integration_tests.timestampadd": [], "test.springbricks_integration_tests.assert_to_boolean": [], "test.springbricks_integration_tests.assert_to_array": [], "test.springbricks_integration_tests.assert_date_from_parts": [], "test.springbricks_integration_tests.asset_to_decimal": [], "test.springbricks_integration_tests.assert_zeroifnull": [], "test.springbricks_integration_tests.assert_week": [], "test.springbricks_integration_tests.assert_md5_binary": [], "test.springbricks_integration_tests.asset_try_to_numeric": [], "test.springbricks_integration_tests.assert_strtok_to_array": [], "test.springbricks_integration_tests.timestampdiff": [], "test.springbricks_integration_tests.asset_to_numeric": [], "test.springbricks_integration_tests.assert_listagg": [], "test.springbricks_integration_tests.assert_base64_encode": [], "test.springbricks_integration_tests.assert_to_time": [], "test.springbricks_integration_tests.assert_startswith": [], "test.springbricks_integration_tests.asset_try_to_number": [], "test.springbricks_integration_tests.assert_dayofweekiso": [], "test.springbricks_integration_tests.assert_listaggdistinct": [], "test.springbricks_integration_tests.timediff": [], "test.springbricks_integration_tests.assert_contains": [], "test.springbricks_integration_tests.assert_json_extract_path_text": [], "test.springbricks_integration_tests.asset_to_number": [], "test.springbricks_integration_tests.assert_monthname": [], "seed.springbricks_integration_tests.springbrickstests": ["test.springbricks_integration_tests.assert_contains", "test.springbricks_integration_tests.assert_date_from_parts", "test.springbricks_integration_tests.assert_dayname", "test.springbricks_integration_tests.assert_dayofweekiso", "test.springbricks_integration_tests.assert_json_extract_path_text", "test.springbricks_integration_tests.assert_md5_binary", "test.springbricks_integration_tests.assert_monthname", "test.springbricks_integration_tests.assert_startswith", "test.springbricks_integration_tests.assert_strtok_to_array", "test.springbricks_integration_tests.assert_to_array", "test.springbricks_integration_tests.assert_to_boolean", "test.springbricks_integration_tests.assert_to_time", "test.springbricks_integration_tests.assert_week", "test.springbricks_integration_tests.assert_zeroifnull", "test.springbricks_integration_tests.timediff", "test.springbricks_integration_tests.timestampadd", "test.springbricks_integration_tests.timestampdiff"]}, "group_map": {}}