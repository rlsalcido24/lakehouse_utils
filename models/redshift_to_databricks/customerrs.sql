
{{
    config(
        materialized = 'table'
    )
}}

select 
    cast(c_custkey as string) as stringkey,
    c_name,
    c_address,
    c_nationkey,
    c_phone, 
    log10(c_acctbal) as actbalbaseten,
    log10(c_acctbal) as actbalbaseten,
    get_json_object('{"f2":{"f3":1},"f4":{"f5":99,"f6":"star"}}', '$.f4.f6'),
    power(2.71828, 100),
    CASE  Millenia WHEN lower( dow ::string) IN ('millennium', 'millennia', 'mil', 'mils') THEN (CEILING((YEAR(  2008-01-05 14:00:00 ::timestamp ) - 1) / 1000))  Century WHEN lower( dow ::string) IN ('century', 'centuries',	'c', 'cent', 'cents') THEN (CEILING((YEAR(  2008-01-05 14:00:00 ::timestamp ) - 1) / 100))  Decade WHEN lower( dow ::string) IN ('decade', 'decades', 'dec', 'decs') THEN (CEILING((YEAR(  2008-01-05 14:00:00 ::timestamp ) - 1) / 10))  Years WHEN lower( dow ::string) IN ('year', 'years','y', 'yr', 'yrs') THEN FLOOR(date_part('YEAR', 2008-01-05 14:00:00::timestamp) / 1)  Quarter WHEN lower( dow ::string) IN ('quarter', 'quarters', 'qtr', 'qtrs') THEN date_part('QUARTER', 2008-01-05 14:00:00::timestamp)  Month WHEN lower( dow ::string) IN ('month', 'months', 'mon', 'mons') THEN date_part('MONTH', 2008-01-05 14:00:00::timestamp)  Week WHEN lower( dow ::string) IN ('week', 'weeks', 'w') THEN date_part('WEEK', 2008-01-05 14:00:00::timestamp)  Day of Week: in Redshift day of week is 0-6, starting with Sunday, Databricks is 1-7, starting with Sunday WHEN lower( dow ::string) IN ('day of week', 'dayofweek', 'dow', 'dw', 'weekday') THEN date_part('DAYOFWEEK', 2008-01-05 14:00:00::timestamp) - 1  Day WHEN lower( dow ::string) IN ('day', 'days', 'd') THEN date_part('DAY', 2008-01-05 14:00:00::timestamp)  Hour WHEN lower( dow ::string) IN ('hour', 'hours',	'h', 'hr', 'hrs') THEN date_part('HOUR', 2008-01-05 14:00:00::timestamp)  Minute WHEN lower( dow ::string) IN ('minute', 'minutes', 'm', 'min', 'mins') THEN date_part('MINUTE', 2008-01-05 14:00:00::timestamp)  Second WHEN lower( dow ::string) IN ('second', 'seconds',	's', 'sec', 'secs') THEN date_part('SECOND', 2008-01-05 14:00:00::timestamp)  Millisecond WHEN lower( dow ::string) IN ('millisecond', 'milliseconds',	'ms', 'msec', 'msecs', 'msecond', 'mseconds', 'millisec', 'millisecs', 'millisecon') THEN date_part('SECOND', 2008-01-05 14:00:00::timestamp)*1000  Microsecond WHEN lower( dow ::string) IN ('microsecond', 'microseconds',	'microsec', 'microsecs', 'microsecond', 'usecond', 'useconds', 'us', 'usec', 'usecs') THEN date_part('SECOND', 2008-01-05 14:00:00::timestamp)*1000000  Else just try to use the raw dow - let it fail if it doenst convert so users know ELSE NULL END,
    hll_cardinality(expr),
    array_size([11,12,13,{"f1":21,"f2":[25,26]},14])),
    c_mktsegment,
    c_comment,
    date_format(date_trunc('second', current_timestamp()), 'yyyy-MM-dd HH:mm:ss') as hoy,
    date_format(date_trunc('second', current_timestamp()), 'yyyy-MM-dd HH:mm:ss') AS get_date_caps_test,
    date_format(current_timestamp(), 'yyyy-MM-dd HH:mm:ss') AS sys_date_col_test,
    date_format(current_timestamp(), 'yyyy-MM-dd HH:mm:ss') AS sys_date_caps_col_test,
    coalesce(test, test_is_null) AS null_test_col_caps,
    coalesce(test, test_is_null) AS null_test_col_caps,
    coalesce(test, 'test_is_null') AS null_test_col,
    CASE  Millenia WHEN lower( year ::string) IN ('millennium', 'millennia', 'mil', 'mils') THEN (CEILING((YEAR(  date(origination_date) ::timestamp ) - 1) / 1000))  Century WHEN lower( year ::string) IN ('century', 'centuries',	'c', 'cent', 'cents') THEN (CEILING((YEAR(  date(origination_date) ::timestamp ) - 1) / 100))  Decade WHEN lower( year ::string) IN ('decade', 'decades', 'dec', 'decs') THEN (CEILING((YEAR(  date(origination_date) ::timestamp ) - 1) / 10))  Years WHEN lower( year ::string) IN ('year', 'years','y', 'yr', 'yrs') THEN FLOOR(date_part('YEAR', date(origination_date)::timestamp) / 1)  Quarter WHEN lower( year ::string) IN ('quarter', 'quarters', 'qtr', 'qtrs') THEN date_part('QUARTER', date(origination_date)::timestamp)  Month WHEN lower( year ::string) IN ('month', 'months', 'mon', 'mons') THEN date_part('MONTH', date(origination_date)::timestamp)  Week WHEN lower( year ::string) IN ('week', 'weeks', 'w') THEN date_part('WEEK', date(origination_date)::timestamp)  Day of Week: in Redshift day of week is 0-6, starting with Sunday, Databricks is 1-7, starting with Sunday WHEN lower( year ::string) IN ('day of week', 'dayofweek', 'dow', 'dw', 'weekday') THEN date_part('DAYOFWEEK', date(origination_date)::timestamp) - 1  Day WHEN lower( year ::string) IN ('day', 'days', 'd') THEN date_part('DAY', date(origination_date)::timestamp)  Hour WHEN lower( year ::string) IN ('hour', 'hours',	'h', 'hr', 'hrs') THEN date_part('HOUR', date(origination_date)::timestamp)  Minute WHEN lower( year ::string) IN ('minute', 'minutes', 'm', 'min', 'mins') THEN date_part('MINUTE', date(origination_date)::timestamp)  Second WHEN lower( year ::string) IN ('second', 'seconds',	's', 'sec', 'secs') THEN date_part('SECOND', date(origination_date)::timestamp)  Millisecond WHEN lower( year ::string) IN ('millisecond', 'milliseconds',	'ms', 'msec', 'msecs', 'msecond', 'mseconds', 'millisec', 'millisecs', 'millisecon') THEN date_part('SECOND', date(origination_date)::timestamp)*1000  Microsecond WHEN lower( year ::string) IN ('microsecond', 'microseconds',	'microsec', 'microsecs', 'microsecond', 'usecond', 'useconds', 'us', 'usec', 'usecs') THEN date_part('SECOND', date(origination_date)::timestamp)*1000000  Else just try to use the raw year - let it fail if it doenst convert so users know ELSE NULL END) || '-' || 'Q' || floor(
            (CASE  Millenia WHEN lower( month ::string) IN ('millennium', 'millennia', 'mil', 'mils') THEN (CEILING((YEAR(  date(origination_date)) ::timestamp ) - 1) / 1000))  Century WHEN lower( month ::string) IN ('century', 'centuries',	'c', 'cent', 'cents') THEN (CEILING((YEAR(  date(origination_date)) ::timestamp ) - 1) / 100))  Decade WHEN lower( month ::string) IN ('decade', 'decades', 'dec', 'decs') THEN (CEILING((YEAR(  date(origination_date)) ::timestamp ) - 1) / 10))  Years WHEN lower( month ::string) IN ('year', 'years','y', 'yr', 'yrs') THEN FLOOR(date_part('YEAR', date(origination_date))::timestamp) / 1)  Quarter WHEN lower( month ::string) IN ('quarter', 'quarters', 'qtr', 'qtrs') THEN date_part('QUARTER', date(origination_date))::timestamp)  Month WHEN lower( month ::string) IN ('month', 'months', 'mon', 'mons') THEN date_part('MONTH', date(origination_date))::timestamp)  Week WHEN lower( month ::string) IN ('week', 'weeks', 'w') THEN date_part('WEEK', date(origination_date))::timestamp)  Day of Week: in Redshift day of week is 0-6, starting with Sunday, Databricks is 1-7, starting with Sunday WHEN lower( month ::string) IN ('day of week', 'dayofweek', 'dow', 'dw', 'weekday') THEN date_part('DAYOFWEEK', date(origination_date))::timestamp) - 1  Day WHEN lower( month ::string) IN ('day', 'days', 'd') THEN date_part('DAY', date(origination_date))::timestamp)  Hour WHEN lower( month ::string) IN ('hour', 'hours',	'h', 'hr', 'hrs') THEN date_part('HOUR', date(origination_date))::timestamp)  Minute WHEN lower( month ::string) IN ('minute', 'minutes', 'm', 'min', 'mins') THEN date_part('MINUTE', date(origination_date))::timestamp)  Second WHEN lower( month ::string) IN ('second', 'seconds',	's', 'sec', 'secs') THEN date_part('SECOND', date(origination_date))::timestamp)  Millisecond WHEN lower( month ::string) IN ('millisecond', 'milliseconds',	'ms', 'msec', 'msecs', 'msecond', 'mseconds', 'millisec', 'millisecs', 'millisecon') THEN date_part('SECOND', date(origination_date))::timestamp)*1000  Microsecond WHEN lower( month ::string) IN ('microsecond', 'microseconds',	'microsec', 'microsecs', 'microsecond', 'usecond', 'useconds', 'us', 'usec', 'usecs') THEN date_part('SECOND', date(origination_date))::timestamp)*1000000  Else just try to use the raw month - let it fail if it doenst convert so users know ELSE NULL END) - 1) / 3) + 1 as origination_quarter,
    CASE  Millenia WHEN lower( SECONDS ::string) IN ('millennium', 'millennia', 'mil', 'mils') THEN (CEILING((YEAR(  '2019-10-01 00:00:01.000001'::timestamp')) ::timestamp ) - 1) / 1000))  Century WHEN lower( SECONDS ::string) IN ('century', 'centuries',	'c', 'cent', 'cents') THEN (CEILING((YEAR(  '2019-10-01 00:00:01.000001'::timestamp')) ::timestamp ) - 1) / 100))  Decade WHEN lower( SECONDS ::string) IN ('decade', 'decades', 'dec', 'decs') THEN (CEILING((YEAR(  '2019-10-01 00:00:01.000001'::timestamp')) ::timestamp ) - 1) / 10))  Years WHEN lower( SECONDS ::string) IN ('year', 'years','y', 'yr', 'yrs') THEN FLOOR(date_part('YEAR', '2019-10-01 00:00:01.000001'::timestamp'))::timestamp) / 1)  Quarter WHEN lower( SECONDS ::string) IN ('quarter', 'quarters', 'qtr', 'qtrs') THEN date_part('QUARTER', '2019-10-01 00:00:01.000001'::timestamp'))::timestamp)  Month WHEN lower( SECONDS ::string) IN ('month', 'months', 'mon', 'mons') THEN date_part('MONTH', '2019-10-01 00:00:01.000001'::timestamp'))::timestamp)  Week WHEN lower( SECONDS ::string) IN ('week', 'weeks', 'w') THEN date_part('WEEK', '2019-10-01 00:00:01.000001'::timestamp'))::timestamp)  Day of Week: in Redshift day of week is 0-6, starting with Sunday, Databricks is 1-7, starting with Sunday WHEN lower( SECONDS ::string) IN ('day of week', 'dayofweek', 'dow', 'dw', 'weekday') THEN date_part('DAYOFWEEK', '2019-10-01 00:00:01.000001'::timestamp'))::timestamp) - 1  Day WHEN lower( SECONDS ::string) IN ('day', 'days', 'd') THEN date_part('DAY', '2019-10-01 00:00:01.000001'::timestamp'))::timestamp)  Hour WHEN lower( SECONDS ::string) IN ('hour', 'hours',	'h', 'hr', 'hrs') THEN date_part('HOUR', '2019-10-01 00:00:01.000001'::timestamp'))::timestamp)  Minute WHEN lower( SECONDS ::string) IN ('minute', 'minutes', 'm', 'min', 'mins') THEN date_part('MINUTE', '2019-10-01 00:00:01.000001'::timestamp'))::timestamp)  Second WHEN lower( SECONDS ::string) IN ('second', 'seconds',	's', 'sec', 'secs') THEN date_part('SECOND', '2019-10-01 00:00:01.000001'::timestamp'))::timestamp)  Millisecond WHEN lower( SECONDS ::string) IN ('millisecond', 'milliseconds',	'ms', 'msec', 'msecs', 'msecond', 'mseconds', 'millisec', 'millisecs', 'millisecon') THEN date_part('SECOND', '2019-10-01 00:00:01.000001'::timestamp'))::timestamp)*1000  Microsecond WHEN lower( SECONDS ::string) IN ('microsecond', 'microseconds',	'microsec', 'microsecs', 'microsecond', 'usecond', 'useconds', 'us', 'usec', 'usecs') THEN date_part('SECOND', '2019-10-01 00:00:01.000001'::timestamp'))::timestamp)*1000000  Else just try to use the raw SECONDS - let it fail if it doenst convert so users know ELSE NULL END
    first_value(
            case when colA = 2 then id2
            end ) ignore nulls
          over (
            partition by
                customer_id
            order by
                created_at
            rows between unbounded preceding and unbounded following
        ) as test_syntax_change
from
    redshift_sample_data.tpch_rs1.customer
ORDER BY  colC NULLS FIRST,colB  DESC NULLS FIRST